#!/usr/bin/env python3
"""
æœ‰åæ—¥æœ¬YouTubeãƒãƒ£ãƒ³ãƒãƒ«åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

@description æ—¥æœ¬ã§äººæ°—ã®é«˜ã„æœ‰åãƒãƒ£ãƒ³ãƒãƒ«ã‚’åé›†ã—ã¦DBä¿å­˜
ã‚µãƒ ãƒã‚¤ãƒ«ä»˜ãAIåˆ†æãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦Firestoreãƒ»BigQueryã«è“„ç©

@author InfuMatch Development Team
@version 1.0.0
"""

import os
import json
import asyncio
import re
from datetime import datetime, timezone
from typing import List, Dict, Any, Optional
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from google.cloud import firestore
from google.cloud import bigquery

# AIåˆ†æã‚µãƒ¼ãƒ“ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.ai_channel_analyzer import AdvancedChannelAnalyzer

# è¨­å®š
YOUTUBE_API_KEY = "AIzaSyDtPl5WSRdxk744ha5Tlwno4iTBZVO96r4"
PROJECT_ID = "hackathon-462905"

class FamousJapaneseChannelCollector:
    """
    æœ‰åæ—¥æœ¬ãƒãƒ£ãƒ³ãƒãƒ«åé›†ãƒ»ç™»éŒ²ã‚·ã‚¹ãƒ†ãƒ 
    
    æ©Ÿèƒ½:
    1. æœ‰åãƒãƒ£ãƒ³ãƒãƒ«ã®æˆ¦ç•¥çš„æ¤œç´¢
    2. AIåˆ†æã«ã‚ˆã‚‹é«˜åº¦ãªåˆ†æ
    3. ã‚µãƒ ãƒã‚¤ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿åé›†
    4. Firestoreãƒ»BigQueryè‡ªå‹•ç™»éŒ²
    """
    
    def __init__(self, api_key: str = YOUTUBE_API_KEY):
        self.api_key = api_key
        self.service = build('youtube', 'v3', developerKey=api_key)
        self.ai_analyzer = AdvancedChannelAnalyzer()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        self.firestore_db = firestore.Client(project=PROJECT_ID)
        self.bigquery_client = bigquery.Client(project=PROJECT_ID)
        
        # åé›†ãƒ‡ãƒ¼ã‚¿
        self.collected_channels = []
        self.stats = {
            'searched': 0,
            'filtered': 0,
            'analyzed': 0,
            'saved_firestore': 0,
            'saved_bigquery': 0,
            'errors': 0
        }
    
    def get_famous_search_queries(self) -> List[Dict[str, Any]]:
        """æœ‰åãƒãƒ£ãƒ³ãƒãƒ«åé›†ç”¨ã®æˆ¦ç•¥çš„æ¤œç´¢ã‚¯ã‚¨ãƒª"""
        return [
            # ãƒ¡ã‚¬ç´šYouTuber
            {"queries": ["ãƒ’ã‚«ã‚­ãƒ³", "ã¯ã˜ã‚ã—ã‚ƒã¡ã‚‡ãƒ¼", "ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼ã‚º", "æ±æµ·ã‚ªãƒ³ã‚¨ã‚¢"], "category": "ã‚¨ãƒ³ã‚¿ãƒ¡"},
            {"queries": ["æ°´æºœã‚Šãƒœãƒ³ãƒ‰", "ã™ã—ã‚‰ãƒ¼ã‚ã‚“", "ã‚³ãƒ ãƒ‰ãƒƒãƒˆ"], "category": "ã‚¨ãƒ³ã‚¿ãƒ¡"},
            
            # ã‚²ãƒ¼ãƒ ç³»æœ‰åãƒãƒ£ãƒ³ãƒãƒ«  
            {"queries": ["ãƒãƒƒã‚­ãƒ¼", "ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆ å®Ÿæ³", "åŠ è—¤ç´”ä¸€", "ã‚‚ã“ã†"], "category": "ã‚²ãƒ¼ãƒ "},
            {"queries": ["å…„è€…å¼Ÿè€…", "ã‚­ãƒ¨", "ãƒ¬ãƒˆãƒ«ãƒˆ"], "category": "ã‚²ãƒ¼ãƒ "},
            
            # æ–™ç†ãƒ»ã‚°ãƒ«ãƒ¡æœ‰åãƒãƒ£ãƒ³ãƒãƒ«
            {"queries": ["ãƒªãƒ¥ã‚¦ã‚¸ ãƒã‚ºãƒ¬ã‚·ãƒ”", "ãã¾ãã‚Œã‚¯ãƒƒã‚¯", "è°·ã‚„ã‚“", "æ–™ç†ç ”ç©¶å®¶"], "category": "æ–™ç†"},
            {"queries": ["å¤§é£Ÿã„", "æœ¨ä¸‹ã‚†ã†ã‹", "å¤§èƒƒç‹"], "category": "æ–™ç†"},
            
            # ç¾å®¹ãƒ»ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³
            {"queries": ["ä½ã€…æœ¨ã‚ã•ã²", "ç¾å®¹ç³»", "ãƒ¡ã‚¤ã‚¯", "ã‚¹ã‚­ãƒ³ã‚±ã‚¢"], "category": "ç¾å®¹"},
            {"queries": ["ã‚³ã‚¹ãƒ¡ ãƒ¬ãƒ“ãƒ¥ãƒ¼", "åŒ–ç²§å“", "ç¾å®¹"], "category": "ç¾å®¹"},
            
            # ãƒ“ã‚¸ãƒã‚¹ãƒ»æ•™è‚²
            {"queries": ["ä¸­ç”°æ•å½¦", "ã‚ªãƒªãƒ©ã‚¸", "ä¸¡å­¦é•·", "æŠ•è³‡"], "category": "æ•™è‚²"},
            {"queries": ["ãƒ“ã‚¸ãƒã‚¹", "å‰¯æ¥­", "èµ·æ¥­", "çµŒæ¸ˆ"], "category": "æ•™è‚²"},
            
            # éŸ³æ¥½ãƒ»ã‚¨ãƒ³ã‚¿ãƒ¡
            {"queries": ["Officialé«­ç”·dism", "ã‚ã„ã¿ã‚‡ã‚“", "ç±³æ´¥ç„å¸«", "YOASOBI"], "category": "éŸ³æ¥½"},
            {"queries": ["æ­Œã£ã¦ã¿ãŸ", "è¸Šã£ã¦ã¿ãŸ", "ãƒœã‚«ãƒ­"], "category": "éŸ³æ¥½"},
            
            # ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼
            {"queries": ["ç€¬æˆ¸å¼˜å¸", "ã‚«ã‚º", "iPhone", "ã‚¬ã‚¸ã‚§ãƒƒãƒˆ"], "category": "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼"},
            {"queries": ["ãƒ¬ãƒ“ãƒ¥ãƒ¼", "é–‹å°", "Apple", "Android"], "category": "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼"},
            
            # ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»VLOG
            {"queries": ["kemio", "å¤å·å„ªé¦™", "é–¢æ ¹ç†æ²™", "ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«"], "category": "ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«"},
            {"queries": ["vlog", "æ—¥å¸¸", "ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³"], "category": "ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«"}
        ]
    
    def extract_emails_from_description(self, description: str) -> List[str]:
        """æ¦‚è¦æ¬„ã‹ã‚‰ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æŠ½å‡º"""
        if not description:
            return []
        
        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'
        emails = re.findall(email_pattern, description)
        return list(set(emails))
    
    def search_famous_channels(self, search_queries: List[str], category: str, max_results: int = 5) -> List[Dict[str, Any]]:
        """æœ‰åãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢"""
        try:
            print(f"ğŸ” {category} æœ‰åãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢é–‹å§‹")
            
            all_channels = []
            channel_ids_seen = set()
            
            for query in search_queries:
                print(f"   æ¤œç´¢ã‚¯ã‚¨ãƒª: '{query}'")
                
                search_response = self.service.search().list(
                    part='snippet',
                    type='channel',
                    q=query,
                    maxResults=max_results,
                    order='relevance',
                    regionCode='JP',
                    relevanceLanguage='ja'
                ).execute()
                
                for item in search_response.get('items', []):
                    channel_id = item['id']['channelId']
                    if channel_id not in channel_ids_seen:
                        channel_ids_seen.add(channel_id)
                        
                        # ã‚µãƒ ãƒã‚¤ãƒ«URLå–å¾—
                        thumbnail_url = None
                        thumbnails = item['snippet'].get('thumbnails', {})
                        if thumbnails:
                            for quality in ['maxres', 'high', 'medium', 'default']:
                                if quality in thumbnails:
                                    thumbnail_url = thumbnails[quality].get('url')
                                    break
                        
                        channel_data = {
                            'channel_id': channel_id,
                            'title': item['snippet']['title'],
                            'description': item['snippet']['description'],
                            'thumbnail_url': thumbnail_url,
                            'search_query': query,
                            'category': category
                        }
                        all_channels.append(channel_data)
            
            print(f"   âœ… {category}: {len(all_channels)} ãƒãƒ£ãƒ³ãƒãƒ«ç™ºè¦‹")
            self.stats['searched'] += len(all_channels)
            return all_channels
            
        except HttpError as e:
            print(f"âŒ {category} æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            self.stats['errors'] += 1
            return []
        except Exception as e:
            print(f"âŒ {category} æ¤œç´¢å¤±æ•—: {e}")
            self.stats['errors'] += 1
            return []
    
    async def get_channel_details_with_ai(self, channels: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°å–å¾— + AIåˆ†æ"""
        try:
            channel_ids = [ch['channel_id'] for ch in channels]
            print(f"ğŸ“Š {len(channel_ids)} ãƒãƒ£ãƒ³ãƒãƒ«ã®è©³ç´°å–å¾— + AIåˆ†æä¸­...")
            
            # YouTube API ã§ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°å–å¾—
            channels_response = self.service.channels().list(
                part='snippet,statistics,contentDetails',
                id=','.join(channel_ids)
            ).execute()
            
            enhanced_channels = []
            
            for item in channels_response.get('items', []):
                try:
                    snippet = item.get('snippet', {})
                    statistics = item.get('statistics', {})
                    
                    # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—
                    subscriber_count = int(statistics.get('subscriberCount', 0))
                    video_count = int(statistics.get('videoCount', 0))
                    view_count = int(statistics.get('viewCount', 0))
                    
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: 1ä¸‡äººä»¥ä¸Šï¼ˆæœ‰åãƒãƒ£ãƒ³ãƒãƒ«ãªã®ã§ä¸‹é™å¼•ãä¸‹ã’ï¼‰
                    if subscriber_count < 10000:
                        continue
                    
                    # å…ƒã®ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’å–å¾—
                    original_channel = next(ch for ch in channels if ch['channel_id'] == item['id'])
                    category_name = original_channel['category']
                    
                    # ã‚µãƒ ãƒã‚¤ãƒ«URLï¼ˆè©³ç´°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å†å–å¾—ï¼‰
                    thumbnail_url = original_channel.get('thumbnail_url')
                    if not thumbnail_url:
                        thumbnails = snippet.get('thumbnails', {})
                        if thumbnails:
                            for quality in ['maxres', 'high', 'medium', 'default']:
                                if quality in thumbnails:
                                    thumbnail_url = thumbnails[quality].get('url')
                                    break
                    
                    # åŸºæœ¬ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿
                    channel_data = {
                        'channel_id': item['id'],
                        'channel_title': snippet.get('title', ''),
                        'description': snippet.get('description', ''),
                        'subscriber_count': subscriber_count,
                        'video_count': video_count,
                        'view_count': view_count,
                        'country': snippet.get('country', 'JP'),
                        'thumbnail_url': thumbnail_url,
                        'emails': self.extract_emails_from_description(snippet.get('description', '')),
                        'has_contact': len(self.extract_emails_from_description(snippet.get('description', ''))) > 0,
                        'engagement_estimate': round((view_count / video_count / subscriber_count) * 100, 2) if video_count > 0 and subscriber_count > 0 else 0,
                        'collected_at': datetime.now().isoformat(),
                        'collection_method': 'famous_channels_targeted'
                    }
                    
                    # ğŸ¤– AIåˆ†æå®Ÿè¡Œ
                    print(f"ğŸ¤– AIåˆ†æä¸­: {channel_data['channel_title']}")
                    ai_analysis = await self.ai_analyzer.analyze_channel_comprehensive(channel_data)
                    
                    # AIåˆ†æçµæœã‚’çµ±åˆ
                    enhanced_channel = {
                        **channel_data,
                        'ai_analysis': ai_analysis,
                        'category': ai_analysis.get('category_tags', {}).get('primary_category', category_name),
                        'sub_categories': ai_analysis.get('category_tags', {}).get('sub_categories', []),
                        'content_themes': ai_analysis.get('category_tags', {}).get('content_themes', []),
                        'recommended_products': ai_analysis.get('product_matching', {}).get('recommended_products', []),
                        'brand_safety_score': ai_analysis.get('brand_safety', {}).get('overall_safety_score', 0.8),
                        'analysis_confidence': ai_analysis.get('analysis_confidence', 0.5)
                    }
                    
                    enhanced_channels.append(enhanced_channel)
                    self.stats['analyzed'] += 1
                    
                    # çµæœè¡¨ç¤º
                    print(f"âœ… å®Œäº†: {channel_data['channel_title']}")
                    print(f"   ğŸ“Š ç™»éŒ²è€…: {subscriber_count:,}")
                    print(f"   ğŸ¯ ã‚«ãƒ†ã‚´ãƒª: {enhanced_channel['category']}")
                    print(f"   ğŸ›¡ï¸ å®‰å…¨æ€§: {enhanced_channel['brand_safety_score']:.2f}")
                    print(f"   ğŸ“ˆ ä¿¡é ¼åº¦: {enhanced_channel['analysis_confidence']:.2f}")
                    if enhanced_channel['thumbnail_url']:
                        print(f"   ğŸ–¼ï¸ ã‚µãƒ ãƒã‚¤ãƒ«: âœ…")
                    if enhanced_channel['recommended_products']:
                        top_product = enhanced_channel['recommended_products'][0]
                        print(f"   ğŸ’¼ æ¨å¥¨å•†æ: {top_product.get('category', 'N/A')}")
                    print()
                    
                except Exception as e:
                    print(f"âŒ ãƒãƒ£ãƒ³ãƒãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({item.get('id', 'Unknown')}): {e}")
                    self.stats['errors'] += 1
                    continue
            
            self.stats['filtered'] = len(enhanced_channels)
            return enhanced_channels
            
        except HttpError as e:
            print(f"âŒ YouTube API ã‚¨ãƒ©ãƒ¼: {e}")
            self.stats['errors'] += 1
            return []
        except Exception as e:
            print(f"âŒ è©³ç´°å–å¾—å¤±æ•—: {e}")
            self.stats['errors'] += 1
            return []
    
    async def save_to_firestore(self, channels: List[Dict[str, Any]]) -> bool:
        """Firestoreã«ä¿å­˜"""
        try:
            print(f"ğŸ”¥ Firestoreã« {len(channels)} ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ä¿å­˜ä¸­...")
            
            collection_ref = self.firestore_db.collection('influencers')
            
            for i, channel in enumerate(channels, 1):
                try:
                    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª
                    existing_query = collection_ref.where('channel_id', '==', channel['channel_id']).limit(1)
                    existing_docs = list(existing_query.stream())
                    
                    if existing_docs:
                        # æ›´æ–°
                        doc_ref = existing_docs[0].reference
                        doc_ref.update({
                            **channel,
                            'updated_at': datetime.now(timezone.utc).isoformat(),
                            'data_source': 'famous_channels_collection'
                        })
                        print(f"ğŸ”„ æ›´æ–°: {i}. {channel['channel_title']} (ç™»éŒ²è€…: {channel['subscriber_count']:,})")
                    else:
                        # æ–°è¦ä½œæˆ
                        doc_ref = collection_ref.document(channel['channel_id'])
                        doc_ref.set({
                            **channel,
                            'created_at': datetime.now(timezone.utc).isoformat(),
                            'updated_at': datetime.now(timezone.utc).isoformat(),
                            'data_source': 'famous_channels_collection',
                            'status': 'active'
                        })
                        print(f"âœ… æ–°è¦: {i}. {channel['channel_title']} (ç™»éŒ²è€…: {channel['subscriber_count']:,})")
                    
                    self.stats['saved_firestore'] += 1
                    
                except Exception as e:
                    print(f"âŒ Firestoreä¿å­˜ã‚¨ãƒ©ãƒ¼ ({channel.get('channel_title', 'Unknown')}): {e}")
                    self.stats['errors'] += 1
                    continue
            
            print(f"âœ… Firestoreä¿å­˜å®Œäº†: {self.stats['saved_firestore']} ä»¶")
            return True
            
        except Exception as e:
            print(f"âŒ Firestoreä¿å­˜å¤±æ•—: {e}")
            self.stats['errors'] += 1
            return False
    
    async def save_to_bigquery(self, channels: List[Dict[str, Any]]) -> bool:
        """BigQueryã«ä¿å­˜"""
        try:
            print(f"ğŸ—ï¸ BigQueryã« {len(channels)} ãƒãƒ£ãƒ³ãƒãƒ«ã‚’ä¿å­˜ä¸­...")
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«å‚ç…§
            dataset_ref = self.bigquery_client.dataset('infumatch_data')
            table_ref = dataset_ref.table('influencers')
            
            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
            rows_to_insert = []
            for channel in channels:
                try:
                    row = {
                        'influencer_id': channel['channel_id'],
                        'channel_id': channel['channel_id'],
                        'channel_title': channel['channel_title'],
                        'description': channel.get('description', '')[:1000],  # BigQueryåˆ¶é™å¯¾å¿œ
                        'subscriber_count': channel['subscriber_count'],
                        'video_count': channel['video_count'],
                        'view_count': channel['view_count'],
                        'category': channel.get('category', ''),
                        'country': channel.get('country', 'JP'),
                        'language': 'ja',
                        'contact_email': channel['emails'][0] if channel['emails'] else None,
                        'thumbnail_url': channel.get('thumbnail_url'),
                        'ai_analysis_json': json.dumps(channel.get('ai_analysis', {}), ensure_ascii=False),
                        'brand_safety_score': channel.get('brand_safety_score', 0.0),
                        'analysis_confidence': channel.get('analysis_confidence', 0.0),
                        'created_at': datetime.now(timezone.utc),
                        'updated_at': datetime.now(timezone.utc),
                        'is_active': True
                    }
                    rows_to_insert.append(row)
                    
                except Exception as e:
                    print(f"âŒ BigQueryè¡Œå¤‰æ›ã‚¨ãƒ©ãƒ¼ ({channel.get('channel_title', 'Unknown')}): {e}")
                    self.stats['errors'] += 1
                    continue
            
            # ãƒãƒƒãƒæŒ¿å…¥
            errors = self.bigquery_client.insert_rows_json(table_ref, rows_to_insert)
            
            if errors:
                print(f"âŒ BigQueryæŒ¿å…¥ã‚¨ãƒ©ãƒ¼: {errors}")
                self.stats['errors'] += len(errors)
                return False
            else:
                self.stats['saved_bigquery'] = len(rows_to_insert)
                print(f"âœ… BigQueryä¿å­˜æˆåŠŸ: {self.stats['saved_bigquery']} ä»¶")
                return True
                
        except Exception as e:
            print(f"âŒ BigQueryä¿å­˜å¤±æ•—: {e}")
            self.stats['errors'] += 1
            return False
    
    def save_backup_file(self, channels: List[Dict[str, Any]], filename: str = None) -> str:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"famous_japanese_channels_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(channels, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜: {filename}")
            return filename
            
        except Exception as e:
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜å¤±æ•—: {e}")
            return ""
    
    def print_final_stats(self):
        """æœ€çµ‚çµ±è¨ˆè¡¨ç¤º"""
        print("\\n" + "=" * 80)
        print("ğŸ¯ æœ‰åæ—¥æœ¬ãƒãƒ£ãƒ³ãƒãƒ«åé›†å®Œäº†ã‚µãƒãƒªãƒ¼")
        print("=" * 80)
        
        print(f"ğŸ“Š çµ±è¨ˆæƒ…å ±:")
        print(f"  - æ¤œç´¢ç™ºè¦‹: {self.stats['searched']} ãƒãƒ£ãƒ³ãƒãƒ«")
        print(f"  - ãƒ•ã‚£ãƒ«ã‚¿å¾Œ: {self.stats['filtered']} ãƒãƒ£ãƒ³ãƒãƒ«")
        print(f"  - AIåˆ†æå®Œäº†: {self.stats['analyzed']} ãƒãƒ£ãƒ³ãƒãƒ«")
        print(f"  - Firestoreä¿å­˜: {self.stats['saved_firestore']} ãƒãƒ£ãƒ³ãƒãƒ«")
        print(f"  - BigQueryä¿å­˜: {self.stats['saved_bigquery']} ãƒãƒ£ãƒ³ãƒãƒ«")
        print(f"  - ã‚¨ãƒ©ãƒ¼æ•°: {self.stats['errors']}")
        
        if self.collected_channels:
            print(f"\\nğŸ“‹ åé›†ãƒãƒ£ãƒ³ãƒãƒ«æ¦‚è¦:")
            categories = {}
            total_subscribers = 0
            channels_with_thumbnails = 0
            
            for channel in self.collected_channels:
                cat = channel.get('category', 'æœªåˆ†é¡')
                if cat not in categories:
                    categories[cat] = 0
                categories[cat] += 1
                
                total_subscribers += channel.get('subscriber_count', 0)
                if channel.get('thumbnail_url'):
                    channels_with_thumbnails += 1
            
            print(f"  - ç·ç™»éŒ²è€…æ•°: {total_subscribers:,}äºº")
            print(f"  - ã‚µãƒ ãƒã‚¤ãƒ«å–å¾—ç‡: {channels_with_thumbnails}/{len(self.collected_channels)} ({channels_with_thumbnails/len(self.collected_channels)*100:.1f}%)")
            
            print(f"\\nğŸ“‚ ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:")
            for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
                print(f"  - {category}: {count} ãƒãƒ£ãƒ³ãƒãƒ«")
        
        print("\\nğŸ‰ æœ‰åãƒãƒ£ãƒ³ãƒãƒ«åé›†ãƒ»DBä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        print("=" * 80)

    async def collect_famous_channels(self, target_count: int = 30) -> List[Dict[str, Any]]:
        """æœ‰åæ—¥æœ¬ãƒãƒ£ãƒ³ãƒãƒ«åŒ…æ‹¬åé›†"""
        print("ğŸš€ æœ‰åæ—¥æœ¬YouTubeãƒãƒ£ãƒ³ãƒãƒ«åé›†é–‹å§‹")
        print("=" * 80)
        
        print("ğŸ¯ å®Ÿè¡Œå†…å®¹:")
        print("  1. æˆ¦ç•¥çš„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æœ‰åãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢")
        print("  2. ã‚µãƒ ãƒã‚¤ãƒ«ä»˜ãè©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—")
        print("  3. Gemini AIã«ã‚ˆã‚‹åŒ…æ‹¬çš„åˆ†æ")
        print("  4. Firestoreãƒ»BigQueryè‡ªå‹•ä¿å­˜")
        print("  5. å“è³ªç®¡ç†ãƒ»çµ±è¨ˆè¡¨ç¤º")
        print()
        
        # æ¤œç´¢ã‚¯ã‚¨ãƒªå–å¾—
        search_categories = self.get_famous_search_queries()
        
        all_channels = []
        collected_count = 0
        
        for category_data in search_categories:
            if collected_count >= target_count:
                break
                
            queries = category_data["queries"]
            category = category_data["category"]
            
            # ãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢
            found_channels = self.search_famous_channels(queries, category, max_results=3)
            all_channels.extend(found_channels)
            
            collected_count = len(all_channels)
            print(f"   é€²æ—: {collected_count}/{target_count} ãƒãƒ£ãƒ³ãƒãƒ«")
        
        if not all_channels:
            print("âŒ ãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        # ä¸Šä½ãƒãƒ£ãƒ³ãƒãƒ«ã«çµã‚Šè¾¼ã¿
        selected_channels = all_channels[:target_count]
        print(f"\\nğŸ“Š é¸æŠ: {len(selected_channels)} ãƒãƒ£ãƒ³ãƒãƒ«ï¼ˆç›®æ¨™: {target_count}ï¼‰")
        
        # AIåˆ†æä»˜ãè©³ç´°å–å¾—
        enhanced_channels = await self.get_channel_details_with_ai(selected_channels)
        
        if not enhanced_channels:
            print("âŒ æœ‰åŠ¹ãªãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        self.collected_channels = enhanced_channels
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        print(f"\\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜é–‹å§‹...")
        firestore_success = await self.save_to_firestore(enhanced_channels)
        bigquery_success = await self.save_to_bigquery(enhanced_channels)
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜
        backup_file = self.save_backup_file(enhanced_channels)
        
        # çµ±è¨ˆè¡¨ç¤º
        self.print_final_stats()
        
        return enhanced_channels


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    collector = FamousJapaneseChannelCollector()
    
    try:
        # 30ãƒãƒ£ãƒ³ãƒãƒ«åé›†å®Ÿè¡Œ
        channels = await collector.collect_famous_channels(target_count=30)
        
        if channels:
            print(f"\\nğŸ‰ åé›†æˆåŠŸ: {len(channels)} ãƒãƒ£ãƒ³ãƒãƒ«")
            print("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†ï¼")
        else:
            print("\\nâŒ åé›†å¤±æ•—")
            
    except Exception as e:
        print(f"\\nâŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())