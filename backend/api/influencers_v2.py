"""
æ‹¡å¼µç‰ˆã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼API

@description YouTube APIçµ±åˆã¨AIåˆ†ææ©Ÿèƒ½ã‚’å«ã‚€å®Œå…¨ç‰ˆAPI
ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆæ›¸ã®è¦ä»¶ã«å¯¾å¿œ

@author InfuMatch Development Team
@version 2.0.0
"""

import logging
import asyncio
from typing import List, Optional, Dict, Any
from datetime import datetime
from fastapi import APIRouter, Query, HTTPException, BackgroundTasks, Depends
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

from services.youtube_api import YouTubeInfluencerService
from services.batch_processor import YouTubeBatchProcessor
from services.ai_analyzers import IntegratedAIAnalyzer
from core.config import get_settings
from core.database import FirestoreClient, DatabaseHelper, DatabaseCollections

logger = logging.getLogger(__name__)
settings = get_settings()

# APIãƒ«ãƒ¼ã‚¿ãƒ¼
router = APIRouter(prefix="/api/v2", tags=["influencers"])

# ä¾å­˜é–¢ä¿‚
def get_youtube_service():
    return YouTubeInfluencerService()

def get_batch_processor():
    return YouTubeBatchProcessor()

def get_ai_analyzer():
    return IntegratedAIAnalyzer()

def get_db_helper():
    db_client = FirestoreClient()
    return DatabaseHelper(db_client)


# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class InfluencerResponse(BaseModel):
    """ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼æƒ…å ±ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    channel_id: str
    channel_name: str
    description: str
    subscriber_count: int
    video_count: int
    view_count: int
    engagement_rate: float
    thumbnail_url: Optional[str] = None
    country: Optional[str] = None
    
    # AIåˆ†æçµæœ
    category_analysis: Optional[Dict[str, Any]] = None
    email_analysis: Optional[List[Dict[str, Any]]] = None
    trend_analysis: Optional[Dict[str, Any]] = None
    overall_score: Optional[Dict[str, Any]] = None
    
    # é€£çµ¡å¯èƒ½æ€§
    has_business_email: bool = False
    contactability_score: float = 0.0
    
    # ãƒ‡ãƒ¼ã‚¿å“è³ª
    data_quality_score: float = 0.0
    last_analyzed: Optional[str] = None
    fetched_at: str


class SearchRequest(BaseModel):
    """æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    keyword: Optional[str] = Field(None, description="æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
    category: Optional[str] = Field(None, description="ã‚«ãƒ†ã‚´ãƒª")
    min_subscribers: Optional[int] = Field(1000, description="æœ€å°ç™»éŒ²è€…æ•°")
    max_subscribers: Optional[int] = Field(1000000, description="æœ€å¤§ç™»éŒ²è€…æ•°")
    min_engagement: Optional[float] = Field(0.0, description="æœ€å°ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡")
    has_email: Optional[bool] = Field(None, description="ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æœ‰ç„¡")
    min_quality_score: Optional[float] = Field(0.0, description="æœ€å°å“è³ªã‚¹ã‚³ã‚¢")
    sort_by: str = Field("engagement_rate", description="ã‚½ãƒ¼ãƒˆé …ç›®")
    sort_order: str = Field("desc", description="ã‚½ãƒ¼ãƒˆé †")
    limit: int = Field(20, description="å–å¾—ä»¶æ•°")
    offset: int = Field(0, description="ã‚ªãƒ•ã‚»ãƒƒãƒˆ")


class BatchRequest(BaseModel):
    """ãƒãƒƒãƒå‡¦ç†ãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""
    categories: List[str] = Field(default=["beauty", "gaming", "cooking", "tech"])
    max_per_category: int = Field(50, description="ã‚«ãƒ†ã‚´ãƒªã‚ãŸã‚Šæœ€å¤§å–å¾—æ•°")
    subscriber_ranges: Optional[List[List[int]]] = Field(None, description="ç™»éŒ²è€…æ•°ç¯„å›²")


class AnalysisResponse(BaseModel):
    """åˆ†æçµæœãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    channel_id: str
    analysis_timestamp: str
    category_analysis: Dict[str, Any]
    email_analysis: List[Dict[str, Any]]
    trend_analysis: Dict[str, Any]
    overall_score: Dict[str, Any]
    recommendation: str


# API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

@router.get("/influencers/search")
async def search_influencers(
    request: SearchRequest = Depends(),
    db_helper: DatabaseHelper = Depends(get_db_helper)
) -> Dict[str, Any]:
    """
    é«˜åº¦ãªã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼æ¤œç´¢
    
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æ¡ä»¶ã«åˆè‡´ã™ã‚‹ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’æ¤œç´¢
    """
    try:
        logger.info(f"ğŸ” Advanced influencer search: {request.keyword}")
        
        # ã‚¯ã‚¨ãƒªæ¡ä»¶æ§‹ç¯‰
        conditions = []
        
        # ç™»éŒ²è€…æ•°ç¯„å›²
        if request.min_subscribers:
            conditions.append(('subscriber_count', '>=', request.min_subscribers))
        if request.max_subscribers:
            conditions.append(('subscriber_count', '<=', request.max_subscribers))
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡
        if request.min_engagement:
            conditions.append(('engagement_rate', '>=', request.min_engagement))
        
        # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æœ‰ç„¡
        if request.has_email is not None:
            conditions.append(('has_business_email', '==', request.has_email))
        
        # å“è³ªã‚¹ã‚³ã‚¢
        if request.min_quality_score:
            conditions.append(('data_quality_score', '>=', request.min_quality_score))
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹
        conditions.append(('status', '==', 'active'))
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¤œç´¢å®Ÿè¡Œ
        results = await db_helper.query_documents(
            collection=DatabaseCollections.INFLUENCERS,
            conditions=conditions,
            limit=request.limit + request.offset,  # ã‚ªãƒ•ã‚»ãƒƒãƒˆè€ƒæ…®
            order_by=(request.sort_by, request.sort_order)
        )
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ•ã‚£ãƒ«ã‚¿ï¼‰
        if request.keyword:
            keyword_lower = request.keyword.lower()
            filtered_results = []
            for result in results:
                if (keyword_lower in result.get('channel_name', '').lower() or
                    keyword_lower in result.get('description', '').lower()):
                    filtered_results.append(result)
            results = filtered_results
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚£ãƒ«ã‚¿
        if request.category and request.category != "all":
            results = [
                r for r in results 
                if r.get('category_analysis', {}).get('main_category') == request.category
            ]
        
        # ãƒšãƒ¼ã‚¸ãƒ³ã‚°
        total_count = len(results)
        paginated_results = results[request.offset:request.offset + request.limit]
        
        return {
            "results": paginated_results,
            "total_count": total_count,
            "page_info": {
                "limit": request.limit,
                "offset": request.offset,
                "has_next": request.offset + request.limit < total_count
            },
            "search_params": request.dict()
        }
        
    except Exception as e:
        logger.error(f"âŒ Search failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/influencers/{channel_id}")
async def get_influencer_detail(
    channel_id: str,
    include_analysis: bool = Query(True, description="AIåˆ†æçµæœã‚’å«ã‚ã‚‹"),
    db_helper: DatabaseHelper = Depends(get_db_helper)
) -> InfluencerResponse:
    """
    ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼è©³ç´°æƒ…å ±å–å¾—
    """
    try:
        logger.info(f"ğŸ“Š Getting influencer details: {channel_id}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å–å¾—
        influencer = await db_helper.get_document(
            collection=DatabaseCollections.INFLUENCERS,
            document_id=channel_id
        )
        
        if not influencer:
            raise HTTPException(status_code=404, detail="Influencer not found")
        
        # AIåˆ†æçµæœã‚’é™¤å¤–ã™ã‚‹å ´åˆ
        if not include_analysis:
            for key in ['category_analysis', 'email_analysis', 'trend_analysis', 'overall_score']:
                influencer.pop(key, None)
        
        return InfluencerResponse(**influencer)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Failed to get influencer details: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/influencers/discover")
async def discover_new_influencers(
    search_queries: List[str],
    background_tasks: BackgroundTasks,
    min_subscribers: int = Query(1000, description="æœ€å°ç™»éŒ²è€…æ•°"),
    max_subscribers: int = Query(100000, description="æœ€å¤§ç™»éŒ²è€…æ•°"),
    max_per_query: int = Query(20, description="ã‚¯ã‚¨ãƒªã‚ãŸã‚Šæœ€å¤§å–å¾—æ•°"),
    youtube_service: YouTubeInfluencerService = Depends(get_youtube_service)
) -> Dict[str, Any]:
    """
    æ–°è¦ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ç™ºè¦‹
    
    YouTube API ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’ç™ºè¦‹
    """
    try:
        logger.info(f"ğŸ” Discovering influencers for queries: {search_queries}")
        
        # ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ç™ºè¦‹ã‚’å®Ÿè¡Œ
        discovered = await youtube_service.discover_influencers(
            search_queries=search_queries,
            subscriber_min=min_subscribers,
            subscriber_max=max_subscribers,
            max_per_query=max_per_query
        )
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
        if discovered:
            background_tasks.add_task(
                youtube_service.save_influencers_to_db,
                discovered
            )
        
        return {
            "discovered_count": len(discovered),
            "influencers": discovered[:10],  # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨ã—ã¦æœ€åˆã®10ä»¶
            "status": "discovery_completed",
            "message": f"{len(discovered)}ä»¶ã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ"
        }
        
    except Exception as e:
        logger.error(f"âŒ Discovery failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/influencers/batch-discovery")
async def batch_discover_influencers(
    request: BatchRequest,
    background_tasks: BackgroundTasks,
    batch_processor: YouTubeBatchProcessor = Depends(get_batch_processor)
) -> Dict[str, Any]:
    """
    å¤§è¦æ¨¡ãƒãƒƒãƒã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ç™ºè¦‹
    
    è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã§ã®å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿åé›†
    """
    try:
        logger.info(f"ğŸš€ Starting batch discovery for categories: {request.categories}")
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
        background_tasks.add_task(
            _run_batch_discovery,
            batch_processor,
            request.categories,
            request.subscriber_ranges,
            request.max_per_category
        )
        
        return {
            "status": "batch_started",
            "categories": request.categories,
            "estimated_duration_minutes": len(request.categories) * 5,
            "message": "ãƒãƒƒãƒå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚å®Œäº†ã¾ã§æ•°åˆ†ãŠå¾…ã¡ãã ã•ã„ã€‚"
        }
        
    except Exception as e:
        logger.error(f"âŒ Batch discovery failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/influencers/{channel_id}/analyze")
async def analyze_influencer(
    channel_id: str,
    force_refresh: bool = Query(False, description="å¼·åˆ¶å†åˆ†æ"),
    ai_analyzer: IntegratedAIAnalyzer = Depends(get_ai_analyzer),
    db_helper: DatabaseHelper = Depends(get_db_helper)
) -> AnalysisResponse:
    """
    ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®AIåˆ†æå®Ÿè¡Œ
    """
    try:
        logger.info(f"ğŸ¤– Analyzing influencer: {channel_id}")
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å–å¾—
        influencer = await db_helper.get_document(
            collection=DatabaseCollections.INFLUENCERS,
            document_id=channel_id
        )
        
        if not influencer:
            raise HTTPException(status_code=404, detail="Influencer not found")
        
        # åˆ†ææ¸ˆã¿ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆå¼·åˆ¶å†åˆ†æã§ãªã„å ´åˆï¼‰
        if not force_refresh and influencer.get('category_analysis'):
            last_analyzed = influencer.get('last_analyzed')
            if last_analyzed:
                # 1é€±é–“ä»¥å†…ã«åˆ†ææ¸ˆã¿ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                analyzed_date = datetime.fromisoformat(last_analyzed.replace('Z', '+00:00'))
                if (datetime.utcnow() - analyzed_date.replace(tzinfo=None)).days < 7:
                    return AnalysisResponse(
                        channel_id=channel_id,
                        analysis_timestamp=last_analyzed,
                        category_analysis=influencer.get('category_analysis', {}),
                        email_analysis=influencer.get('email_analysis', []),
                        trend_analysis=influencer.get('trend_analysis', {}),
                        overall_score=influencer.get('overall_score', {}),
                        recommendation=influencer.get('recommendation', '')
                    )
        
        # AIåˆ†æå®Ÿè¡Œ
        analysis_result = await ai_analyzer.comprehensive_analysis(influencer)
        
        # çµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        update_data = {
            'category_analysis': analysis_result.get('category_analysis'),
            'email_analysis': analysis_result.get('email_analysis'),
            'trend_analysis': analysis_result.get('trend_analysis'),
            'overall_score': analysis_result.get('overall_score'),
            'recommendation': analysis_result.get('recommendation'),
            'last_analyzed': analysis_result.get('analysis_timestamp')
        }
        
        await db_helper.update_document(
            collection=DatabaseCollections.INFLUENCERS,
            document_id=channel_id,
            data=update_data
        )
        
        return AnalysisResponse(**analysis_result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Analysis failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analytics/trending")
async def get_trending_analytics(
    region: str = Query("JP", description="åœ°åŸŸã‚³ãƒ¼ãƒ‰"),
    max_results: int = Query(50, description="æœ€å¤§å–å¾—æ•°"),
    batch_processor: YouTubeBatchProcessor = Depends(get_batch_processor)
) -> Dict[str, Any]:
    """
    ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå–å¾—
    """
    try:
        logger.info(f"ğŸ“ˆ Getting trending analytics for {region}")
        
        result = await batch_processor.analyze_trending_channels(
            region=region,
            max_results=max_results
        )
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ Trending analytics failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/analytics/categories")
async def get_category_distribution(
    db_helper: DatabaseHelper = Depends(get_db_helper)
) -> Dict[str, Any]:
    """
    ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒåˆ†æ
    """
    try:
        logger.info("ğŸ“Š Getting category distribution")
        
        # å…¨ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’å–å¾—
        all_influencers = await db_helper.query_documents(
            collection=DatabaseCollections.INFLUENCERS,
            conditions=[('status', '==', 'active')],
            limit=1000
        )
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒè¨ˆç®—
        category_stats = {}
        total_count = len(all_influencers)
        
        for influencer in all_influencers:
            category_analysis = influencer.get('category_analysis', {})
            main_category = category_analysis.get('main_category', 'unknown')
            
            if main_category not in category_stats:
                category_stats[main_category] = {
                    'count': 0,
                    'avg_subscribers': 0,
                    'avg_engagement': 0,
                    'total_subscribers': 0,
                    'total_engagement': 0
                }
            
            stats = category_stats[main_category]
            stats['count'] += 1
            stats['total_subscribers'] += influencer.get('subscriber_count', 0)
            stats['total_engagement'] += influencer.get('engagement_rate', 0)
        
        # å¹³å‡å€¤è¨ˆç®—
        for category, stats in category_stats.items():
            if stats['count'] > 0:
                stats['avg_subscribers'] = stats['total_subscribers'] // stats['count']
                stats['avg_engagement'] = round(stats['total_engagement'] / stats['count'], 2)
                stats['percentage'] = round((stats['count'] / total_count) * 100, 1)
        
        return {
            'total_influencers': total_count,
            'category_distribution': category_stats,
            'analysis_date': datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ Category distribution failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/maintenance/update-analytics")
async def update_influencer_analytics(
    background_tasks: BackgroundTasks,
    batch_size: int = Query(50, description="ãƒãƒƒãƒã‚µã‚¤ã‚º"),
    days_since_update: int = Query(7, description="æ›´æ–°å¯¾è±¡æ—¥æ•°"),
    batch_processor: YouTubeBatchProcessor = Depends(get_batch_processor)
) -> Dict[str, Any]:
    """
    ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼åˆ†æãƒ‡ãƒ¼ã‚¿ã®ä¸€æ‹¬æ›´æ–°
    """
    try:
        logger.info("ğŸ”„ Starting analytics update")
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§æ›´æ–°å®Ÿè¡Œ
        background_tasks.add_task(
            batch_processor.update_existing_influencers,
            batch_size,
            days_since_update
        )
        
        return {
            "status": "update_started",
            "batch_size": batch_size,
            "days_since_update": days_since_update,
            "message": "åˆ†æãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã‚’é–‹å§‹ã—ã¾ã—ãŸ"
        }
        
    except Exception as e:
        logger.error(f"âŒ Analytics update failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯é–¢æ•°

async def _run_batch_discovery(
    batch_processor: YouTubeBatchProcessor,
    categories: List[str],
    subscriber_ranges: Optional[List[List[int]]],
    max_per_category: int
):
    """ãƒãƒƒãƒç™ºè¦‹ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ"""
    try:
        # subscriber_ranges ã®å¤‰æ›
        ranges = None
        if subscriber_ranges:
            ranges = [(r[0], r[1]) for r in subscriber_ranges]
        
        result = await batch_processor.discover_influencers_batch(
            categories=categories,
            subscriber_ranges=ranges,
            max_per_category=max_per_category
        )
        
        logger.info(f"âœ… Batch discovery completed: {result}")
        
    except Exception as e:
        logger.error(f"âŒ Background batch discovery failed: {e}")


# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
@router.get("/health")
async def health_check():
    """APIãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "2.0.0"
    }