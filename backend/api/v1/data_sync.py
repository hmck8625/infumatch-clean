"""
ãƒ‡ãƒ¼ã‚¿åŒæœŸ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

@description Firestore â†” BigQuery ãƒ‡ãƒ¼ã‚¿åŒæœŸã®ç®¡ç†API
æ‰‹å‹•åŒæœŸã€è‡ªå‹•åŒæœŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã€åŒæœŸçŠ¶æ³ç¢ºèªæ©Ÿèƒ½ã‚’æä¾›

@author InfuMatch Development Team  
@version 1.0.0
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timezone, timedelta
import pandas as pd

from fastapi import APIRouter, HTTPException, BackgroundTasks, Query, Depends
from pydantic import BaseModel, Field

from services.data_integration import get_data_integration_service, run_daily_sync
from core.bigquery_client import get_bigquery_analytics
from core.config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()

router = APIRouter()


# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«
class SyncResultModel(BaseModel):
    """åŒæœŸçµæœã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    success: bool = Field(..., description="åŒæœŸæˆåŠŸãƒ•ãƒ©ã‚°")
    synced_count: int = Field(..., description="åŒæœŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°")
    failed_count: int = Field(0, description="å¤±æ•—ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°")
    duration_seconds: float = Field(..., description="å‡¦ç†æ™‚é–“ï¼ˆç§’ï¼‰")
    errors: List[str] = Field(default_factory=list, description="ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆ")
    completed_at: str = Field(..., description="å®Œäº†æ™‚åˆ»")


class SyncStatusModel(BaseModel):
    """åŒæœŸçŠ¶æ³ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    last_sync_time: Optional[str] = Field(None, description="æœ€çµ‚åŒæœŸæ™‚åˆ»")
    next_scheduled_sync: Optional[str] = Field(None, description="æ¬¡å›äºˆå®šåŒæœŸæ™‚åˆ»")
    sync_frequency: str = Field("daily", description="åŒæœŸé »åº¦")
    total_records_synced: int = Field(0, description="ç´¯è¨ˆåŒæœŸãƒ¬ã‚³ãƒ¼ãƒ‰æ•°")
    recent_sync_results: List[SyncResultModel] = Field(default_factory=list, description="æœ€è¿‘ã®åŒæœŸçµæœ")


class MetricsModel(BaseModel):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«"""
    date: str = Field(..., description="å¯¾è±¡æ—¥ä»˜")
    total_influencers: int = Field(0, description="ç·ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼æ•°")
    active_campaigns: int = Field(0, description="ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³æ•°")
    completed_negotiations: int = Field(0, description="å®Œäº†äº¤æ¸‰æ•°")
    total_revenue: float = Field(0.0, description="ç·å£²ä¸Š")
    avg_engagement_rate: float = Field(0.0, description="å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡")


# ä¾å­˜æ€§æ³¨å…¥
def get_data_integration() -> Any:
    """ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚µãƒ¼ãƒ“ã‚¹ã®ä¾å­˜æ€§æ³¨å…¥"""
    return get_data_integration_service()


@router.post("/sync/full", response_model=SyncResultModel, tags=["Data Sync"])
async def trigger_full_sync(
    background_tasks: BackgroundTasks,
    integration_service: Any = Depends(get_data_integration)
) -> SyncResultModel:
    """
    å®Œå…¨ãƒ‡ãƒ¼ã‚¿åŒæœŸã®æ‰‹å‹•å®Ÿè¡Œ
    
    Firestoreã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’BigQueryã«åŒæœŸã—ã¾ã™ã€‚
    ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
    """
    try:
        logger.info("ğŸ”„ Manual full sync triggered")
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§åŒæœŸå®Ÿè¡Œ
        start_time = datetime.now(timezone.utc)
        result = await integration_service.full_sync()
        
        return SyncResultModel(
            success=result.get('success', False),
            synced_count=result.get('total_synced', 0),
            failed_count=result.get('total_failed', 0),
            duration_seconds=result.get('duration_seconds', 0),
            errors=result.get('errors', []),
            completed_at=result.get('completed_at', start_time.isoformat())
        )
        
    except Exception as e:
        logger.error(f"âŒ Full sync failed: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Full sync failed: {str(e)}"
        )


@router.post("/sync/influencers", response_model=SyncResultModel, tags=["Data Sync"])
async def sync_influencers(
    batch_size: int = Query(100, description="ãƒãƒƒãƒã‚µã‚¤ã‚º", ge=1, le=1000),
    integration_service: Any = Depends(get_data_integration)
) -> SyncResultModel:
    """
    ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åŒæœŸ
    
    Firestoreã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’BigQueryã«åŒæœŸã—ã¾ã™ã€‚
    """
    try:
        logger.info(f"ğŸ”„ Influencer sync triggered (batch_size: {batch_size})")
        
        start_time = datetime.now(timezone.utc)
        result = await integration_service.sync_influencers_to_bigquery(batch_size=batch_size)
        end_time = datetime.now(timezone.utc)
        
        duration = (end_time - start_time).total_seconds()
        
        return SyncResultModel(
            success=result.get('error') is None,
            synced_count=result.get('synced_count', 0),
            failed_count=result.get('failed_count', 0),
            duration_seconds=duration,
            errors=[result['error']] if result.get('error') else [],
            completed_at=end_time.isoformat()
        )
        
    except Exception as e:
        logger.error(f"âŒ Influencer sync failed: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Influencer sync failed: {str(e)}"
        )


@router.post("/sync/campaigns", response_model=SyncResultModel, tags=["Data Sync"])
async def sync_campaigns(
    batch_size: int = Query(100, description="ãƒãƒƒãƒã‚µã‚¤ã‚º", ge=1, le=1000),
    integration_service: Any = Depends(get_data_integration)
) -> SyncResultModel:
    """
    ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã®åŒæœŸ
    
    Firestoreã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’BigQueryã«åŒæœŸã—ã¾ã™ã€‚
    """
    try:
        logger.info(f"ğŸ”„ Campaign sync triggered (batch_size: {batch_size})")
        
        start_time = datetime.now(timezone.utc)
        result = await integration_service.sync_campaigns_to_bigquery(batch_size=batch_size)
        end_time = datetime.now(timezone.utc)
        
        duration = (end_time - start_time).total_seconds()
        
        return SyncResultModel(
            success=result.get('error') is None,
            synced_count=result.get('synced_count', 0),
            failed_count=result.get('failed_count', 0),
            duration_seconds=duration,
            errors=[result['error']] if result.get('error') else [],
            completed_at=end_time.isoformat()
        )
        
    except Exception as e:
        logger.error(f"âŒ Campaign sync failed: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Campaign sync failed: {str(e)}"
        )


@router.post("/metrics/generate", response_model=SyncResultModel, tags=["Data Sync"])
async def generate_daily_metrics(
    target_date: Optional[str] = Query(None, description="å¯¾è±¡æ—¥ä»˜ (YYYY-MM-DDå½¢å¼)"),
    integration_service: Any = Depends(get_data_integration)
) -> SyncResultModel:
    """
    æ—¥æ¬¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç”Ÿæˆ
    
    æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ï¼ˆã¾ãŸã¯å‰æ—¥ï¼‰ã®æ—¥æ¬¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç”Ÿæˆã—ã¦BigQueryã«ä¿å­˜ã—ã¾ã™ã€‚
    """
    try:
        # æ—¥ä»˜ãƒ‘ãƒ¼ã‚¹
        if target_date:
            try:
                parsed_date = datetime.fromisoformat(target_date).replace(tzinfo=timezone.utc)
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail="Invalid date format. Use YYYY-MM-DD format."
                )
        else:
            parsed_date = None
        
        logger.info(f"ğŸ“Š Daily metrics generation triggered for {target_date or 'yesterday'}")
        
        start_time = datetime.now(timezone.utc)
        result = await integration_service.generate_daily_metrics(target_date=parsed_date)
        end_time = datetime.now(timezone.utc)
        
        duration = (end_time - start_time).total_seconds()
        
        return SyncResultModel(
            success=result.get('success', False),
            synced_count=result.get('metrics_generated', 0),
            failed_count=0,
            duration_seconds=duration,
            errors=[result['error']] if result.get('error') else [],
            completed_at=end_time.isoformat()
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Daily metrics generation failed: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Daily metrics generation failed: {str(e)}"
        )


@router.get("/sync/status", response_model=SyncStatusModel, tags=["Data Sync"])
async def get_sync_status() -> SyncStatusModel:
    """
    ãƒ‡ãƒ¼ã‚¿åŒæœŸã®çŠ¶æ³ç¢ºèª
    
    æœ€çµ‚åŒæœŸæ™‚åˆ»ã€æ¬¡å›äºˆå®šã€ç´¯è¨ˆçµ±è¨ˆãªã©ã®åŒæœŸçŠ¶æ³ã‚’è¿”ã—ã¾ã™ã€‚
    """
    try:
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Firestoreã¾ãŸã¯åˆ¥ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰åŒæœŸå±¥æ­´ã‚’å–å¾—
        # ç¾åœ¨ã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        
        return SyncStatusModel(
            last_sync_time=(datetime.now(timezone.utc) - timedelta(hours=1)).isoformat(),
            next_scheduled_sync=(datetime.now(timezone.utc) + timedelta(hours=23)).isoformat(),
            sync_frequency="daily",
            total_records_synced=1500,
            recent_sync_results=[
                SyncResultModel(
                    success=True,
                    synced_count=150,
                    failed_count=0,
                    duration_seconds=45.3,
                    errors=[],
                    completed_at=(datetime.now(timezone.utc) - timedelta(hours=1)).isoformat()
                )
            ]
        )
        
    except Exception as e:
        logger.error(f"âŒ Failed to get sync status: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get sync status: {str(e)}"
        )


@router.get("/analytics/overview", response_model=List[MetricsModel], tags=["Analytics"])
async def get_analytics_overview(
    days: int = Query(7, description="å–å¾—æ—¥æ•°", ge=1, le=365)
) -> List[MetricsModel]:
    """
    åˆ†æãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦å–å¾—
    
    éå»Næ—¥é–“ã®æ—¥æ¬¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—ã—ã¾ã™ã€‚
    """
    try:
        analytics = get_bigquery_analytics()
        
        # BigQueryã‹ã‚‰æ—¥æ¬¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å–å¾—
        df = analytics.get_daily_metrics_summary(days=days)
        
        if df.empty:
            return []
        
        # DataFrameã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        metrics = []
        for _, row in df.iterrows():
            metrics.append(MetricsModel(
                date=str(row['date']),
                total_influencers=int(row['total_influencers']) if pd.notna(row['total_influencers']) else 0,
                active_campaigns=int(row['active_campaigns']) if pd.notna(row['active_campaigns']) else 0,
                completed_negotiations=int(row['completed_negotiations']) if pd.notna(row['completed_negotiations']) else 0,
                total_revenue=float(row['daily_revenue']) if pd.notna(row['daily_revenue']) else 0.0,
                avg_engagement_rate=float(row['platform_engagement_rate']) if pd.notna(row['platform_engagement_rate']) else 0.0
            ))
        
        return metrics
        
    except Exception as e:
        logger.error(f"âŒ Failed to get analytics overview: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get analytics overview: {str(e)}"
        )


@router.get("/analytics/categories", tags=["Analytics"])
async def get_category_performance():
    """
    ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    
    å„ã‚«ãƒ†ã‚´ãƒªã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼æ•°ã€å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ãªã©ã‚’è¿”ã—ã¾ã™ã€‚
    """
    try:
        analytics = get_bigquery_analytics()
        
        # BigQueryã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        df = analytics.get_category_performance()
        
        if df.empty:
            return {"categories": []}
        
        # DataFrameã‚’è¾æ›¸ã«å¤‰æ›
        categories = []
        for _, row in df.iterrows():
            categories.append({
                "category": row['category'],
                "influencer_count": int(row['influencer_count']) if pd.notna(row['influencer_count']) else 0,
                "avg_subscribers": float(row['avg_subscribers']) if pd.notna(row['avg_subscribers']) else 0,
                "avg_views": float(row['avg_views']) if pd.notna(row['avg_views']) else 0,
                "avg_engagement": float(row['avg_engagement']) if pd.notna(row['avg_engagement']) else 0
            })
        
        return {"categories": categories}
        
    except Exception as e:
        logger.error(f"âŒ Failed to get category performance: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get category performance: {str(e)}"
        )


@router.get("/analytics/growth-trends", tags=["Analytics"])
async def get_growth_trends(
    days: int = Query(30, description="å–å¾—æ—¥æ•°", ge=1, le=365)
):
    """
    æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    
    ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚
    """
    try:
        analytics = get_bigquery_analytics()
        
        # BigQueryã‹ã‚‰æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        df = analytics.get_influencer_growth_trends(days=days)
        
        if df.empty:
            return {"trends": []}
        
        # ãƒ‡ãƒ¼ã‚¿åŠ å·¥ã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
        trends = []
        for _, row in df.iterrows():
            trends.append({
                "influencer_id": row['influencer_id'],
                "date": str(row['date']),
                "subscriber_growth": int(row['subscriber_growth']) if pd.notna(row['subscriber_growth']) else 0,
                "view_growth": int(row['view_growth']) if pd.notna(row['view_growth']) else 0,
                "engagement_rate": float(row['engagement_rate']) if pd.notna(row['engagement_rate']) else 0,
                "trend_score": float(row['trend_score']) if pd.notna(row['trend_score']) else 0
            })
        
        return {"trends": trends}
        
    except Exception as e:
        logger.error(f"âŒ Failed to get growth trends: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to get growth trends: {str(e)}"
        )


@router.post("/sync/schedule", tags=["Data Sync"])
async def schedule_daily_sync(background_tasks: BackgroundTasks):
    """
    æ—¥æ¬¡åŒæœŸã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
    
    ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿åŒæœŸã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    """
    try:
        logger.info("ğŸ“… Scheduling daily sync task")
        
        # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã¨ã—ã¦å®Ÿè¡Œ
        background_tasks.add_task(run_daily_sync)
        
        return {
            "message": "Daily sync scheduled successfully",
            "scheduled_at": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"âŒ Failed to schedule daily sync: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Failed to schedule daily sync: {str(e)}"
        )


# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
@router.get("/health", tags=["Health"])
async def data_sync_health():
    """
    ãƒ‡ãƒ¼ã‚¿åŒæœŸã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    
    BigQueryã¨Firestoreã®æ¥ç¶šçŠ¶æ³ã‚’ç¢ºèªã—ã¾ã™ã€‚
    """
    try:
        health_status = {
            "status": "healthy",
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "services": {}
        }
        
        # Firestoreã®æ¥ç¶šç¢ºèª
        try:
            from core.database import get_firestore_client
            firestore_client = get_firestore_client()
            # ç°¡å˜ãªã‚¯ã‚¨ãƒªã§ãƒ†ã‚¹ãƒˆ
            test_collection = firestore_client.client.collection('health_check')
            health_status["services"]["firestore"] = "connected"
        except Exception as e:
            health_status["services"]["firestore"] = f"error: {str(e)}"
            health_status["status"] = "degraded"
        
        # BigQueryã®æ¥ç¶šç¢ºèª
        try:
            bigquery_client = get_bigquery_client()
            # ç°¡å˜ãªã‚¯ã‚¨ãƒªã§ãƒ†ã‚¹ãƒˆ
            query = f"SELECT 1 as test_value"
            result = list(bigquery_client.query(query))
            health_status["services"]["bigquery"] = "connected"
        except Exception as e:
            health_status["services"]["bigquery"] = f"error: {str(e)}"
            health_status["status"] = "degraded"
        
        return health_status
        
    except Exception as e:
        logger.error(f"âŒ Health check failed: {str(e)}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }