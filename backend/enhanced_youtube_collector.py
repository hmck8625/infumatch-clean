#!/usr/bin/env python3
"""
AIåˆ†æçµ±åˆYouTubeåé›†ã‚·ã‚¹ãƒ†ãƒ 

@description ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§AIåˆ†æã‚’å®Ÿè¡Œ
- ã‚«ãƒ†ã‚´ãƒªã‚¿ã‚°è‡ªå‹•ä»˜ä¸
- ãƒãƒ£ãƒ³ãƒãƒ«æ¦‚è¦ã®æ§‹é€ åŒ– 
- å•†æãƒãƒƒãƒãƒ³ã‚°åˆ†æ

@author InfuMatch Development Team
@version 2.0.0
"""

import os
import json
import asyncio
import re
from datetime import datetime
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# AIåˆ†æã‚µãƒ¼ãƒ“ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.ai_channel_analyzer import AdvancedChannelAnalyzer

# è¨­å®š
YOUTUBE_API_KEY = "AIzaSyDtPl5WSRdxk744ha5Tlwno4iTBZVO96r4"
PROJECT_ID = "hackathon-462905"


class EnhancedYouTubeCollector:
    """
    AIåˆ†æçµ±åˆYouTubeãƒ‡ãƒ¼ã‚¿åé›†ã‚¯ãƒ©ã‚¹
    
    ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨åŒæ™‚ã«AIåˆ†æã‚’å®Ÿè¡Œã—ã€
    é«˜ä»˜åŠ ä¾¡å€¤ãªã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    """
    
    def __init__(self, api_key):
        self.api_key = api_key
        self.service = build('youtube', 'v3', developerKey=api_key)
        self.ai_analyzer = AdvancedChannelAnalyzer()
        self.collected_data = []
    
    def extract_emails_from_description(self, description):
        """æ¦‚è¦æ¬„ã‹ã‚‰ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æŠ½å‡º"""
        if not description:
            return []
        
        email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'
        emails = re.findall(email_pattern, description)
        return list(set(emails))
    
    def search_channels_by_keywords(self, search_queries, max_results=5):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢"""
        try:
            print(f"ğŸ” AIåˆ†æçµ±åˆãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢é–‹å§‹")
            
            all_channels = []
            channel_ids_seen = set()
            
            for query in search_queries:
                print(f"   æ¤œç´¢ã‚¯ã‚¨ãƒª: '{query}'")
                
                search_response = self.service.search().list(
                    part='snippet',
                    type='channel',
                    q=query,
                    maxResults=max_results,
                    order='relevance',
                    regionCode='JP',
                    relevanceLanguage='ja'
                ).execute()
                
                for item in search_response.get('items', []):
                    channel_id = item['id']['channelId']
                    if channel_id not in channel_ids_seen:
                        channel_ids_seen.add(channel_id)
                        channel_data = {
                            'channel_id': channel_id,
                            'title': item['snippet']['title'],
                            'description': item['snippet']['description'],
                            'thumbnail': item['snippet']['thumbnails'].get('high', {}).get('url'),
                            'search_query': query
                        }
                        all_channels.append(channel_data)
            
            print(f"   âœ… ç™ºè¦‹: {len(all_channels)} ãƒãƒ£ãƒ³ãƒãƒ«")
            return all_channels
            
        except HttpError as e:
            print(f"âŒ YouTube API ã‚¨ãƒ©ãƒ¼: {e}")
            return []
        except Exception as e:
            print(f"âŒ æ¤œç´¢å¤±æ•—: {e}")
            return []
    
    async def get_channel_details_with_ai(self, channels):
        """ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°å–å¾— + AIåˆ†æ"""
        try:
            channel_ids = [ch['channel_id'] for ch in channels]
            print(f"ğŸ“Š {len(channel_ids)} ãƒãƒ£ãƒ³ãƒãƒ«ã®è©³ç´°å–å¾— + AIåˆ†æä¸­...")
            
            # YouTube API ã§ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°å–å¾—
            channels_response = self.service.channels().list(
                part='snippet,statistics,contentDetails',
                id=','.join(channel_ids)
            ).execute()
            
            enhanced_channels = []
            
            for item in channels_response.get('items', []):
                try:
                    snippet = item.get('snippet', {})
                    statistics = item.get('statistics', {})
                    
                    # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—
                    subscriber_count = int(statistics.get('subscriberCount', 0))
                    video_count = int(statistics.get('videoCount', 0))
                    view_count = int(statistics.get('viewCount', 0))
                    
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: 1ä¸‡ã€œ50ä¸‡äºº
                    if not (10000 <= subscriber_count <= 500000):
                        continue
                    
                    # ã‚µãƒ ãƒã‚¤ãƒ«URLå–å¾—
                    thumbnail_url = None
                    thumbnails = snippet.get('thumbnails', {})
                    if thumbnails:
                        # é«˜ç”»è³ªã‹ã‚‰é †ã«å–å¾—ã‚’è©¦ã¿ã‚‹
                        for quality in ['maxres', 'high', 'medium', 'default']:
                            if quality in thumbnails:
                                thumbnail_url = thumbnails[quality].get('url')
                                break
                    
                    # åŸºæœ¬ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿
                    channel_data = {
                        'channel_id': item['id'],
                        'channel_title': snippet.get('title', ''),
                        'description': snippet.get('description', ''),
                        'subscriber_count': subscriber_count,
                        'video_count': video_count,
                        'view_count': view_count,
                        'country': snippet.get('country', 'JP'),
                        'thumbnail_url': thumbnail_url,
                        'emails': self.extract_emails_from_description(snippet.get('description', '')),
                        'has_contact': len(self.extract_emails_from_description(snippet.get('description', ''))) > 0,
                        'engagement_estimate': round((view_count / video_count / subscriber_count) * 100, 2) if video_count > 0 and subscriber_count > 0 else 0,
                        'collected_at': datetime.now().isoformat()
                    }
                    
                    # ğŸ¤– AIåˆ†æå®Ÿè¡Œ
                    print(f"ğŸ¤– AIåˆ†æä¸­: {channel_data['channel_title']}")
                    ai_analysis = await self.ai_analyzer.analyze_channel_comprehensive(channel_data)
                    
                    # AIåˆ†æçµæœã‚’çµ±åˆ
                    enhanced_channel = {
                        **channel_data,
                        'ai_analysis': ai_analysis,
                        'category': ai_analysis.get('category_tags', {}).get('primary_category', 'æœªåˆ†é¡'),
                        'sub_categories': ai_analysis.get('category_tags', {}).get('sub_categories', []),
                        'content_themes': ai_analysis.get('category_tags', {}).get('content_themes', []),
                        'recommended_products': ai_analysis.get('product_matching', {}).get('recommended_products', []),
                        'brand_safety_score': ai_analysis.get('brand_safety', {}).get('overall_safety_score', 0.8),
                        'analysis_confidence': ai_analysis.get('analysis_confidence', 0.5)
                    }
                    
                    enhanced_channels.append(enhanced_channel)
                    
                    # çµæœè¡¨ç¤º
                    print(f"âœ… å®Œäº†: {channel_data['channel_title']}")
                    print(f"   ğŸ“Š ç™»éŒ²è€…: {subscriber_count:,}")
                    print(f"   ğŸ¯ ã‚«ãƒ†ã‚´ãƒª: {enhanced_channel['category']}")
                    print(f"   ğŸ›¡ï¸ å®‰å…¨æ€§: {enhanced_channel['brand_safety_score']:.2f}")
                    print(f"   ğŸ“ˆ ä¿¡é ¼åº¦: {enhanced_channel['analysis_confidence']:.2f}")
                    if enhanced_channel['recommended_products']:
                        top_product = enhanced_channel['recommended_products'][0]
                        print(f"   ğŸ’¼ æ¨å¥¨å•†æ: {top_product.get('category', 'N/A')}")
                    print()
                    
                except Exception as e:
                    print(f"âŒ ãƒãƒ£ãƒ³ãƒãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({item.get('id', 'Unknown')}): {e}")
                    continue
            
            return enhanced_channels
            
        except HttpError as e:
            print(f"âŒ YouTube API ã‚¨ãƒ©ãƒ¼: {e}")
            return []
        except Exception as e:
            print(f"âŒ è©³ç´°å–å¾—å¤±æ•—: {e}")
            return []
    
    async def collect_ai_enhanced_channels(self, search_queries, target_count=10):
        """AIåˆ†æçµ±åˆãƒãƒ£ãƒ³ãƒãƒ«åé›†"""
        print("ğŸš€ AIåˆ†æçµ±åˆYouTuberãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
        print("=" * 80)
        
        print("ğŸ”§ å®Ÿè¡Œå†…å®¹:")
        print("  1. YouTube APIã§ãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢")
        print("  2. åŸºæœ¬ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
        print("  3. Gemini AIã«ã‚ˆã‚‹åŒ…æ‹¬çš„åˆ†æ")
        print("     - ã‚«ãƒ†ã‚´ãƒªã‚¿ã‚°è‡ªå‹•ä»˜ä¸")
        print("     - ãƒãƒ£ãƒ³ãƒãƒ«æ¦‚è¦æ§‹é€ åŒ–")
        print("     - å•†æãƒãƒƒãƒãƒ³ã‚°åˆ†æ")
        print("     - ã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹åˆ†æ")
        print("     - ãƒ–ãƒ©ãƒ³ãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è©•ä¾¡")
        print()
        
        # ãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢
        all_channels = self.search_channels_by_keywords(search_queries, max_results=5)
        
        if not all_channels:
            print("âŒ ãƒãƒ£ãƒ³ãƒãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        # AIåˆ†æä»˜ãè©³ç´°å–å¾—
        enhanced_channels = await self.get_channel_details_with_ai(all_channels)
        
        # çµæœã‚’åˆ¶é™
        self.collected_data = enhanced_channels[:target_count]
        
        # çµæœè¡¨ç¤º
        self.print_enhanced_results()
        
        return self.collected_data
    
    def print_enhanced_results(self):
        """AIåˆ†æçµæœã‚’å«ã‚€è©³ç´°è¡¨ç¤º"""
        if not self.collected_data:
            print("âŒ åé›†ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print("\\n" + "=" * 100)
        print("ğŸ¯ AIåˆ†æçµ±åˆåé›†çµæœ")
        print("=" * 100)
        
        total_channels = len(self.collected_data)
        channels_with_email = sum(1 for ch in self.collected_data if ch['has_contact'])
        total_subscribers = sum(ch['subscriber_count'] for ch in self.collected_data)
        avg_confidence = sum(ch['analysis_confidence'] for ch in self.collected_data) / total_channels if total_channels > 0 else 0
        avg_safety = sum(ch['brand_safety_score'] for ch in self.collected_data) / total_channels if total_channels > 0 else 0
        
        print(f"ğŸ“Š çµ±è¨ˆæƒ…å ±:")
        print(f"  - åé›†ãƒãƒ£ãƒ³ãƒãƒ«æ•°: {total_channels}")
        print(f"  - é€£çµ¡å¯èƒ½ãƒãƒ£ãƒ³ãƒãƒ«: {channels_with_email} ({channels_with_email/total_channels*100:.1f}%)")
        print(f"  - ç·ç™»éŒ²è€…æ•°: {total_subscribers:,}")
        print(f"  - å¹³å‡AIä¿¡é ¼åº¦: {avg_confidence:.2f}")
        print(f"  - å¹³å‡ãƒ–ãƒ©ãƒ³ãƒ‰å®‰å…¨æ€§: {avg_safety:.2f}")
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥çµ±è¨ˆ
        categories = {}
        for ch in self.collected_data:
            cat = ch['category']
            if cat not in categories:
                categories[cat] = 0
            categories[cat] += 1
        
        print(f"\\nğŸ“‹ ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:")
        for category, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            print(f"  - {category}: {count}ãƒãƒ£ãƒ³ãƒãƒ«")
        
        print(f"\\nğŸ“‹ è©³ç´°çµæœ:")
        print("-" * 100)
        
        # ä¿¡é ¼åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        sorted_channels = sorted(self.collected_data, key=lambda x: x['analysis_confidence'], reverse=True)
        
        for i, channel in enumerate(sorted_channels, 1):
            print(f"{i:2d}. {channel['channel_title']}")
            print(f"     ğŸ“Š ç™»éŒ²è€…: {channel['subscriber_count']:,}äºº")
            print(f"     ğŸ¯ ã‚«ãƒ†ã‚´ãƒª: {channel['category']}")
            if channel['sub_categories']:
                print(f"     ğŸ·ï¸ ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒª: {', '.join(channel['sub_categories'])}")
            if channel['content_themes']:
                print(f"     ğŸ“ ãƒ†ãƒ¼ãƒ: {', '.join(channel['content_themes'][:3])}")
            print(f"     ğŸ›¡ï¸ å®‰å…¨æ€§: {channel['brand_safety_score']:.2f}")
            print(f"     ğŸ“ˆ AIä¿¡é ¼åº¦: {channel['analysis_confidence']:.2f}")
            
            if channel['recommended_products']:
                top_products = channel['recommended_products'][:2]
                products_str = ', '.join([p.get('category', 'N/A') for p in top_products])
                print(f"     ğŸ’¼ æ¨å¥¨å•†æ: {products_str}")
            
            if channel['emails']:
                print(f"     ğŸ“§ é€£çµ¡å…ˆ: {', '.join(channel['emails'][:1])}")
            print()
        
        print("=" * 100)
        print("ğŸ‰ AIåˆ†æçµ±åˆãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†ï¼")
    
    def save_enhanced_data(self, filename="ai_enhanced_youtubers.json"):
        """AIåˆ†æçµæœã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ä¿å­˜"""
        if not self.collected_data:
            print("âŒ ä¿å­˜ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.collected_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ AIåˆ†æçµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
            # ã‚µãƒãƒªãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä½œæˆ
            summary = {
                "collection_timestamp": datetime.now().isoformat(),
                "total_channels": len(self.collected_data),
                "analysis_summary": {
                    "avg_confidence": sum(ch['analysis_confidence'] for ch in self.collected_data) / len(self.collected_data),
                    "avg_brand_safety": sum(ch['brand_safety_score'] for ch in self.collected_data) / len(self.collected_data),
                    "categories": list(set(ch['category'] for ch in self.collected_data)),
                    "contact_rate": sum(1 for ch in self.collected_data if ch['has_contact']) / len(self.collected_data)
                }
            }
            
            with open('ai_analysis_summary.json', 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼ã‚’ ai_analysis_summary.json ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¤±æ•—: {e}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    collector = EnhancedYouTubeCollector(YOUTUBE_API_KEY)
    
    # ã‚²ãƒ¼ãƒ ç³»ãƒãƒ£ãƒ³ãƒãƒ«æ¤œç´¢ã‚¯ã‚¨ãƒª
    test_queries = [
        "ã‚²ãƒ¼ãƒ å®Ÿæ³",
        "å®Ÿæ³ãƒ—ãƒ¬ã‚¤",
        "ã‚²ãƒ¼ãƒ é…ä¿¡",
        "ãƒã‚¤ãƒ³ã‚¯ãƒ©ãƒ•ãƒˆ å®Ÿæ³",
        "ãƒ•ã‚©ãƒ¼ãƒˆãƒŠã‚¤ãƒˆ å®Ÿæ³",
        "ã‚¨ãƒ¼ãƒšãƒƒã‚¯ã‚¹ å®Ÿæ³",
        "ã‚²ãƒ¼ãƒ æ”»ç•¥",
        "gaming japan",
        "æ—¥æœ¬ ã‚²ãƒ¼ãƒ å®Ÿæ³",
        "ã‚²ãƒ¼ãƒ å®Ÿæ³è€…"
    ]
    
    try:
        print("ğŸ¤– AIåˆ†æçµ±åˆYouTuberåé›†ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 60)
        print("å®Ÿè¡Œå†…å®¹: æ¤œç´¢ â†’ è©³ç´°å–å¾— â†’ AIåˆ†æ â†’ çµæœä¿å­˜")
        print()
        
        # AIåˆ†æä»˜ããƒ‡ãƒ¼ã‚¿åé›†
        channels = await collector.collect_ai_enhanced_channels(test_queries, target_count=33)
        
        if channels:
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            collector.save_enhanced_data()
            
            print(f"\\nâœ… æˆåŠŸ: {len(channels)} ä»¶ã®AIåˆ†ææ¸ˆã¿YouTuberãƒ‡ãƒ¼ã‚¿ã‚’åé›†")
            print("ğŸ“„ çµæœã¯ ai_enhanced_youtubers.json ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            print("ğŸ“Š ã‚µãƒãƒªãƒ¼ã¯ ai_analysis_summary.json ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            
        else:
            print("âŒ ãƒ‡ãƒ¼ã‚¿åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


if __name__ == "__main__":
    asyncio.run(main())