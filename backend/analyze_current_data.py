#!/usr/bin/env python3
"""
ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã®AIåˆ†æçŠ¶æ³ç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

@description ç™»éŒ²æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ai_analysisãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å®Ÿè£…çŠ¶æ³ã‚’ç¢ºèª
å®Ÿéš›ã®AIåˆ†ææ©Ÿèƒ½ã®å‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ

@author InfuMatch Development Team
@version 1.0.0
"""

import json
from google.cloud import firestore, bigquery

def check_ai_analysis_in_databases():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ai_analysiså®Ÿè£…çŠ¶æ³ã‚’ç¢ºèª"""
    print("ğŸ” ç¾åœ¨ã®ai_analysiså®Ÿè£…çŠ¶æ³")
    print("=" * 60)
    
    try:
        # Firestoreç¢ºèª
        print("\nğŸ”¥ Firestore ã®ai_analysis:")
        db = firestore.Client(project="hackathon-462905")
        docs = list(db.collection('influencers').limit(3).stream())
        
        for i, doc in enumerate(docs, 1):
            doc_data = doc.to_dict()
            ai_analysis = doc_data.get('ai_analysis', {})
            
            print(f"\nğŸ“„ ã‚µãƒ³ãƒ—ãƒ« {i}: {doc_data.get('channel_title', 'Unknown')}")
            print(f"   ai_analysis: {ai_analysis}")
            
            # è©³ç´°åˆ†æ
            if ai_analysis:
                for key, value in ai_analysis.items():
                    print(f"     - {key}: {value}")
        
        # BigQueryç¢ºèª
        print(f"\nğŸ—ï¸ BigQuery ã®ai_analysis:")
        client = bigquery.Client(project="hackathon-462905")
        query = """
        SELECT 
            channel_title,
            ai_analysis,
            JSON_EXTRACT_SCALAR(ai_analysis, '$.content_quality_score') as content_quality,
            JSON_EXTRACT_SCALAR(ai_analysis, '$.brand_safety_score') as brand_safety,
            JSON_EXTRACT_SCALAR(ai_analysis, '$.growth_potential') as growth_potential,
            JSON_EXTRACT_SCALAR(ai_analysis, '$.engagement_rate') as engagement_rate
        FROM `hackathon-462905.infumatch_data.influencers`
        LIMIT 3
        """
        
        query_job = client.query(query)
        results = query_job.result()
        
        for i, row in enumerate(results, 1):
            print(f"\nğŸ“Š ã‚µãƒ³ãƒ—ãƒ« {i}: {row.channel_title}")
            print(f"   ai_analysis JSON: {row.ai_analysis}")
            print(f"   content_quality: {row.content_quality}")
            print(f"   brand_safety: {row.brand_safety}")
            print(f"   growth_potential: {row.growth_potential}")
            print(f"   engagement_rate: {row.engagement_rate}")
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

def analyze_ai_analysis_structure():
    """ai_analysisã®ç¾åœ¨ã®æ§‹é€ ã‚’åˆ†æ"""
    print(f"\nğŸ“‹ ç¾åœ¨ã®ai_analysisæ§‹é€ åˆ†æ")
    print("=" * 60)
    
    # ç¾åœ¨ã®å®Ÿè£…
    current_structure = {
        "content_quality_score": {
            "type": "float",
            "range": "0.0-1.0",
            "current_value": 0.8,
            "description": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªã‚¹ã‚³ã‚¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰",
            "implementation": "æœªå®Ÿè£…"
        },
        "brand_safety_score": {
            "type": "float", 
            "range": "0.0-1.0",
            "current_value": 0.9,
            "description": "ãƒ–ãƒ©ãƒ³ãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ã‚¹ã‚³ã‚¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰",
            "implementation": "æœªå®Ÿè£…"
        },
        "growth_potential": {
            "type": "float",
            "range": "0.0-1.0", 
            "current_value": 0.7,
            "description": "æˆé•·ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰",
            "implementation": "æœªå®Ÿè£…"
        },
        "engagement_rate": {
            "type": "float",
            "range": "0.0-âˆ",
            "current_value": "å‹•çš„è¨ˆç®—",
            "description": "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ï¼ˆview_count/video_count/subscriber_count*100ï¼‰",
            "implementation": "å®Ÿè£…æ¸ˆã¿"
        }
    }
    
    print("ğŸ“Š å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®è©³ç´°:")
    for field, details in current_structure.items():
        print(f"\nğŸ”¸ {field}:")
        for key, value in details.items():
            print(f"   {key}: {value}")

def show_available_ai_analyzers():
    """åˆ©ç”¨å¯èƒ½ãªAIåˆ†ææ©Ÿèƒ½ã‚’è¡¨ç¤º"""
    print(f"\nğŸ¤– åˆ©ç”¨å¯èƒ½ãªAIåˆ†ææ©Ÿèƒ½")
    print("=" * 60)
    
    # backend/services/ai_analyzers.py ã‹ã‚‰èª­ã¿å–ã£ãŸæ©Ÿèƒ½
    analyzers = {
        "CategoryAnalyzer": {
            "æ©Ÿèƒ½": "ãƒãƒ£ãƒ³ãƒãƒ«ã‚«ãƒ†ã‚´ãƒªã®è©³ç´°åˆ†æ",
            "AI": "Gemini 1.5 Flash",
            "åˆ†æå†…å®¹": [
                "ä¸»è¦ã‚«ãƒ†ã‚´ãƒªåˆ¤å®šï¼ˆ10ã‚«ãƒ†ã‚´ãƒªï¼‰",
                "ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªç‰¹å®š",
                "ã‚«ãƒ†ã‚´ãƒªä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢",
                "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ†ãƒ¼ãƒåˆ†æ"
            ],
            "å®Ÿè£…çŠ¶æ³": "å®Ÿè£…æ¸ˆã¿ï¼ˆæœªé©ç”¨ï¼‰"
        },
        "TrendAnalyzer": {
            "æ©Ÿèƒ½": "ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã¨ãƒã‚¤ãƒ©ãƒ«äºˆæ¸¬", 
            "AI": "Gemini API",
            "åˆ†æå†…å®¹": [
                "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ",
                "æˆé•·ç‡äºˆæ¸¬",
                "è¦–è´è€…å‹•å‘åˆ†æ",
                "ç«¶åˆåˆ†æ"
            ],
            "å®Ÿè£…çŠ¶æ³": "å®Ÿè£…æ¸ˆã¿ï¼ˆæœªé©ç”¨ï¼‰"
        },
        "IntegratedAIAnalyzer": {
            "æ©Ÿèƒ½": "åŒ…æ‹¬çš„ãªã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼åˆ†æ",
            "AI": "è¤‡æ•°AIãƒ¢ãƒ‡ãƒ«çµ±åˆ",
            "åˆ†æå†…å®¹": [
                "ãƒ–ãƒ©ãƒ³ãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£åˆ¤å®š",
                "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªè©•ä¾¡", 
                "æˆé•·ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«åˆ†æ",
                "ãƒãƒƒãƒãƒ³ã‚°é©æ€§ã‚¹ã‚³ã‚¢"
            ],
            "å®Ÿè£…çŠ¶æ³": "å®Ÿè£…æ¸ˆã¿ï¼ˆæœªé©ç”¨ï¼‰"
        }
    }
    
    for analyzer_name, details in analyzers.items():
        print(f"\nğŸ”§ {analyzer_name}:")
        for key, value in details.items():
            if isinstance(value, list):
                print(f"   {key}:")
                for item in value:
                    print(f"     - {item}")
            else:
                print(f"   {key}: {value}")

def propose_ai_analysis_enhancement():
    """AIåˆ†ææ©Ÿèƒ½ã®å¼·åŒ–æ¡ˆã‚’ææ¡ˆ"""
    print(f"\nğŸ’¡ AIåˆ†ææ©Ÿèƒ½å¼·åŒ–ææ¡ˆ")
    print("=" * 60)
    
    enhancement_plan = {
        "Phase 1": {
            "ç›®æ¨™": "åŸºæœ¬AIåˆ†æã®å®Ÿè£…",
            "æœŸé–“": "1-2æ™‚é–“",
            "å†…å®¹": [
                "CategoryAnalyzerã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¸ã®é©ç”¨",
                "content_quality_scoreã®å®Ÿç®—å‡º",
                "brand_safety_scoreã®å®Ÿç®—å‡º"
            ],
            "æœŸå¾…åŠ¹æœ": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‹ã‚‰å®Ÿéš›ã®åˆ†æå€¤ã¸ã®ç§»è¡Œ"
        },
        "Phase 2": {
            "ç›®æ¨™": "é«˜åº¦åˆ†æã®å®Ÿè£…",
            "æœŸé–“": "2-3æ™‚é–“", 
            "å†…å®¹": [
                "TrendAnalyzerã«ã‚ˆã‚‹æˆé•·äºˆæ¸¬",
                "ç«¶åˆåˆ†ææ©Ÿèƒ½",
                "ãƒãƒƒãƒãƒ³ã‚°é©æ€§ã‚¹ã‚³ã‚¢ç®—å‡º"
            ],
            "æœŸå¾…åŠ¹æœ": "ä¼æ¥­ãƒãƒƒãƒãƒ³ã‚°ã®ç²¾åº¦å‘ä¸Š"
        },
        "Phase 3": {
            "ç›®æ¨™": "ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ",
            "æœŸé–“": "1æ—¥",
            "å†…å®¹": [
                "å®šæœŸçš„ãªåˆ†ææ›´æ–°",
                "ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–ã®æ¤œå‡º",
                "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡"
            ],
            "æœŸå¾…åŠ¹æœ": "å‹•çš„ãªã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼è©•ä¾¡"
        }
    }
    
    for phase, details in enhancement_plan.items():
        print(f"\nğŸ“… {phase}: {details['ç›®æ¨™']}")
        print(f"   æœŸé–“: {details['æœŸé–“']}")
        print(f"   å†…å®¹:")
        for item in details['å†…å®¹']:
            print(f"     - {item}")
        print(f"   æœŸå¾…åŠ¹æœ: {details['æœŸå¾…åŠ¹æœ']}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ”¬ ai_analysis ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 80)
    
    # ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ç¢ºèª
    check_ai_analysis_in_databases()
    
    # æ§‹é€ åˆ†æ
    analyze_ai_analysis_structure()
    
    # åˆ©ç”¨å¯èƒ½æ©Ÿèƒ½è¡¨ç¤º
    show_available_ai_analyzers()
    
    # å¼·åŒ–ææ¡ˆ
    propose_ai_analysis_enhancement()
    
    print(f"\nğŸ¯ çµè«–:")
    print(f"âœ… é«˜åº¦ãªAIåˆ†ææ©Ÿèƒ½ã¯å®Ÿè£…æ¸ˆã¿")
    print(f"âš ï¸ ç¾åœ¨ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ã¿ä½¿ç”¨")
    print(f"ğŸš€ å®Ÿéš›ã®åˆ†æé©ç”¨ã§å¤§å¹…ãªä¾¡å€¤å‘ä¸ŠãŒå¯èƒ½")

if __name__ == "__main__":
    main()