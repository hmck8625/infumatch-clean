"""
AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹

@description å…¨AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…±é€šæ©Ÿèƒ½ã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
Vertex AI ã¨ Google Agentspace ã®çµ±åˆåŸºç›¤

@author InfuMatch Development Team
@version 1.0.0
"""

import logging
import json
import asyncio
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
from dataclasses import dataclass

try:
    import vertexai
    from vertexai.language_models import TextGenerationModel, ChatModel
    from vertexai.generative_models import GenerativeModel
    VERTEX_AVAILABLE = True
except ImportError:
    VERTEX_AVAILABLE = False

import google.generativeai as genai
import google.auth
from google.oauth2 import service_account

from core.config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


@dataclass
class AgentConfig:
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
    
    å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‹•ä½œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©
    """
    
    name: str
    model_name: str = "gemini-1.5-pro"
    temperature: float = 0.7
    max_output_tokens: int = 2048
    top_p: float = 0.9
    top_k: int = 40
    safety_settings: Optional[Dict] = None
    system_instruction: Optional[str] = None
    
    def __post_init__(self):
        """åˆæœŸåŒ–å¾Œå‡¦ç†"""
        if self.safety_settings is None:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å®‰å…¨è¨­å®š
            self.safety_settings = {
                "HARM_CATEGORY_HATE_SPEECH": "BLOCK_MEDIUM_AND_ABOVE",
                "HARM_CATEGORY_DANGEROUS_CONTENT": "BLOCK_MEDIUM_AND_ABOVE",
                "HARM_CATEGORY_SEXUALLY_EXPLICIT": "BLOCK_MEDIUM_AND_ABOVE",
                "HARM_CATEGORY_HARASSMENT": "BLOCK_MEDIUM_AND_ABOVE",
            }


class BaseAgent(ABC):
    """
    AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹
    
    å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å…±é€šæ©Ÿèƒ½ã‚’æä¾›
    - Vertex AI ã®åˆæœŸåŒ–ã¨ç®¡ç†
    - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
    - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    - ãƒ­ã‚°è¨˜éŒ²
    """
    
    def __init__(self, config: AgentConfig):
        """
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–
        
        Args:
            config: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
        """
        self.config = config
        self.model = None
        self.use_vertex = False
        self._initialize_ai()
        
        logger.info(f"ğŸ¤– Initialized agent: {self.config.name}")
    
    def _initialize_ai(self) -> None:
        """AI ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ï¼ˆVertex AI ã¾ãŸã¯ Gemini APIï¼‰"""
        try:
            # ã¾ãšVertex AI ã‚’è©¦è¡Œ
            if VERTEX_AVAILABLE:
                try:
                    self._initialize_vertex_ai()
                    self._initialize_vertex_model()
                    self.use_vertex = True
                    logger.info("âœ… Using Vertex AI")
                    return
                except Exception as e:
                    logger.warning(f"âš ï¸ Vertex AI failed, falling back to Gemini API: {e}")
            
            # Gemini API ã‚’ä½¿ç”¨
            self._initialize_gemini_api()
            logger.info("âœ… Using Gemini API")
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize AI services: {e}")
            raise
    
    def _initialize_vertex_ai(self) -> None:
        """Vertex AI ã®åˆæœŸåŒ–"""
        # èªè¨¼è¨­å®š
        if settings.GOOGLE_APPLICATION_CREDENTIALS and settings.is_development:
            credentials = service_account.Credentials.from_service_account_file(
                settings.GOOGLE_APPLICATION_CREDENTIALS
            )
            vertexai.init(
                project=settings.GOOGLE_CLOUD_PROJECT_ID,
                location=settings.GOOGLE_CLOUD_REGION,
                credentials=credentials
            )
        else:
            vertexai.init(
                project=settings.GOOGLE_CLOUD_PROJECT_ID,
                location=settings.GOOGLE_CLOUD_REGION
            )
    
    def _initialize_vertex_model(self) -> None:
        """Vertex AI ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
        self.model = GenerativeModel(
            model_name=self.config.model_name,
            system_instruction=self.config.system_instruction,
        )
        logger.info(f"âœ… Vertex AI Model {self.config.model_name} initialized")
    
    def _initialize_gemini_api(self) -> None:
        """Gemini API ã®åˆæœŸåŒ–"""
        # API ã‚­ãƒ¼è¨­å®š
        api_key = getattr(settings, 'GEMINI_API_KEY', None)
        if not api_key:
            raise ValueError("GEMINI_API_KEY not found in settings")
        
        genai.configure(api_key=api_key)
        
        # ãƒ¢ãƒ‡ãƒ«åã‚’Gemini APIç”¨ã«å¤‰æ›
        model_name = self.config.model_name
        if model_name.startswith('gemini-1.5-pro'):
            model_name = 'gemini-1.5-pro'
        elif model_name.startswith('gemini-1.5-flash'):
            model_name = 'gemini-1.5-flash'
        
        generation_config = {
            "temperature": self.config.temperature,
            "top_p": self.config.top_p,
            "top_k": self.config.top_k,
            "max_output_tokens": self.config.max_output_tokens,
        }
        
        self.model = genai.GenerativeModel(
            model_name=model_name,
            generation_config=generation_config,
            system_instruction=self.config.system_instruction
        )
        logger.info(f"âœ… Gemini API Model {model_name} initialized")
    
    async def generate_response(
        self,
        prompt: str,
        context: Optional[Dict[str, Any]] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
        
        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            context: è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            **kwargs: è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            
        Returns:
            Dict: ç”Ÿæˆçµæœ
        """
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å‰å‡¦ç†
            formatted_prompt = await self._format_prompt(prompt, context)
            
            # ç”Ÿæˆè¨­å®š
            generation_config = {
                "temperature": kwargs.get("temperature", self.config.temperature),
                "max_output_tokens": kwargs.get("max_output_tokens", self.config.max_output_tokens),
                "top_p": kwargs.get("top_p", self.config.top_p),
                "top_k": kwargs.get("top_k", self.config.top_k),
            }
            
            # AIç”Ÿæˆå®Ÿè¡Œ
            logger.info(f"ğŸ¤– Generating response with {self.config.name}")
            
            if self.use_vertex:
                # Vertex AIä½¿ç”¨
                response = await asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: self.model.generate_content(
                        formatted_prompt,
                        generation_config=generation_config,
                        safety_settings=self.config.safety_settings
                    )
                )
            else:
                # Gemini APIä½¿ç”¨
                response = await asyncio.get_event_loop().run_in_executor(
                    None, 
                    lambda: self.model.generate_content(formatted_prompt)
                )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
            result = await self._process_response(response, context)
            
            logger.info(f"âœ… Response generated successfully by {self.config.name}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Failed to generate response: {e}")
            return {
                "success": False,
                "error": str(e),
                "agent": self.config.name,
                "timestamp": datetime.utcnow().isoformat()
            }
    
    async def _format_prompt(
        self, 
        prompt: str, 
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        
        Args:
            prompt: åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            
        Returns:
            str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        # åŸºæœ¬çš„ãªå‰å‡¦ç†ï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯èƒ½ï¼‰
        formatted = prompt
        
        if context:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¿½åŠ 
            context_str = self._context_to_string(context)
            formatted = f"{context_str}\n\n{prompt}"
        
        return formatted
    
    async def _process_response(
        self, 
        response: Any, 
        context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å¾Œå‡¦ç†
        
        Args:
            response: AIç”Ÿæˆãƒ¬ã‚¹ãƒãƒ³ã‚¹
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
            
        Returns:
            Dict: å‡¦ç†æ¸ˆã¿çµæœ
        """
        try:
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            response_text = response.text if hasattr(response, 'text') else str(response)
            
            # åŸºæœ¬çš„ãªçµæœæ§‹é€ 
            result = {
                "success": True,
                "content": response_text,
                "agent": self.config.name,
                "model": self.config.model_name,
                "timestamp": datetime.utcnow().isoformat(),
                "tokens_used": self._estimate_tokens(response_text),
            }
            
            # å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æƒ…å ±
            if hasattr(response, 'candidates') and response.candidates:
                candidate = response.candidates[0]
                if hasattr(candidate, 'safety_ratings'):
                    result["safety_ratings"] = candidate.safety_ratings
            
            # JSONãƒ‘ãƒ¼ã‚¹ã‚’è©¦è¡Œï¼ˆæ§‹é€ åŒ–å‡ºåŠ›ã®å ´åˆï¼‰
            try:
                parsed_content = json.loads(response_text)
                result["parsed_content"] = parsed_content
                result["content_type"] = "json"
            except (json.JSONDecodeError, ValueError):
                result["content_type"] = "text"
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Failed to process response: {e}")
            return {
                "success": False,
                "error": f"Response processing failed: {str(e)}",
                "agent": self.config.name,
                "timestamp": datetime.utcnow().isoformat()
            }
    
    def _context_to_string(self, context: Dict[str, Any]) -> str:
        """
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¾æ›¸ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        
        Args:
            context: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¾æ›¸
            
        Returns:
            str: æ–‡å­—åˆ—åŒ–ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        """
        context_lines = []
        
        for key, value in context.items():
            if isinstance(value, (dict, list)):
                value_str = json.dumps(value, ensure_ascii=False, indent=2)
            else:
                value_str = str(value)
            
            context_lines.append(f"## {key}:\n{value_str}")
        
        return "\n\n".join(context_lines)
    
    def _estimate_tokens(self, text: str) -> int:
        """
        ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¦‚ç®—
        
        Args:
            text: å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            int: æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°
        """
        # ç°¡æ˜“çš„ãªæ¨å®šï¼ˆæ—¥æœ¬èªã¯æ–‡å­—æ•°ã®ç´„1.5å€ï¼‰
        char_count = len(text)
        estimated_tokens = int(char_count * 1.5) if any('\u3040' <= c <= '\u309F' or '\u30A0' <= c <= '\u30FF' for c in text) else char_count // 4
        return max(estimated_tokens, 1)
    
    @abstractmethod
    async def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰ã®å‡¦ç†ã‚’å®Ÿè¡Œ
        
        Args:
            input_data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        pass
    
    def get_agent_info(self) -> Dict[str, Any]:
        """
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—
        
        Returns:
            Dict: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæƒ…å ±
        """
        return {
            "name": self.config.name,
            "model": self.config.model_name,
            "temperature": self.config.temperature,
            "max_tokens": self.config.max_output_tokens,
            "capabilities": self.get_capabilities(),
            "status": "ready" if self.model else "not_initialized"
        }
    
    @abstractmethod
    def get_capabilities(self) -> List[str]:
        """
        ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æ©Ÿèƒ½ä¸€è¦§ã‚’å–å¾—
        
        Returns:
            List[str]: æ©Ÿèƒ½ãƒªã‚¹ãƒˆ
        """
        pass


class AgentManager:
    """
    ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆç®¡ç†ã‚¯ãƒ©ã‚¹
    
    è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç”Ÿæˆãƒ»ç®¡ç†ãƒ»å”èª¿å‡¦ç†
    """
    
    def __init__(self):
        self.agents: Dict[str, BaseAgent] = {}
        self._initialized = False
    
    async def initialize_agents(self) -> None:
        """å…¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        if self._initialized:
            return
        
        try:
            logger.info("ğŸš€ Initializing AI agents...")
            
            # å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åˆæœŸåŒ–ï¼ˆå¾Œã§å®Ÿè£…ï¼‰
            # self.agents["preprocessor"] = DataPreprocessorAgent(...)
            # self.agents["recommendation"] = RecommendationAgent(...)
            # self.agents["negotiation"] = NegotiationAgent(...)
            
            self._initialized = True
            logger.info("âœ… All agents initialized successfully")
            
        except Exception as e:
            logger.error(f"âŒ Failed to initialize agents: {e}")
            raise
    
    def get_agent(self, agent_name: str) -> Optional[BaseAgent]:
        """
        æŒ‡å®šã•ã‚ŒãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å–å¾—
        
        Args:
            agent_name: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå
            
        Returns:
            Optional[BaseAgent]: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        return self.agents.get(agent_name)
    
    def list_agents(self) -> List[Dict[str, Any]]:
        """
        ç™»éŒ²æ¸ˆã¿ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¸€è¦§ã‚’å–å¾—
        
        Returns:
            List[Dict]: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        return [agent.get_agent_info() for agent in self.agents.values()]
    
    async def process_with_agent(
        self, 
        agent_name: str, 
        input_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        æŒ‡å®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§å‡¦ç†ã‚’å®Ÿè¡Œ
        
        Args:
            agent_name: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå
            input_data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            Dict: å‡¦ç†çµæœ
        """
        agent = self.get_agent(agent_name)
        
        if not agent:
            return {
                "success": False,
                "error": f"Agent '{agent_name}' not found",
                "timestamp": datetime.utcnow().isoformat()
            }
        
        return await agent.process(input_data)


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
agent_manager = AgentManager()