"""
è¿”ä¿¡å†…å®¹é©åˆ‡æ€§åˆ¤å®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ã‚·ãƒ³ãƒ—ãƒ«æ§‹æˆ

@description è¿”ä¿¡å†…å®¹ãŒé©åˆ‡ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
@author InfuMatch Development Team
@version 3.0.0
"""

import logging
import json
from typing import Dict, Any
from datetime import datetime

from ..base_agent import BaseAgent, AgentConfig

logger = logging.getLogger(__name__)


class ContentEvaluationAgent(BaseAgent):
    """
    è¿”ä¿¡å†…å®¹é©åˆ‡æ€§åˆ¤å®šã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    
    æ©Ÿèƒ½:
    - è¿”ä¿¡å†…å®¹ã®é©åˆ‡æ€§åˆ¤å®š
    - ãƒ“ã‚¸ãƒã‚¹ãƒãƒŠãƒ¼ãƒ»è¨€èªé©åˆ‡æ€§ã®è©•ä¾¡
    - ãƒªã‚¹ã‚¯è©•ä¾¡ãƒ»æ³•çš„å•é¡Œã®ãƒã‚§ãƒƒã‚¯
    - æ”¹å–„ææ¡ˆã®ç”Ÿæˆ
    """
    
    def __init__(self):
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        config = AgentConfig(
            name="ContentEvaluationAgent",
            model_name="gemini-1.5-pro",
            temperature=0.1,  # ä¸€è²«æ€§é‡è¦–
            max_output_tokens=1024,
            system_instruction=self._get_evaluation_instruction()
        )
        super().__init__(config)
        self.agent_id = "content_evaluation_agent"
        self.specialization = "Content Quality & Appropriateness Assessment"
        
        logger.info("ğŸ” ContentEvaluationAgent åˆæœŸåŒ–å®Œäº†")
    
    def _get_evaluation_instruction(self) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤ºã‚’å–å¾—"""
        return """
ã‚ãªãŸã¯è¿”ä¿¡å†…å®¹ã®å“è³ªè©•ä¾¡å°‚é–€å®¶ã§ã™ã€‚
ææ¡ˆã•ã‚ŒãŸè¿”ä¿¡å†…å®¹ã‚’å¤šè§’çš„ã«è©•ä¾¡ã—ã€é©åˆ‡æ€§ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

è©•ä¾¡é …ç›®:
1. ãƒ“ã‚¸ãƒã‚¹ãƒãƒŠãƒ¼ãƒ»è¨€èªé©åˆ‡æ€§
2. ç›¸æ‰‹ã®æœŸå¾…ã«å¯¾ã™ã‚‹å›ç­”æ€§
3. ãƒªã‚¹ã‚¯è©•ä¾¡ï¼ˆæ³•çš„ãƒ»ãƒ–ãƒ©ãƒ³ãƒ‰ãƒ»é–¢ä¿‚æ€§ï¼‰
4. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ˜ç¢ºæ€§ãƒ»ä¸€è²«æ€§
5. æ”¹å–„ææ¡ˆ

ç·åˆçš„ãªåˆ¤å®šã‚¹ã‚³ã‚¢ï¼ˆ0.0-1.0ï¼‰ã¨å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
    
    async def evaluate_content(
        self,
        proposed_content: str,
        thread_analysis: Dict[str, Any],
        strategy_plan: Dict[str, Any],
        company_settings: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        è¿”ä¿¡å†…å®¹ã‚’è©•ä¾¡
        
        Args:
            proposed_content: ææ¡ˆã•ã‚ŒãŸè¿”ä¿¡å†…å®¹
            thread_analysis: ã‚¹ãƒ¬ãƒƒãƒ‰åˆ†æçµæœ
            strategy_plan: æˆ¦ç•¥ç«‹æ¡ˆçµæœ
            company_settings: ä¼æ¥­è¨­å®šæƒ…å ±
            
        Returns:
            Dict: è©•ä¾¡çµæœ
        """
        try:
            logger.info("ğŸ” è¿”ä¿¡å†…å®¹è©•ä¾¡é–‹å§‹")
            
            # ä¼æ¥­æƒ…å ±ã‚’æ•´ç†
            company_info = company_settings.get("companyInfo", {})
            products = company_settings.get("products", [])
            
            # è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            evaluation_prompt = f"""
ä»¥ä¸‹ã®è¿”ä¿¡å†…å®¹ã‚’å¤šè§’çš„ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ã€ææ¡ˆã•ã‚ŒãŸè¿”ä¿¡å†…å®¹ã€‘
{proposed_content}

ã€äº¤æ¸‰çŠ¶æ³ã€‘
äº¤æ¸‰æ®µéš: {thread_analysis.get('negotiation_stage', 'ä¸æ˜')}
ç›¸æ‰‹ã®æ„Ÿæƒ…: {thread_analysis.get('sentiment_analysis', {}).get('tone', 'ä¸æ˜')}
ç›¸æ‰‹ã®æ‡¸å¿µ: {', '.join(thread_analysis.get('partner_concerns', []))}
æœŸå¾…ã•ã‚Œã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {thread_analysis.get('next_expected_action', 'ä¸æ˜')}

ã€æˆ¦ç•¥æ–¹é‡ã€‘
åŸºæœ¬ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: {strategy_plan.get('primary_approach', 'ä¸æ˜')}
é‡è¦ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {', '.join(strategy_plan.get('key_messages', []))}
ãƒˆãƒ¼ãƒ³è¨­å®š: {strategy_plan.get('tone_setting', 'ä¸æ˜')}

ã€ä¼æ¥­æƒ…å ±ã€‘
ä¼šç¤¾å: {company_info.get('companyName', 'InfuMatch')}
ä¸»è¦å•†å“: {', '.join([p.get('name', '') for p in products[:3]])}

ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ã—ã€JSONå½¢å¼ã§çµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
{{
    "overall_score": 0.0-1.0,
    "evaluation_details": {{
        "business_manner_score": 0.0-1.0,
        "responsiveness_score": 0.0-1.0,
        "risk_assessment_score": 0.0-1.0,
        "clarity_score": 0.0-1.0,
        "strategy_alignment_score": 0.0-1.0
    }},
    "strengths": ["è‰¯ã„ç‚¹1", "è‰¯ã„ç‚¹2"],
    "concerns": ["æ‡¸å¿µç‚¹1", "æ‡¸å¿µç‚¹2"],
    "improvement_suggestions": ["æ”¹å–„ææ¡ˆ1", "æ”¹å–„ææ¡ˆ2"],
    "risk_flags": ["ãƒªã‚¹ã‚¯é …ç›®1", "ãƒªã‚¹ã‚¯é …ç›®2"],
    "approval_recommendation": "approve|revise|reject",
    "confidence_level": 0.0-1.0,
    "evaluation_reasoning": "è©•ä¾¡ç†ç”±ã®è©³ç´°èª¬æ˜"
}}
"""
            
            # AIè©•ä¾¡ã‚’å®Ÿè¡Œ
            response = await self._generate_response(evaluation_prompt)
            
            # JSONè§£æã‚’è©¦è¡Œ
            try:
                evaluation_result = json.loads(response)
                logger.info("âœ… è¿”ä¿¡å†…å®¹è©•ä¾¡å®Œäº†")
                return evaluation_result
                
            except json.JSONDecodeError:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è©•ä¾¡
                logger.warning("âš ï¸ JSONè§£æå¤±æ•—ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è©•ä¾¡ã‚’å®Ÿè¡Œ")
                return self._create_fallback_evaluation(proposed_content)
                
        except Exception as e:
            logger.error(f"âŒ è¿”ä¿¡å†…å®¹è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return self._create_error_evaluation(str(e))
    
    async def quick_approval_check(
        self,
        proposed_content: str,
        basic_criteria: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        ç°¡æ˜“æ‰¿èªãƒã‚§ãƒƒã‚¯
        
        Args:
            proposed_content: ææ¡ˆã•ã‚ŒãŸè¿”ä¿¡å†…å®¹
            basic_criteria: åŸºæœ¬åˆ¤å®šåŸºæº–
            
        Returns:
            Dict: ç°¡æ˜“è©•ä¾¡çµæœ
        """
        try:
            logger.info("âš¡ ç°¡æ˜“æ‰¿èªãƒã‚§ãƒƒã‚¯é–‹å§‹")
            
            # åŸºæœ¬çš„ãªãƒªã‚¹ã‚¯ãƒã‚§ãƒƒã‚¯
            risk_keywords = [
                "ä¿è¨¼", "ç¢ºç´„", "å¿…ãš", "çµ¶å¯¾", "100%", "ç„¡æ–™", "ã‚¿ãƒ€",
                "æ³•çš„", "è¨´è¨Ÿ", "é•å", "å•é¡Œ", "è‹¦æƒ…"
            ]
            
            content_lower = proposed_content.lower()
            found_risks = [keyword for keyword in risk_keywords if keyword in proposed_content]
            
            # åŸºæœ¬ã‚¹ã‚³ã‚¢è¨ˆç®—
            base_score = 0.8
            if found_risks:
                base_score -= len(found_risks) * 0.1
            
            # å†…å®¹ã®é•·ã•ãƒã‚§ãƒƒã‚¯
            content_length = len(proposed_content)
            if content_length < 50:
                base_score -= 0.2  # çŸ­ã™ãã‚‹
            elif content_length > 1000:
                base_score -= 0.1  # é•·ã™ãã‚‹
            
            approval = "approve" if base_score >= 0.7 else "revise" if base_score >= 0.5 else "reject"
            
            return {
                "quick_score": max(base_score, 0.0),
                "approval_recommendation": approval,
                "risk_flags": found_risks,
                "content_length": content_length,
                "evaluation_type": "quick_check",
                "confidence_level": 0.8
            }
            
        except Exception as e:
            logger.error(f"âŒ ç°¡æ˜“æ‰¿èªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "quick_score": 0.0,
                "approval_recommendation": "reject",
                "risk_flags": [f"è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}"],
                "evaluation_type": "error",
                "confidence_level": 0.0
            }
    
    def _create_fallback_evaluation(self, content: str) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è©•ä¾¡ã‚’ä½œæˆ"""
        return {
            "overall_score": 0.7,
            "evaluation_details": {
                "business_manner_score": 0.7,
                "responsiveness_score": 0.7,
                "risk_assessment_score": 0.8,
                "clarity_score": 0.7,
                "strategy_alignment_score": 0.6
            },
            "strengths": ["åŸºæœ¬çš„ãªè¿”ä¿¡å†…å®¹ãŒå«ã¾ã‚Œã¦ã„ã‚‹"],
            "concerns": ["è©³ç´°è©•ä¾¡ãŒå®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ"],
            "improvement_suggestions": ["æ‰‹å‹•ã§ã®æœ€çµ‚ç¢ºèªã‚’æ¨å¥¨"],
            "risk_flags": [],
            "approval_recommendation": "revise",
            "confidence_level": 0.6,
            "evaluation_reasoning": "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è©•ä¾¡ã«ã‚ˆã‚ŠåŸºæœ¬çš„ãªå¦¥å½“æ€§ã‚’ç¢ºèª"
        }
    
    def _create_error_evaluation(self, error_message: str) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®è©•ä¾¡ã‚’ä½œæˆ"""
        return {
            "overall_score": 0.0,
            "evaluation_details": {
                "business_manner_score": 0.0,
                "responsiveness_score": 0.0,
                "risk_assessment_score": 0.0,
                "clarity_score": 0.0,
                "strategy_alignment_score": 0.0
            },
            "strengths": [],
            "concerns": [f"è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {error_message}"],
            "improvement_suggestions": ["æ‰‹å‹•ã§ã®å†…å®¹ç¢ºèªãŒå¿…è¦"],
            "risk_flags": ["è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼"],
            "approval_recommendation": "reject",
            "confidence_level": 0.0,
            "evaluation_reasoning": f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ã«ã‚ˆã‚Šè©•ä¾¡ä¸å¯: {error_message}"
        }
    
    async def process(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """BaseAgentã®æŠ½è±¡ãƒ¡ã‚½ãƒƒãƒ‰å®Ÿè£…"""
        proposed_content = input_data.get("proposed_content", "")
        thread_analysis = input_data.get("thread_analysis", {})
        strategy_plan = input_data.get("strategy_plan", {})
        company_settings = input_data.get("company_settings", {})
        
        result = await self.evaluate_content(
            proposed_content, thread_analysis, strategy_plan, company_settings
        )
        
        return {
            "success": True,
            "agent_type": "content_evaluation",
            "evaluation_result": result,
            "timestamp": datetime.now().isoformat()
        }
    
    def get_capabilities(self) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèƒ½åŠ›æƒ…å ±ã‚’å–å¾—"""
        return {
            "agent_type": "content_evaluation",
            "specialization": self.specialization,
            "capabilities": [
                "content_quality_assessment",
                "business_manner_evaluation",
                "risk_assessment",
                "improvement_suggestions",
                "approval_recommendations",
                "quick_approval_checks"
            ],
            "evaluation_criteria": [
                "business_manner",
                "responsiveness",
                "risk_assessment",
                "clarity",
                "strategy_alignment"
            ],
            "confidence_threshold": 0.7
        }