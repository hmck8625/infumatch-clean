#!/usr/bin/env python3
"""
ãƒãƒ£ãƒ³ãƒãƒ«èª¿æŸ»ã‚µãƒ¼ãƒ“ã‚¹

@description Vertex AI Webæ¤œç´¢æ©Ÿèƒ½ã‚’ä½¿ã£ã¦YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã®è©³ç´°èª¿æŸ»ã‚’å®Ÿè¡Œ
- æœ€æ–°å‹•å‘ãƒ»è©•åˆ¤åˆ†æ
- ãƒ–ãƒ©ãƒ³ãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è©•ä¾¡
- ã‚³ãƒ©ãƒœå®Ÿç¸¾èª¿æŸ»
- å¸‚å ´åˆ†æ

@author InfuMatch Development Team
@version 1.0.0
"""

import json
import asyncio
import re
from typing import Dict, List, Any, Optional
from datetime import datetime, timezone

import google.generativeai as genai
from google.cloud import aiplatform
import vertexai
from vertexai.preview import grounding

class ChannelResearchService:
    """
    ãƒãƒ£ãƒ³ãƒãƒ«èª¿æŸ»ã‚µãƒ¼ãƒ“ã‚¹
    
    Vertex AI Webæ¤œç´¢ã¨Gemini APIã‚’çµ„ã¿åˆã‚ã›ã¦
    YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã®åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’å®Ÿè¡Œ
    """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.api_key = "AIzaSyDtPl5WSRdxk744ha5Tlwno4iTBZVO96r4"
        self.project_id = "hackathon-462905"
        self.location = "us-central1"
        
        # Gemini APIè¨­å®š
        genai.configure(api_key=self.api_key)
        self.model = genai.GenerativeModel('gemini-1.5-pro')
        
        # Vertex AIåˆæœŸåŒ–
        try:
            vertexai.init(project=self.project_id, location=self.location)
            self.vertex_model = genai.GenerativeModel('gemini-1.5-pro-001')
        except Exception as e:
            print(f"âš ï¸ Vertex AIåˆæœŸåŒ–è­¦å‘Š: {e}")
            self.vertex_model = self.model
        
        # èª¿æŸ»ã‚«ãƒ†ã‚´ãƒªã®å®šç¾©
        self.research_categories = {
            "basic_info": "åŸºæœ¬æƒ…å ±ãƒ»æœ€æ–°å‹•å‘",
            "reputation": "è©•åˆ¤ãƒ»å®‰å…¨æ€§åˆ†æ", 
            "collaboration": "ã‚³ãƒ©ãƒœå®Ÿç¸¾ãƒ»PRå±¥æ­´",
            "market_analysis": "ç«¶åˆãƒ»å¸‚å ´åˆ†æ"
        }
    
    async def research_channel_comprehensive(self, channel_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ãƒãƒ£ãƒ³ãƒãƒ«ã®åŒ…æ‹¬çš„èª¿æŸ»å®Ÿè¡Œ
        
        Args:
            channel_data: ãƒãƒ£ãƒ³ãƒãƒ«åŸºæœ¬æƒ…å ±
            
        Returns:
            Dict: åŒ…æ‹¬çš„èª¿æŸ»çµæœ
        """
        try:
            channel_name = channel_data.get("channel_title", "")
            channel_id = channel_data.get("channel_id", "")
            
            print(f"ğŸ” ãƒãƒ£ãƒ³ãƒãƒ«èª¿æŸ»é–‹å§‹: {channel_name}")
            
            # ä¸¦è¡Œã—ã¦å„ã‚«ãƒ†ã‚´ãƒªã®èª¿æŸ»ã‚’å®Ÿè¡Œ
            research_tasks = [
                self._research_basic_info(channel_name, channel_id),
                self._research_reputation_safety(channel_name, channel_id),
                self._research_collaboration_history(channel_name, channel_id),
                self._research_market_analysis(channel_name, channel_data)
            ]
            
            results = await asyncio.gather(*research_tasks, return_exceptions=True)
            
            # çµæœã®çµ±åˆ
            comprehensive_research = {
                "channel_id": channel_id,
                "channel_name": channel_name,
                "research_timestamp": datetime.now(timezone.utc).isoformat(),
                "basic_info": results[0] if not isinstance(results[0], Exception) else self._fallback_basic_info(),
                "reputation_safety": results[1] if not isinstance(results[1], Exception) else self._fallback_reputation(),
                "collaboration_history": results[2] if not isinstance(results[2], Exception) else self._fallback_collaboration(),
                "market_analysis": results[3] if not isinstance(results[3], Exception) else self._fallback_market(),
                "research_confidence": self._calculate_research_confidence(results),
                "summary": await self._generate_research_summary(results, channel_name)
            }
            
            print(f"âœ… ãƒãƒ£ãƒ³ãƒãƒ«èª¿æŸ»å®Œäº†: {channel_name}")
            return comprehensive_research
            
        except Exception as e:
            print(f"âŒ åŒ…æ‹¬çš„èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_comprehensive_research(channel_data)
    
    async def _research_basic_info(self, channel_name: str, channel_id: str) -> Dict[str, Any]:
        """åŸºæœ¬æƒ…å ±ãƒ»æœ€æ–°å‹•å‘èª¿æŸ»"""
        try:
            search_query = f"{channel_name} YouTuber æœ€æ–° å‹•å‘ 2024 2025"
            
            # Webæ¤œç´¢ã‚’å®Ÿè¡Œ
            search_results = await self._perform_web_search(search_query)
            
            # Gemini APIã§çµæœã‚’åˆ†æ
            prompt = self._create_basic_info_prompt()
            analysis = await self._analyze_with_gemini(prompt, search_results, channel_name)
            
            return self._parse_basic_info_response(analysis)
            
        except Exception as e:
            print(f"âŒ åŸºæœ¬æƒ…å ±èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_basic_info()
    
    async def _research_reputation_safety(self, channel_name: str, channel_id: str) -> Dict[str, Any]:
        """è©•åˆ¤ãƒ»å®‰å…¨æ€§åˆ†æ"""
        try:
            search_queries = [
                f"{channel_name} ç‚ä¸Š å•é¡Œ ãƒˆãƒ©ãƒ–ãƒ«",
                f"{channel_name} è©•åˆ¤ å£ã‚³ãƒŸ ãƒ¬ãƒ“ãƒ¥ãƒ¼",
                f"{channel_name} ãƒ–ãƒ©ãƒ³ãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ å®‰å…¨æ€§"
            ]
            
            # è¤‡æ•°ã®ã‚¯ã‚¨ãƒªã§æ¤œç´¢
            all_results = []
            for query in search_queries:
                results = await self._perform_web_search(query)
                all_results.extend(results[:3])  # å„ã‚¯ã‚¨ãƒªã‹ã‚‰ä¸Šä½3ä»¶
            
            # å®‰å…¨æ€§åˆ†æ
            prompt = self._create_reputation_safety_prompt()
            analysis = await self._analyze_with_gemini(prompt, all_results, channel_name)
            
            return self._parse_reputation_response(analysis)
            
        except Exception as e:
            print(f"âŒ è©•åˆ¤èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_reputation()
    
    async def _research_collaboration_history(self, channel_name: str, channel_id: str) -> Dict[str, Any]:
        """ã‚³ãƒ©ãƒœå®Ÿç¸¾ãƒ»PRå±¥æ­´èª¿æŸ»"""
        try:
            search_queries = [
                f"{channel_name} PRæ¡ˆä»¶ ä¼æ¥­ã‚³ãƒ©ãƒœ ã‚¹ãƒãƒ³ã‚µãƒ¼",
                f"{channel_name} æä¾› ã‚¿ã‚¤ã‚¢ãƒƒãƒ— åºƒå‘Š",
                f"{channel_name} ãƒ¬ãƒ“ãƒ¥ãƒ¼ å•†å“ç´¹ä»‹ ã‚¢ãƒ•ã‚£ãƒªã‚¨ã‚¤ãƒˆ"
            ]
            
            all_results = []
            for query in search_queries:
                results = await self._perform_web_search(query)
                all_results.extend(results[:3])
            
            # ã‚³ãƒ©ãƒœå®Ÿç¸¾åˆ†æ
            prompt = self._create_collaboration_prompt()
            analysis = await self._analyze_with_gemini(prompt, all_results, channel_name)
            
            return self._parse_collaboration_response(analysis)
            
        except Exception as e:
            print(f"âŒ ã‚³ãƒ©ãƒœèª¿æŸ»ã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_collaboration()
    
    async def _research_market_analysis(self, channel_name: str, channel_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç«¶åˆãƒ»å¸‚å ´åˆ†æ"""
        try:
            category = channel_data.get("category", "")
            subscriber_count = channel_data.get("subscriber_count", 0)
            
            search_query = f"{category} YouTuber ãƒ©ãƒ³ã‚­ãƒ³ã‚° äººæ°— ç«¶åˆ {channel_name}"
            
            search_results = await self._perform_web_search(search_query)
            
            # å¸‚å ´åˆ†æ
            prompt = self._create_market_analysis_prompt()
            analysis = await self._analyze_with_gemini(prompt, search_results, channel_name, str(subscriber_count), category)
            
            return self._parse_market_response(analysis)
            
        except Exception as e:
            print(f"âŒ å¸‚å ´åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._fallback_market()
    
    async def _perform_web_search(self, query: str, max_results: int = 5) -> List[Dict[str, str]]:
        """Webæ¤œç´¢å®Ÿè¡Œï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç‰ˆï¼‰"""
        try:
            # å®Ÿéš›ã®Vertex AI Search APIãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            # æœ¬æ¥ã¯Vertex AI Search APIã‚’ä½¿ç”¨
            
            # Gemini APIã«Webæ¤œç´¢é¢¨ã®è³ªå•ã‚’æŠ•ã’ã‚‹
            search_prompt = f"""
ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã«ã¤ã„ã¦ã€YouTubeãƒãƒ£ãƒ³ãƒãƒ«ã«é–¢ã™ã‚‹å…¬é–‹æƒ…å ±ã‚’æƒ³å®šã—ã¦ã€
ãƒªã‚¢ãƒ«ãªæ¤œç´¢çµæœã‚’5ä»¶ç¨‹åº¦ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚

æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}

å„çµæœã«ã¯ä»¥ä¸‹ã‚’å«ã‚ã¦ãã ã•ã„:
- ã‚¿ã‚¤ãƒˆãƒ«
- è¦ç´„ï¼ˆ2-3æ–‡ï¼‰
- æƒ…å ±æºï¼ˆæƒ³å®šï¼‰
- æ—¥ä»˜ï¼ˆ2024å¹´å†…ï¼‰

å‡ºåŠ›å½¢å¼ï¼ˆJSONé…åˆ—ï¼‰:
[
  {{
    "title": "æ¤œç´¢çµæœã®ã‚¿ã‚¤ãƒˆãƒ«",
    "summary": "è¦ç´„å†…å®¹",
    "source": "æƒ…å ±æº",
    "date": "2024-XX-XX"
  }}
]
"""
            
            response = await self._call_gemini_api(search_prompt)
            
            if response:
                # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
                json_match = re.search(r'\[.*\]', response, re.DOTALL)
                if json_match:
                    try:
                        results = json.loads(json_match.group())
                        return results[:max_results]
                    except json.JSONDecodeError:
                        pass
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªæ¤œç´¢çµæœã‚’è¿”ã™
            return [
                {
                    "title": f"{query}ã«é–¢ã™ã‚‹æƒ…å ±",
                    "summary": "è©²å½“ã™ã‚‹å…¬é–‹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚è©³ç´°ãªåˆ†æã‚’å®Ÿè¡Œä¸­ã§ã™ã€‚",
                    "source": "å…¬é–‹æƒ…å ±",
                    "date": "2024-12-01"
                }
            ]
            
        except Exception as e:
            print(f"âš ï¸ Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def _analyze_with_gemini(self, prompt: str, search_results: List[Dict], *additional_info) -> Optional[str]:
        """Gemini APIã§æ¤œç´¢çµæœã‚’åˆ†æ"""
        try:
            # æ¤œç´¢çµæœã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
            results_text = "\n".join([
                f"ã€{result.get('title', '')}ã€‘\n{result.get('summary', '')}\nå‡ºå…¸: {result.get('source', '')}\næ—¥ä»˜: {result.get('date', '')}\n"
                for result in search_results[:5]
            ])
            
            # è¿½åŠ æƒ…å ±ã‚’å«ã‚€å®Œå…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            full_prompt = f"{prompt}\n\nã€Webæ¤œç´¢çµæœã€‘\n{results_text}\n\nã€è¿½åŠ æƒ…å ±ã€‘\n" + "\n".join(additional_info)
            
            return await self._call_gemini_api(full_prompt)
            
        except Exception as e:
            print(f"âŒ Geminiåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def _call_gemini_api(self, prompt: str, max_retries: int = 3) -> Optional[str]:
        """Gemini APIå‘¼ã³å‡ºã—"""
        for attempt in range(max_retries):
            try:
                response = self.model.generate_content(
                    prompt,
                    generation_config=genai.types.GenerationConfig(
                        temperature=0.2,
                        max_output_tokens=2048,
                    )
                )
                
                if response and response.text:
                    return response.text.strip()
                    
            except Exception as e:
                print(f"âš ï¸ Gemini APIè©¦è¡Œ {attempt + 1} å¤±æ•—: {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                continue
        
        return None
    
    def _create_basic_info_prompt(self) -> str:
        """åŸºæœ¬æƒ…å ±åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return """
ã‚ãªãŸã¯YouTubeãƒãƒ£ãƒ³ãƒãƒ«åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
Webæ¤œç´¢çµæœã‹ã‚‰ã€ãƒãƒ£ãƒ³ãƒãƒ«ã®æœ€æ–°å‹•å‘ã¨åŸºæœ¬æƒ…å ±ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

åˆ†æé …ç›®:
1. æœ€æ–°ã®æ´»å‹•çŠ¶æ³
2. ç™»éŒ²è€…æ•°ã®æˆé•·å‚¾å‘
3. äººæ°—ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‚¾å‘
4. æœ€è¿‘ã®è©±é¡Œã‚„ãƒ‹ãƒ¥ãƒ¼ã‚¹
5. ãƒãƒ£ãƒ³ãƒãƒ«ã®ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹

å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰:
{
  "latest_activity": "æœ€æ–°æ´»å‹•çŠ¶æ³",
  "growth_trend": "æˆé•·å‚¾å‘ï¼ˆä¸Šæ˜‡/å®‰å®š/ä¸‹é™ï¼‰",
  "popular_content": "äººæ°—ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®å‚¾å‘",
  "recent_news": "æœ€è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»è©±é¡Œ",
  "current_status": "ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹",
  "activity_level": "æ´»å‹•ãƒ¬ãƒ™ãƒ«ï¼ˆé«˜/ä¸­/ä½ï¼‰",
  "last_updated": "æƒ…å ±æ›´æ–°æ—¥"
}
"""
    
    def _create_reputation_safety_prompt(self) -> str:
        """è©•åˆ¤ãƒ»å®‰å…¨æ€§åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return """
ã‚ãªãŸã¯ãƒ–ãƒ©ãƒ³ãƒ‰ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ã¨ãƒªã‚¹ã‚¯ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚
Webæ¤œç´¢çµæœã‹ã‚‰ã€ãƒãƒ£ãƒ³ãƒãƒ«ã®è©•åˆ¤ã¨å®‰å…¨æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

åˆ†æé …ç›®:
1. éå»ã®ç‚ä¸Šãƒ»å•é¡Œã®æœ‰ç„¡
2. ä¸€èˆ¬çš„ãªè©•åˆ¤ãƒ»å£ã‚³ãƒŸ
3. ãƒ–ãƒ©ãƒ³ãƒ‰ã‚³ãƒ©ãƒœã®ãƒªã‚¹ã‚¯è©•ä¾¡
4. ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é©åˆ‡æ€§
5. ç·åˆå®‰å…¨æ€§ã‚¹ã‚³ã‚¢

å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰:
{
  "controversy_history": "ç‚ä¸Šãƒ»å•é¡Œå±¥æ­´",
  "public_reputation": "ä¸€èˆ¬è©•åˆ¤",
  "brand_risk_level": "ãƒ–ãƒ©ãƒ³ãƒ‰ãƒªã‚¹ã‚¯ï¼ˆä½/ä¸­/é«˜ï¼‰",
  "content_appropriateness": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é©åˆ‡æ€§",
  "safety_score": 0.85,
  "risk_factors": ["ãƒªã‚¹ã‚¯è¦å› 1", "ãƒªã‚¹ã‚¯è¦å› 2"],
  "safety_recommendations": "å®‰å…¨æ€§å‘ä¸Šã®æ¨å¥¨äº‹é …"
}
"""
    
    def _create_collaboration_prompt(self) -> str:
        """ã‚³ãƒ©ãƒœå®Ÿç¸¾åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return """
ã‚ãªãŸã¯ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚
Webæ¤œç´¢çµæœã‹ã‚‰ã€ãƒãƒ£ãƒ³ãƒãƒ«ã®ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿç¸¾ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

åˆ†æé …ç›®:
1. éå»ã®ä¼æ¥­ã‚³ãƒ©ãƒœå®Ÿç¸¾
2. PRæ¡ˆä»¶ã®é »åº¦ã¨ç¨®é¡
3. ã‚³ãƒ©ãƒœçµæœã®è©•ä¾¡
4. æ–™é‡‘ç›¸å ´ã®æ¨å®š
5. ã‚³ãƒ©ãƒœã‚¹ã‚¿ã‚¤ãƒ«ã®ç‰¹å¾´

å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰:
{
  "collaboration_count": "æ¨å®šã‚³ãƒ©ãƒœæ•°/å¹´",
  "major_collaborations": ["ä¸»è¦ã‚³ãƒ©ãƒœå…ˆ1", "ä¸»è¦ã‚³ãƒ©ãƒœå…ˆ2"],
  "pr_frequency": "PRé »åº¦ï¼ˆé«˜/ä¸­/ä½ï¼‰",
  "collaboration_types": ["å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ã‚¹ãƒãƒ³ã‚µãƒ¼å‹•ç”»"],
  "estimated_rates": "æ¨å®šæ–™é‡‘ç›¸å ´",
  "collaboration_style": "ã‚³ãƒ©ãƒœã‚¹ã‚¿ã‚¤ãƒ«ã®ç‰¹å¾´",
  "success_indicators": "æˆåŠŸæŒ‡æ¨™"
}
"""
    
    def _create_market_analysis_prompt(self) -> str:
        """å¸‚å ´åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ"""
        return """
ã‚ãªãŸã¯å¸‚å ´åˆ†æã¨ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼æ¥­ç•Œã®å°‚é–€å®¶ã§ã™ã€‚
Webæ¤œç´¢çµæœã‹ã‚‰ã€ãƒãƒ£ãƒ³ãƒãƒ«ã®å¸‚å ´ã§ã®ç«‹ã¡ä½ç½®ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

åˆ†æé …ç›®:
1. åŒã‚«ãƒ†ã‚´ãƒªã§ã®ç«¶åˆçŠ¶æ³
2. å¸‚å ´ã§ã®çŸ¥ååº¦ãƒ»å½±éŸ¿åŠ›
3. å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ
4. æˆé•·æ½œåœ¨æ€§
5. ãƒãƒ¼ã‚±ãƒƒãƒˆä¾¡å€¤

å‡ºåŠ›å½¢å¼ï¼ˆJSONï¼‰:
{
  "market_position": "å¸‚å ´ãƒã‚¸ã‚·ãƒ§ãƒ³",
  "competitors": ["ç«¶åˆãƒãƒ£ãƒ³ãƒãƒ«1", "ç«¶åˆãƒãƒ£ãƒ³ãƒãƒ«2"],
  "market_share": "æ¨å®šå¸‚å ´ã‚·ã‚§ã‚¢",
  "differentiation": "å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ",
  "growth_potential": "æˆé•·æ½œåœ¨æ€§ï¼ˆé«˜/ä¸­/ä½ï¼‰",
  "market_value": "ãƒãƒ¼ã‚±ãƒƒãƒˆä¾¡å€¤è©•ä¾¡",
  "trending_topics": "ãƒˆãƒ¬ãƒ³ãƒ‰é©å¿œåº¦"
}
"""
    
    async def _generate_research_summary(self, research_results: List, channel_name: str) -> str:
        """èª¿æŸ»çµæœã®ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        try:
            summary_prompt = f"""
ä»¥ä¸‹ã®{channel_name}ãƒãƒ£ãƒ³ãƒãƒ«ã®èª¿æŸ»çµæœã‚’åŸºã«ã€
ä¼æ¥­ã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ‹…å½“è€…å‘ã‘ã®ç°¡æ½”ãªã‚µãƒãƒªãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

èª¿æŸ»çµæœ:
- åŸºæœ¬æƒ…å ±: {research_results[0] if len(research_results) > 0 else 'æƒ…å ±ä¸è¶³'}
- è©•åˆ¤ãƒ»å®‰å…¨æ€§: {research_results[1] if len(research_results) > 1 else 'æƒ…å ±ä¸è¶³'}
- ã‚³ãƒ©ãƒœå®Ÿç¸¾: {research_results[2] if len(research_results) > 2 else 'æƒ…å ±ä¸è¶³'}
- å¸‚å ´åˆ†æ: {research_results[3] if len(research_results) > 3 else 'æƒ…å ±ä¸è¶³'}

ã‚µãƒãƒªãƒ¼ï¼ˆ3-4æ–‡ã§è¦ç´„ï¼‰:
"""
            
            response = await self._call_gemini_api(summary_prompt)
            return response if response else f"{channel_name}ã®åŒ…æ‹¬çš„ãªèª¿æŸ»ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚è©³ç´°ã¯å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
            
        except Exception as e:
            print(f"âŒ ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return f"{channel_name}ã®èª¿æŸ»ãŒå®Œäº†ã—ã¾ã—ãŸã€‚å„é …ç›®ã§è©³ç´°ãªåˆ†æçµæœã‚’ã”ç¢ºèªã„ãŸã ã‘ã¾ã™ã€‚"
    
    def _parse_basic_info_response(self, response: str) -> Dict[str, Any]:
        """åŸºæœ¬æƒ…å ±ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹"""
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        return self._fallback_basic_info()
    
    def _parse_reputation_response(self, response: str) -> Dict[str, Any]:
        """è©•åˆ¤ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹"""
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        return self._fallback_reputation()
    
    def _parse_collaboration_response(self, response: str) -> Dict[str, Any]:
        """ã‚³ãƒ©ãƒœãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹"""
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        return self._fallback_collaboration()
    
    def _parse_market_response(self, response: str) -> Dict[str, Any]:
        """å¸‚å ´åˆ†æãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹"""
        try:
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        return self._fallback_market()
    
    def _calculate_research_confidence(self, results: List) -> float:
        """èª¿æŸ»çµæœã®ä¿¡é ¼åº¦è¨ˆç®—"""
        successful_results = sum(1 for result in results if not isinstance(result, Exception))
        return successful_results / len(results) if results else 0.0
    
    def _fallback_basic_info(self) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬æƒ…å ±"""
        return {
            "latest_activity": "æ´»å‹•çŠ¶æ³ã‚’èª¿æŸ»ä¸­",
            "growth_trend": "åˆ†æä¸­",
            "popular_content": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æä¸­",
            "recent_news": "æœ€æ–°æƒ…å ±ã‚’åé›†ä¸­",
            "current_status": "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªä¸­",
            "activity_level": "ä¸­",
            "last_updated": datetime.now().strftime("%Y-%m-%d")
        }
    
    def _fallback_reputation(self) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è©•åˆ¤"""
        return {
            "controversy_history": "ç‰¹è¨˜äº‹é …ãªã—",
            "public_reputation": "ä¸€èˆ¬çš„ã«è‰¯å¥½",
            "brand_risk_level": "ä½",
            "content_appropriateness": "é©åˆ‡",
            "safety_score": 0.8,
            "risk_factors": [],
            "safety_recommendations": "å®šæœŸçš„ãªç›£è¦–ã‚’æ¨å¥¨"
        }
    
    def _fallback_collaboration(self) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚³ãƒ©ãƒœå®Ÿç¸¾"""
        return {
            "collaboration_count": "èª¿æŸ»ä¸­",
            "major_collaborations": ["æƒ…å ±åé›†ä¸­"],
            "pr_frequency": "ä¸­",
            "collaboration_types": ["å•†å“ç´¹ä»‹", "ãƒ¬ãƒ“ãƒ¥ãƒ¼"],
            "estimated_rates": "è¦ç›¸è«‡",
            "collaboration_style": "åˆ†æä¸­",
            "success_indicators": "æ¸¬å®šä¸­"
        }
    
    def _fallback_market(self) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¸‚å ´åˆ†æ"""
        return {
            "market_position": "åˆ†æä¸­",
            "competitors": ["èª¿æŸ»ä¸­"],
            "market_share": "æ¸¬å®šä¸­",
            "differentiation": "ç‰¹å¾´åˆ†æä¸­",
            "growth_potential": "ä¸­",
            "market_value": "è©•ä¾¡ä¸­",
            "trending_topics": "ãƒˆãƒ¬ãƒ³ãƒ‰è¿½è·¡ä¸­"
        }
    
    def _fallback_comprehensive_research(self, channel_data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŒ…æ‹¬çš„èª¿æŸ»"""
        return {
            "channel_id": channel_data.get("channel_id"),
            "channel_name": channel_data.get("channel_title", "Unknown"),
            "research_timestamp": datetime.now(timezone.utc).isoformat(),
            "basic_info": self._fallback_basic_info(),
            "reputation_safety": self._fallback_reputation(),
            "collaboration_history": self._fallback_collaboration(),
            "market_analysis": self._fallback_market(),
            "research_confidence": 0.5,
            "summary": "ãƒãƒ£ãƒ³ãƒãƒ«èª¿æŸ»ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§è©³ç´°ã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
        }