"""
Geminié«˜åº¦ãƒãƒƒãƒãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - æˆ¦ç•¥çš„ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼åˆ†æã‚·ã‚¹ãƒ†ãƒ 
æ·±ã„åˆ†æã¨èª¬å¾—åŠ›ã®ã‚ã‚‹æ¨è–¦ç†ç”±ã‚’æä¾›
"""
import google.generativeai as genai
from typing import Dict, List, Any, Optional
import json
import logging
from datetime import datetime
from google.cloud import firestore
import asyncio

logger = logging.getLogger(__name__)

class GeminiMatchingAgent:
    """Gemini APIã‚’ä½¿ç”¨ã—ãŸé«˜åº¦ãªã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒãƒƒãƒãƒ³ã‚°åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    def __init__(self, gemini_api_key: str):
        self.gemini_api_key = gemini_api_key
        genai.configure(api_key=gemini_api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        try:
            self.db = firestore.Client(project="hackathon-462905")
        except Exception as e:
            logger.warning(f"Firestore initialization failed: {e}")
            self.db = None
        
    async def analyze_deep_matching(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®æˆ¦ç•¥çš„ãƒãƒƒãƒãƒ³ã‚°åˆ†æ"""
        try:
            start_time = datetime.now()
            logger.info("ğŸ§  Geminié«˜åº¦ãƒãƒƒãƒãƒ³ã‚°åˆ†æé–‹å§‹")
            
            # Step 1: ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
            influencer_candidates = await self._fetch_influencer_candidates(request_data)
            if not influencer_candidates:
                return {
                    "success": False,
                    "error": "ãƒãƒƒãƒãƒ³ã‚°å€™è£œã¨ãªã‚‹ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                }
            
            # Step 2: å„ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®è©³ç´°åˆ†æ
            analysis_results = []
            for influencer in influencer_candidates[:5]:  # ä¸Šä½5åã‚’åˆ†æ
                try:
                    analysis = await self._analyze_single_influencer(
                        influencer, 
                        request_data
                    )
                    if analysis:
                        analysis_results.append(analysis)
                except Exception as e:
                    logger.warning(f"å€‹åˆ¥ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
                    continue
            
            if not analysis_results:
                return {
                    "success": False,
                    "error": "åˆ†æå¯èƒ½ãªã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                }
            
            # Step 3: ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã¨å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
            portfolio_insights = await self._analyze_portfolio_optimization(
                analysis_results, 
                request_data
            )
            market_context = await self._analyze_market_context(
                request_data, 
                analysis_results
            )
            
            # Step 4: çµæœã®æ§‹ç¯‰
            processing_duration = (datetime.now() - start_time).total_seconds()
            
            return {
                "success": True,
                "analysis_results": analysis_results,
                "portfolio_insights": portfolio_insights,
                "market_context": market_context,
                "processing_metadata": {
                    "analysis_duration_ms": int(processing_duration * 1000),
                    "confidence_score": self._calculate_overall_confidence(analysis_results),
                    "gemini_model_used": "gemini-1.5-flash",
                    "analysis_timestamp": datetime.now().isoformat(),
                    "total_candidates_analyzed": len(analysis_results),
                    "total_candidates_available": len(influencer_candidates)
                }
            }
            
        except Exception as e:
            logger.error(f"Geminié«˜åº¦ãƒãƒƒãƒãƒ³ã‚°åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "success": False,
                "error": f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            }
    
    async def _fetch_influencer_candidates(self, request_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ãƒãƒƒãƒãƒ³ã‚°å€™è£œã¨ãªã‚‹ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’å–å¾—"""
        try:
            logger.info("ğŸ“Š ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼å€™è£œãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
            
            # FirestoreãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            if not self.db:
                logger.warning("Firestore not available, using mock data")
                return self._get_mock_influencers()
            
            # Firestoreã‹ã‚‰ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            influencers_ref = self.db.collection('influencers')
            
            # åŸºæœ¬ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            preferences = request_data.get('influencer_preferences', {})
            query = influencers_ref
            
            # ç™»éŒ²è€…æ•°ç¯„å›²ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if preferences.get('subscriber_range'):
                sub_range = preferences['subscriber_range']
                if sub_range.get('min'):
                    query = query.where('subscriber_count', '>=', sub_range['min'])
                if sub_range.get('max'):
                    query = query.where('subscriber_count', '<=', sub_range['max'])
            
            # ã‚«ãƒ†ã‚´ãƒªã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            preferred_categories = preferences.get('preferred_categories', [])
            if preferred_categories:
                query = query.where('category', 'in', preferred_categories[:10])  # Firestoreåˆ¶é™
            
            # çµæœå–å¾—
            docs = query.limit(20).stream()
            candidates = []
            
            for doc in docs:
                data = doc.to_dict()
                data['id'] = doc.id
                candidates.append(data)
            
            logger.info(f"âœ… {len(candidates)}åã®å€™è£œã‚’å–å¾—")
            return candidates
            
        except Exception as e:
            logger.error(f"ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼å€™è£œå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    async def _analyze_single_influencer(self, influencer: Dict[str, Any], request_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """å˜ä¸€ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®è©³ç´°åˆ†æ"""
        try:
            analysis_prompt = self._build_deep_analysis_prompt(influencer, request_data)
            
            response = await self._call_gemini_async(analysis_prompt)
            if not response:
                return None
            
            # JSONå½¢å¼ã®å¿œç­”ã‚’ãƒ‘ãƒ¼ã‚¹
            try:
                parsed_response = json.loads(response)
            except json.JSONDecodeError:
                # JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
                parsed_response = self._extract_analysis_from_text(response)
            
            return {
                "influencer_id": influencer.get('id', ''),
                "influencer_data": {
                    "channel_id": influencer.get('channel_id', ''),
                    "channel_name": influencer.get('channel_name', influencer.get('channel_title', influencer.get('name', ''))),
                    "channel_title": influencer.get('channel_title', ''),
                    "description": influencer.get('description', ''),
                    "subscriber_count": influencer.get('subscriber_count', 0),
                    "video_count": influencer.get('video_count', 0),
                    "view_count": influencer.get('view_count', 0),
                    "engagement_rate": influencer.get('engagement_rate', 0.0),
                    "thumbnail_url": influencer.get('thumbnail_url', ''),
                    "category": influencer.get('category', ''),
                    "email": influencer.get('email', '')
                },
                "overall_compatibility_score": parsed_response.get('overall_compatibility_score', 75),
                "detailed_analysis": {
                    "brand_alignment": {
                        "score": parsed_response.get('brand_alignment_score', 70),
                        "reasoning": parsed_response.get('brand_alignment_reasoning', 'ä¼æ¥­ãƒ–ãƒ©ãƒ³ãƒ‰ã¨ã®é©åˆæ€§ã‚’åˆ†æä¸­'),
                        "key_strengths": parsed_response.get('brand_strengths', ['é«˜ã„ä¿¡é ¼æ€§', 'ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã®ä¸€è‡´']),
                        "potential_concerns": parsed_response.get('brand_concerns', ['ãƒªãƒ¼ãƒã®é™ç•Œ'])
                    },
                    "audience_synergy": {
                        "score": parsed_response.get('audience_synergy_score', 80),
                        "demographic_overlap": parsed_response.get('demographic_overlap', 'ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã®70%ãŒé‡è¤‡'),
                        "engagement_quality": parsed_response.get('engagement_quality', 'é«˜å“è³ªãªã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ'),
                        "conversion_potential": parsed_response.get('conversion_potential', 'ä¸­ç¨‹åº¦ã‹ã‚‰é«˜ã„ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æœŸå¾…å€¤')
                    },
                    "content_fit": {
                        "score": parsed_response.get('content_fit_score', 85),
                        "style_compatibility": parsed_response.get('style_compatibility', 'ä¼æ¥­ãƒ–ãƒ©ãƒ³ãƒ‰ã¨èª¿å’Œã™ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¹ã‚¿ã‚¤ãƒ«'),
                        "content_themes_match": parsed_response.get('content_themes', ['å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼', 'ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ææ¡ˆ']),
                        "creative_opportunities": parsed_response.get('creative_opportunities', ['å•†å“çµ±åˆ', 'ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ†ãƒªãƒ³ã‚°'])
                    },
                    "business_viability": {
                        "score": parsed_response.get('business_viability_score', 75),
                        "roi_prediction": parsed_response.get('roi_prediction', 'æŠ•è³‡å¯¾åŠ¹æœã¯è‰¯å¥½ãªè¦‹è¾¼ã¿'),
                        "risk_assessment": parsed_response.get('risk_assessment', 'ä½ã€œä¸­ç¨‹åº¦ã®ãƒªã‚¹ã‚¯'),
                        "long_term_potential": parsed_response.get('long_term_potential', 'é•·æœŸçš„ãªãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—ã®å¯èƒ½æ€§')
                    }
                },
                "recommendation_summary": {
                    "confidence_level": parsed_response.get('confidence_level', 'Medium'),
                    "primary_recommendation_reason": parsed_response.get('primary_reason', f'{influencer.get("name", "ã“ã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼")}ã¯ä¼æ¥­ã®ä¾¡å€¤è¦³ã¨å¼·ãå…±é³´ã—ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã¸ã®åŠ¹æœçš„ãªãƒªãƒ¼ãƒãŒæœŸå¾…ã§ãã¾ã™'),
                    "success_scenario": parsed_response.get('success_scenario', 'å•†å“ã®è‡ªç„¶ãªç´¹ä»‹ã«ã‚ˆã‚Šã€ãƒ–ãƒ©ãƒ³ãƒ‰èªçŸ¥åº¦å‘ä¸Šã¨å£²ä¸Šå¢—åŠ ãŒæœŸå¾…ã•ã‚Œã¾ã™'),
                    "collaboration_strategy": parsed_response.get('collaboration_strategy', 'æ®µéšçš„ãªã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‹ã‚‰é•·æœŸãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—ã¸ç™ºå±•'),
                    "expected_outcomes": parsed_response.get('expected_outcomes', ['ãƒ–ãƒ©ãƒ³ãƒ‰èªçŸ¥åº¦20%å‘ä¸Š', 'ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡15%å‘ä¸Š', 'å£²ä¸Š5-10%å¢—åŠ '])
                },
                "strategic_insights": {
                    "best_collaboration_types": parsed_response.get('collaboration_types', ['å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼', 'ã‚¹ãƒãƒ³ã‚µãƒ¼ãƒ‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', 'ãƒ©ã‚¤ãƒ–é…ä¿¡']),
                    "optimal_campaign_timing": parsed_response.get('optimal_timing', '3-6ãƒ¶æœˆã®ç¶™ç¶šçš„ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³'),
                    "content_suggestions": parsed_response.get('content_suggestions', ['å•†å“ã®ä½¿ç”¨ä½“é¨“', 'æ—¥å¸¸ã¸ã®çµ±åˆææ¡ˆ', 'ãƒ•ã‚¡ãƒ³ã¨ã®äº¤æµä¼ç”»']),
                    "budget_recommendations": {
                        "min": parsed_response.get('budget_min', 80000),
                        "max": parsed_response.get('budget_max', 150000),
                        "reasoning": parsed_response.get('budget_reasoning', 'ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®å½±éŸ¿åŠ›ã¨ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’è€ƒæ…®ã—ãŸé©æ­£ä¾¡æ ¼ç¯„å›²')
                    }
                }
            }
            
        except Exception as e:
            logger.error(f"å€‹åˆ¥ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _build_deep_analysis_prompt(self, influencer: Dict[str, Any], request_data: Dict[str, Any]) -> str:
        """Geminiç”¨ã®è©³ç´°åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        company_profile = request_data.get('company_profile', {})
        product_portfolio = request_data.get('product_portfolio', {})
        campaign_objectives = request_data.get('campaign_objectives', {})
        
        prompt = f"""
ã‚ãªãŸã¯æˆ¦ç•¥çš„ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ä¼æ¥­ã¨ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®è©³ç´°æƒ…å ±ã‚’åˆ†æã—ã€æˆ¦ç•¥çš„ãªé©åˆæ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

## ğŸ“Š ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
**ä¼æ¥­å**: {company_profile.get('name', 'N/A')}
**æ¥­ç•Œ**: {company_profile.get('industry', 'N/A')}
**ä¼æ¥­èª¬æ˜**: {company_profile.get('description', 'N/A')}
**ãƒ–ãƒ©ãƒ³ãƒ‰ä¾¡å€¤è¦³**: {', '.join(company_profile.get('brand_values', []))}
**ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤**: {', '.join(company_profile.get('target_demographics', []))}
**ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«**: {company_profile.get('communication_style', 'N/A')}

## ğŸ¯ å•†å“ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ª
"""
        
        products = product_portfolio.get('products', [])
        for i, product in enumerate(products[:3], 1):
            prompt += f"""
**å•†å“{i}**: {product.get('name', 'N/A')}
- ã‚«ãƒ†ã‚´ãƒª: {product.get('category', 'N/A')}
- èª¬æ˜: {product.get('description', 'N/A')}
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {product.get('target_audience', 'N/A')}
- ä¾¡æ ¼å¸¯: {product.get('price_range', 'N/A')}
- ç‰¹å¾´: {', '.join(product.get('unique_selling_points', []))}
"""
        
        prompt += f"""
## ğŸš€ ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ç›®æ¨™
**ä¸»è¦ç›®æ¨™**: {', '.join(campaign_objectives.get('primary_goals', []))}
**æˆåŠŸæŒ‡æ¨™**: {', '.join(campaign_objectives.get('success_metrics', []))}
**äºˆç®—ç¯„å›²**: Â¥{campaign_objectives.get('budget_range', {}).get('min', 0):,} - Â¥{campaign_objectives.get('budget_range', {}).get('max', 0):,}
**æœŸé–“**: {campaign_objectives.get('timeline', 'N/A')}

## ğŸ‘¤ åˆ†æå¯¾è±¡ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼
**åå‰**: {influencer.get('name', 'N/A')}
**ãƒãƒ£ãƒ³ãƒãƒ«ID**: {influencer.get('id', 'N/A')}
**ã‚«ãƒ†ã‚´ãƒª**: {influencer.get('category', 'N/A')}
**ç™»éŒ²è€…æ•°**: {influencer.get('subscriber_count', 0):,}äºº
**ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡**: {influencer.get('engagement_rate', 0):.1f}%
**èª¬æ˜**: {influencer.get('description', 'N/A')}
**å‹•ç”»æ•°**: {influencer.get('video_count', 0)}æœ¬
**ç·è¦–è´å›æ•°**: {influencer.get('view_count', 0):,}å›

## ğŸ“‹ åˆ†ææŒ‡ç¤º
ä»¥ä¸‹ã®4ã¤ã®è¦³ç‚¹ã‹ã‚‰æˆ¦ç•¥çš„åˆ†æã‚’è¡Œã„ã€JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

1. **ãƒ–ãƒ©ãƒ³ãƒ‰é©åˆæ€§** (0-100ç‚¹): ä¼æ¥­ã®ä¾¡å€¤è¦³ã€æ¥­ç•Œã€ãƒ–ãƒ©ãƒ³ãƒ‰ã‚¤ãƒ¡ãƒ¼ã‚¸ã¨ã®é©åˆåº¦
2. **ã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹ç›¸ä¹—åŠ¹æœ** (0-100ç‚¹): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã®é‡è¤‡ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå“è³ªã€ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¯èƒ½æ€§
3. **ã‚³ãƒ³ãƒ†ãƒ³ãƒ„é©åˆæ€§** (0-100ç‚¹): ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¹ã‚¿ã‚¤ãƒ«ã€ãƒ†ãƒ¼ãƒã€å‰µé€ çš„æ©Ÿä¼šã®è©•ä¾¡
4. **ãƒ“ã‚¸ãƒã‚¹å®Ÿç¾æ€§** (0-100ç‚¹): ROIäºˆæ¸¬ã€ãƒªã‚¹ã‚¯è©•ä¾¡ã€é•·æœŸçš„å¯èƒ½æ€§

**å¿…é ˆå›ç­”é …ç›®**:
```json
{{
  "overall_compatibility_score": 85,
  "brand_alignment_score": 80,
  "brand_alignment_reasoning": "å…·ä½“çš„ãªç†ç”±",
  "brand_strengths": ["å¼·ã¿1", "å¼·ã¿2"],
  "brand_concerns": ["æ‡¸å¿µç‚¹1"],
  "audience_synergy_score": 90,
  "demographic_overlap": "è©³ç´°ãªé‡è¤‡åˆ†æ",
  "engagement_quality": "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå“è³ªè©•ä¾¡",
  "conversion_potential": "ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³å¯èƒ½æ€§",
  "content_fit_score": 85,
  "style_compatibility": "ã‚¹ã‚¿ã‚¤ãƒ«é©åˆæ€§",
  "content_themes": ["ãƒ†ãƒ¼ãƒ1", "ãƒ†ãƒ¼ãƒ2"],
  "creative_opportunities": ["æ©Ÿä¼š1", "æ©Ÿä¼š2"],
  "business_viability_score": 75,
  "roi_prediction": "ROIäºˆæ¸¬",
  "risk_assessment": "ãƒªã‚¹ã‚¯è©•ä¾¡",
  "long_term_potential": "é•·æœŸçš„å¯èƒ½æ€§",
  "confidence_level": "High/Medium/Low",
  "primary_reason": "ä¸»è¦æ¨è–¦ç†ç”±",
  "success_scenario": "æˆåŠŸã‚·ãƒŠãƒªã‚ª",
  "collaboration_strategy": "ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥",
  "expected_outcomes": ["æœŸå¾…ã•ã‚Œã‚‹æˆæœ1", "æˆæœ2"],
  "collaboration_types": ["æ¨è–¦ã‚³ãƒ©ãƒœæ‰‹æ³•1", "æ‰‹æ³•2"],
  "optimal_timing": "æœ€é©ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°",
  "content_suggestions": ["ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ææ¡ˆ1", "ææ¡ˆ2"],
  "budget_min": 80000,
  "budget_max": 150000,
  "budget_reasoning": "äºˆç®—æ¨å¥¨ç†ç”±"
}}
```

**é‡è¦**: 
- å¿…ãšJSONå½¢å¼ã§å›ç­”
- æ—¥æœ¬èªã§å…·ä½“çš„ã‹ã¤èª¬å¾—åŠ›ã®ã‚ã‚‹åˆ†æã‚’æä¾›
- ä¼æ¥­ã®ç‰¹æ€§ã¨ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®å®Ÿç¸¾ã‚’è©³ç´°ã«è€ƒæ…®
- æˆ¦ç•¥çš„è¦–ç‚¹ã‹ã‚‰å®Ÿç¾å¯èƒ½ã§åŠ¹æœçš„ãªææ¡ˆã‚’è¡Œã†
"""
        
        return prompt
    
    async def _call_gemini_async(self, prompt: str) -> Optional[str]:
        """Gemini APIã®éåŒæœŸå‘¼ã³å‡ºã—"""
        try:
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                lambda: self.model.generate_content(prompt)
            )
            return response.text
        except Exception as e:
            logger.error(f"Gemini APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_analysis_from_text(self, text: str) -> Dict[str, Any]:
        """ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã®å›ç­”ã‹ã‚‰åˆ†ææƒ…å ±ã‚’æŠ½å‡º"""
        # JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return {
            "overall_compatibility_score": 75,
            "brand_alignment_score": 70,
            "brand_alignment_reasoning": "ãƒ†ã‚­ã‚¹ãƒˆè§£æã«ã‚ˆã‚‹æ¨å®šå€¤",
            "brand_strengths": ["é©åˆæ€§", "ä¿¡é ¼æ€§"],
            "brand_concerns": ["è©³ç´°åˆ†æãŒå¿…è¦"],
            "audience_synergy_score": 80,
            "demographic_overlap": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤ã®é‡è¤‡ãŒè¦‹è¾¼ã¾ã‚Œã‚‹",
            "engagement_quality": "è‰¯å¥½ãªã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ",
            "conversion_potential": "ä¸­ç¨‹åº¦ã®ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æœŸå¾…",
            "content_fit_score": 75,
            "style_compatibility": "é©åˆã™ã‚‹ã‚¹ã‚¿ã‚¤ãƒ«",
            "content_themes": ["å•†å“ç´¹ä»‹", "ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«"],
            "creative_opportunities": ["ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", "å‰µä½œæ´»å‹•"],
            "business_viability_score": 70,
            "roi_prediction": "è‰¯å¥½ãªROIãŒæœŸå¾…ã•ã‚Œã‚‹",
            "risk_assessment": "ä½ã€œä¸­ç¨‹åº¦ã®ãƒªã‚¹ã‚¯",
            "long_term_potential": "é•·æœŸçš„ãªé–¢ä¿‚æ§‹ç¯‰ã®å¯èƒ½æ€§",
            "confidence_level": "Medium",
            "primary_reason": text[:200] if text else "åˆ†æçµæœã‚’å–å¾—ä¸­",
            "success_scenario": "ãƒ–ãƒ©ãƒ³ãƒ‰èªçŸ¥åº¦å‘ä¸ŠãŒæœŸå¾…ã•ã‚Œã‚‹",
            "collaboration_strategy": "æ®µéšçš„ãªã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "expected_outcomes": ["èªçŸ¥åº¦å‘ä¸Š", "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå¢—åŠ "],
            "collaboration_types": ["å•†å“ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ã‚¹ãƒãƒ³ã‚µãƒ¼ãƒ‰"],
            "optimal_timing": "3-6ãƒ¶æœˆ",
            "content_suggestions": ["å•†å“ä½“é¨“", "æ—¥å¸¸çµ±åˆ"],
            "budget_min": 80000,
            "budget_max": 150000,
            "budget_reasoning": "æ¨™æº–çš„ãªä¾¡æ ¼å¸¯ã§ã®æ¨å¥¨"
        }
    
    async def _analyze_portfolio_optimization(self, analysis_results: List[Dict[str, Any]], request_data: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–åˆ†æ"""
        try:
            # å…¨ä½“çš„ãªæˆ¦ç•¥ã‚¹ã‚³ã‚¢è¨ˆç®—
            total_scores = [result["overall_compatibility_score"] for result in analysis_results]
            overall_strategy_score = sum(total_scores) / len(total_scores) if total_scores else 0
            
            # å¤šæ§˜æ€§åˆ†æ
            categories = [result.get("detailed_analysis", {}).get("content_fit", {}).get("content_themes_match", []) for result in analysis_results]
            unique_categories = set()
            for cat_list in categories:
                unique_categories.update(cat_list)
            
            diversity_analysis = f"é¸å‡ºã•ã‚ŒãŸã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã¯{len(unique_categories)}ã®ç•°ãªã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ†ãƒ¼ãƒã‚’ã‚«ãƒãƒ¼ã—ã¦ãŠã‚Šã€ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã§ã™ã€‚"
            
            return {
                "overall_strategy_score": int(overall_strategy_score),
                "portfolio_balance": "ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼æ§‹æˆ",
                "diversity_analysis": diversity_analysis,
                "optimization_suggestions": [
                    "ãƒˆãƒƒãƒ—ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ¼ã¨ã®é•·æœŸå¥‘ç´„ã‚’å„ªå…ˆ",
                    "ç•°ãªã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¹ã‚¿ã‚¤ãƒ«ã®çµ„ã¿åˆã‚ã›ã§ãƒªãƒ¼ãƒã‚’æœ€å¤§åŒ–",
                    "æ®µéšçš„ãªäºˆç®—é…åˆ†ã§åŠ¹æœã‚’æ¸¬å®š"
                ]
            }
        except Exception as e:
            logger.error(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "overall_strategy_score": 75,
                "portfolio_balance": "ãƒãƒ©ãƒ³ã‚¹åˆ†æä¸­",
                "diversity_analysis": "å¤šæ§˜æ€§ã‚’è©•ä¾¡ä¸­",
                "optimization_suggestions": ["åˆ†æã‚’ç¶™ç¶šä¸­"]
            }
    
    async def _analyze_market_context(self, request_data: Dict[str, Any], analysis_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ"""
        try:
            company_industry = request_data.get('company_profile', {}).get('industry', '')
            
            # æ¥­ç•Œåˆ¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            industry_trends = {
                'ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼': ['AIæ´»ç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', 'ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', 'ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼è§£èª¬'],
                'ç¾å®¹ãƒ»åŒ–ç²§å“': ['ãƒ“ãƒ•ã‚©ãƒ¼ã‚¢ãƒ•ã‚¿ãƒ¼', 'ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ç´¹ä»‹', 'ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼'],
                'é£Ÿå“ãƒ»é£²æ–™': ['ãƒ¬ã‚·ãƒ”å‹•ç”»', 'é£Ÿä½“é¨“ãƒ¬ãƒãƒ¼ãƒˆ', 'ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ææ¡ˆ'],
                'ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³': ['ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ãƒˆææ¡ˆ', 'ãƒˆãƒ¬ãƒ³ãƒ‰è§£èª¬', 'ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°å‹•ç”»']
            }
            
            trends = industry_trends.get(company_industry, ['ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°', 'ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚³ãƒ©ãƒœ', 'ãƒ–ãƒ©ãƒ³ãƒ‰ã‚¹ãƒˆãƒ¼ãƒªãƒ¼'])
            
            return {
                "industry_trends": trends,
                "competitive_landscape": f"{company_industry}æ¥­ç•Œã«ãŠã‘ã‚‹ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã¯æ´»ç™ºã§ã€å·®åˆ¥åŒ–ãŒé‡è¦ã§ã™ã€‚",
                "timing_considerations": "ç¾åœ¨ã¯æ–°ã—ã„ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã™ã‚‹ã®ã«é©ã—ãŸæ™‚æœŸã§ã™ã€‚"
            }
        except Exception as e:
            logger.error(f"å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                "industry_trends": ["ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æä¸­"],
                "competitive_landscape": "ç«¶åˆçŠ¶æ³ã‚’åˆ†æä¸­",
                "timing_considerations": "ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è©•ä¾¡ä¸­"
            }
    
    def _calculate_overall_confidence(self, analysis_results: List[Dict[str, Any]]) -> float:
        """å…¨ä½“çš„ãªä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if not analysis_results:
            return 0.0
        
        confidence_map = {"High": 0.9, "Medium": 0.7, "Low": 0.4}
        confidences = [
            confidence_map.get(
                result.get("recommendation_summary", {}).get("confidence_level", "Medium"), 
                0.7
            ) for result in analysis_results
        ]
        
        return sum(confidences) / len(confidences)
    
    def _get_mock_influencers(self) -> List[Dict[str, Any]]:
        """ãƒ¢ãƒƒã‚¯ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™"""
        return [
            {
                "id": "mock_1",
                "channel_id": "UCMock1",
                "channel_name": "ã‚²ãƒ¼ãƒ å®Ÿæ³ãƒãƒ£ãƒ³ãƒãƒ«",
                "channel_title": "ã‚²ãƒ¼ãƒ å®Ÿæ³ãƒãƒ£ãƒ³ãƒãƒ«",
                "description": "äººæ°—ã‚²ãƒ¼ãƒ ã®å®Ÿæ³å‹•ç”»ã‚’æ¯æ—¥é…ä¿¡",
                "subscriber_count": 150000,
                "video_count": 500,
                "view_count": 50000000,
                "category": "ã‚²ãƒ¼ãƒ ",
                "engagement_rate": 0.08,
                "thumbnail_url": "https://via.placeholder.com/240x240"
            },
            {
                "id": "mock_2",
                "channel_id": "UCMock2",
                "channel_name": "æ–™ç†ãƒãƒ£ãƒ³ãƒãƒ«",
                "channel_title": "æ–™ç†ãƒãƒ£ãƒ³ãƒãƒ«",
                "description": "ç°¡å˜ãƒ¬ã‚·ãƒ”ã¨æ–™ç†ã®ã‚³ãƒ„ã‚’ç´¹ä»‹",
                "subscriber_count": 80000,
                "video_count": 300,
                "view_count": 20000000,
                "category": "æ–™ç†",
                "engagement_rate": 0.10,
                "thumbnail_url": "https://via.placeholder.com/240x240"
            },
            {
                "id": "mock_3",
                "channel_id": "UCMock3",
                "channel_name": "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ãƒãƒ£ãƒ³ãƒãƒ«",
                "channel_title": "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ãƒãƒ£ãƒ³ãƒãƒ«",
                "description": "å¥åº·çš„ãªãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã¨ãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¦ãƒˆ",
                "subscriber_count": 120000,
                "video_count": 400,
                "view_count": 35000000,
                "category": "ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹",
                "engagement_rate": 0.09,
                "thumbnail_url": "https://via.placeholder.com/240x240"
            }
        ]