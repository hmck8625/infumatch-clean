"""
äºˆæ¸¬åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
äº¤æ¸‰ã®æˆåŠŸç¢ºç‡ã¨æœ€é©ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’äºˆæ¸¬
"""
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from enum import Enum
import logging

# NumPyäº’æ›ã®ç°¡æ˜“å®Ÿè£…ï¼ˆCloud Runç’°å¢ƒç”¨ï¼‰
class np:
    @staticmethod
    def mean(values):
        if not values:
            return 0
        return sum(values) / len(values)
    
    @staticmethod
    def random():
        import random
        return random

class PredictionType(Enum):
    """äºˆæ¸¬ã‚¿ã‚¤ãƒ—"""
    SUCCESS_PROBABILITY = "success_probability"
    OPTIMAL_TIMING = "optimal_timing"
    BUDGET_CONVERGENCE = "budget_convergence"
    ENGAGEMENT_TREND = "engagement_trend"
    RISK_ASSESSMENT = "risk_assessment"

class PredictiveAnalyticsModule:
    """äºˆæ¸¬åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
    
    def __init__(self, pattern_storage, optimization_engine):
        self.pattern_storage = pattern_storage
        self.optimization_engine = optimization_engine
        
        # äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.model_params = {
            "time_decay_factor": 0.95,  # æ™‚é–“çµŒéã«ã‚ˆã‚‹é‡ã¿æ¸›è¡°
            "min_confidence_threshold": 0.6,
            "prediction_horizon_hours": 72,
            "feature_importance": {
                "response_time": 0.25,
                "sentiment_trend": 0.20,
                "budget_alignment": 0.20,
                "engagement_level": 0.15,
                "negotiation_stage": 0.10,
                "historical_success": 0.10
            }
        }
    
    async def generate_comprehensive_prediction(
        self,
        thread_id: str,
        current_state: Dict,
        conversation_history: List[Dict]
    ) -> Dict:
        """åŒ…æ‹¬çš„ãªäºˆæ¸¬ã‚’ç”Ÿæˆ"""
        
        print(f"ğŸ”® åŒ…æ‹¬çš„äºˆæ¸¬åˆ†æé–‹å§‹ - Thread: {thread_id}")
        
        # å„ç¨®äºˆæ¸¬ã‚’å®Ÿè¡Œ
        predictions = {
            "thread_id": thread_id,
            "timestamp": datetime.now().isoformat(),
            "current_stage": current_state.get("negotiation_stage", "unknown"),
            
            # æˆåŠŸç¢ºç‡äºˆæ¸¬
            "success_prediction": await self._predict_success_probability(
                current_state, conversation_history
            ),
            
            # ã‚¿ã‚¤ãƒŸãƒ³ã‚°äºˆæ¸¬
            "timing_prediction": await self._predict_optimal_timing(
                current_state, conversation_history
            ),
            
            # äºˆç®—åæŸäºˆæ¸¬
            "budget_prediction": await self._predict_budget_convergence(
                current_state, conversation_history
            ),
            
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬
            "engagement_prediction": await self._predict_engagement_trend(
                current_state, conversation_history
            ),
            
            # ãƒªã‚¹ã‚¯è©•ä¾¡
            "risk_assessment": await self._assess_negotiation_risks(
                current_state, conversation_history
            ),
            
            # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
            "recommended_actions": await self._generate_action_recommendations(
                current_state
            ),
            
            # å…¨ä½“çš„ãªä¿¡é ¼åº¦
            "overall_confidence": 0.0  # å¾Œã§è¨ˆç®—
        }
        
        # å…¨ä½“çš„ãªä¿¡é ¼åº¦ã‚’è¨ˆç®—
        confidence_scores = [
            predictions["success_prediction"]["confidence"],
            predictions["timing_prediction"]["confidence"],
            predictions["budget_prediction"]["confidence"],
            predictions["engagement_prediction"]["confidence"]
        ]
        predictions["overall_confidence"] = np.mean(confidence_scores)
        
        return predictions
    
    async def _predict_success_probability(
        self,
        current_state: Dict,
        conversation_history: List[Dict]
    ) -> Dict:
        """æˆåŠŸç¢ºç‡ã‚’äºˆæ¸¬"""
        
        # ç‰¹å¾´é‡ã‚’æŠ½å‡º
        features = self._extract_prediction_features(current_state, conversation_history)
        
        # å±¥æ­´ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰é¡ä¼¼ã‚±ãƒ¼ã‚¹ã‚’å–å¾—
        similar_patterns = await self.pattern_storage.find_similar_patterns(current_state)
        
        # ãƒ™ãƒ¼ã‚¹ç¢ºç‡
        base_probability = 0.5
        
        # ç‰¹å¾´é‡ã«ã‚ˆã‚‹èª¿æ•´
        probability_adjustments = []
        
        # å¿œç­”æ™‚é–“ã®å½±éŸ¿
        avg_response_time = features.get("avg_response_time_hours", 24)
        if avg_response_time < 6:
            probability_adjustments.append(0.15)
        elif avg_response_time < 24:
            probability_adjustments.append(0.05)
        else:
            probability_adjustments.append(-0.10)
        
        # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆå‚¾å‘
        sentiment_trend = features.get("sentiment_trend", 0)
        probability_adjustments.append(sentiment_trend * 0.2)
        
        # äºˆç®—ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ
        budget_alignment = features.get("budget_alignment_score", 0.5)
        probability_adjustments.append((budget_alignment - 0.5) * 0.3)
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«
        engagement_score = features.get("engagement_score", 0.5)
        probability_adjustments.append((engagement_score - 0.5) * 0.25)
        
        # å±¥æ­´æˆåŠŸç‡
        if similar_patterns:
            historical_success_rate = self._calculate_historical_success_rate(similar_patterns)
            probability_adjustments.append((historical_success_rate - 0.5) * 0.4)
        
        # æœ€çµ‚ç¢ºç‡ã‚’è¨ˆç®—
        final_probability = base_probability + sum(probability_adjustments)
        final_probability = max(0.05, min(0.95, final_probability))  # 5%-95%ã«åˆ¶é™
        
        # ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—
        confidence_interval = self._calculate_confidence_interval(
            final_probability, len(similar_patterns)
        )
        
        return {
            "probability": final_probability,
            "confidence": self._calculate_prediction_confidence(features, similar_patterns),
            "confidence_interval": confidence_interval,
            "key_factors": self._identify_key_factors(probability_adjustments, features),
            "trend": self._calculate_probability_trend(current_state, conversation_history)
        }
    
    async def _predict_optimal_timing(
        self,
        current_state: Dict,
        conversation_history: List[Dict]
    ) -> Dict:
        """æœ€é©ãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’äºˆæ¸¬"""
        
        # ç¾åœ¨ã®å‹¢ã„ã‚’åˆ†æ
        momentum = self._analyze_conversation_momentum(conversation_history)
        
        # ç›¸æ‰‹ã®å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        response_pattern = self._analyze_response_pattern(conversation_history)
        
        # æœ€é©ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æ±ºå®š
        if momentum > 0.7 and response_pattern["avg_response_hours"] < 6:
            optimal_action = "immediate_follow_up"
            timing_window = "0-2æ™‚é–“ä»¥å†…"
            reasoning = "é«˜ã„å‹¢ã„ã¨è¿…é€Ÿãªå¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³"
        elif momentum > 0.5:
            optimal_action = "timely_response"
            timing_window = "2-6æ™‚é–“ä»¥å†…"
            reasoning = "è‰¯å¥½ãªé€²å±•ã¨å®‰å®šã—ãŸå¯¾è©±"
        elif response_pattern["pattern"] == "business_hours":
            optimal_action = "next_business_day"
            timing_window = "ç¿Œå–¶æ¥­æ—¥ã®åˆå‰ä¸­"
            reasoning = "ãƒ“ã‚¸ãƒã‚¹ã‚¢ãƒ¯ãƒ¼ä¸­å¿ƒã®å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³"
        else:
            optimal_action = "strategic_pause"
            timing_window = "24-48æ™‚é–“å¾Œ"
            reasoning = "ç†Ÿè€ƒã‚’ä¿ƒã™æˆ¦ç•¥çš„ãªé–“"
        
        return {
            "optimal_action": optimal_action,
            "timing_window": timing_window,
            "reasoning": reasoning,
            "urgency_score": momentum,
            "response_pattern": response_pattern,
            "confidence": 0.7 + (0.3 * min(len(conversation_history) / 10, 1.0))
        }
    
    async def _predict_budget_convergence(
        self,
        current_state: Dict,
        conversation_history: List[Dict]
    ) -> Dict:
        """äºˆç®—åæŸã‚’äºˆæ¸¬"""
        
        # äºˆç®—é–¢é€£ã®è¨€åŠã‚’æŠ½å‡º
        budget_mentions = self._extract_budget_mentions(conversation_history)
        
        if not budget_mentions:
            return {
                "convergence_probability": 0.5,
                "estimated_final_range": None,
                "negotiation_room": "unknown",
                "confidence": 0.3,
                "status": "no_budget_discussion"
            }
        
        # äºˆç®—ã®æ¨ç§»ã‚’åˆ†æ
        budget_trajectory = self._analyze_budget_trajectory(budget_mentions)
        
        # åæŸç‚¹ã‚’äºˆæ¸¬
        if budget_trajectory["trend"] == "converging":
            convergence_prob = 0.8
            estimated_range = budget_trajectory["projected_range"]
            negotiation_room = "limited"
        elif budget_trajectory["trend"] == "diverging":
            convergence_prob = 0.3
            estimated_range = budget_trajectory["current_gap"]
            negotiation_room = "significant"
        else:
            convergence_prob = 0.5
            estimated_range = budget_trajectory["average_range"]
            negotiation_room = "moderate"
        
        return {
            "convergence_probability": convergence_prob,
            "estimated_final_range": estimated_range,
            "negotiation_room": negotiation_room,
            "trajectory": budget_trajectory,
            "confidence": 0.5 + (0.4 * len(budget_mentions) / 5),
            "recommendation": self._generate_budget_recommendation(budget_trajectory)
        }
    
    async def _predict_engagement_trend(
        self,
        current_state: Dict,
        conversation_history: List[Dict]
    ) -> Dict:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‚¾å‘ã‚’äºˆæ¸¬"""
        
        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™ã‚’è¨ˆç®—
        engagement_metrics = self._calculate_engagement_metrics(conversation_history)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ
        if len(conversation_history) < 3:
            trend = "insufficient_data"
            prediction = "stable"
        else:
            recent_engagement = engagement_metrics["recent_score"]
            overall_engagement = engagement_metrics["overall_score"]
            
            if recent_engagement > overall_engagement * 1.2:
                trend = "increasing"
                prediction = "continued_high_engagement"
            elif recent_engagement < overall_engagement * 0.8:
                trend = "decreasing"
                prediction = "risk_of_disengagement"
            else:
                trend = "stable"
                prediction = "maintained_engagement"
        
        # æ¬¡ã®3ãƒ©ã‚¦ãƒ³ãƒ‰ã®äºˆæ¸¬
        future_engagement = self._project_future_engagement(
            engagement_metrics, trend
        )
        
        return {
            "current_level": engagement_metrics["overall_score"],
            "trend": trend,
            "prediction": prediction,
            "future_projection": future_engagement,
            "risk_indicators": engagement_metrics["risk_indicators"],
            "opportunity_indicators": engagement_metrics["opportunity_indicators"],
            "confidence": engagement_metrics["confidence"]
        }
    
    async def _assess_negotiation_risks(
        self,
        current_state: Dict,
        conversation_history: List[Dict]
    ) -> Dict:
        """äº¤æ¸‰ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡"""
        
        risks = {
            "overall_risk_level": "medium",
            "risk_factors": [],
            "mitigation_strategies": [],
            "early_warning_signs": []
        }
        
        # å„ãƒªã‚¹ã‚¯è¦å› ã‚’è©•ä¾¡
        risk_scores = {}
        
        # 1. å¿œç­”é…å»¶ãƒªã‚¹ã‚¯
        response_delays = self._check_response_delays(conversation_history)
        if response_delays["max_delay_hours"] > 48:
            risk_scores["response_delay"] = 0.8
            risks["risk_factors"].append({
                "type": "response_delay",
                "severity": "high",
                "description": "å¿œç­”æ™‚é–“ã®é•·æœŸåŒ–",
                "impact": "é–¢å¿ƒã®ä½ä¸‹ã‚„ä»–ç¤¾ã¸ã®æµå‡º"
            })
            risks["mitigation_strategies"].append(
                "è¿…é€Ÿãªãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã¨ä¾¡å€¤ã®å†å¼·èª¿"
            )
        
        # 2. äºˆç®—ãƒŸã‚¹ãƒãƒƒãƒãƒªã‚¹ã‚¯
        budget_gap = current_state.get("budget_gap_percentage", 0)
        if budget_gap > 30:
            risk_scores["budget_mismatch"] = 0.9
            risks["risk_factors"].append({
                "type": "budget_mismatch",
                "severity": "high",
                "description": "äºˆç®—æœŸå¾…å€¤ã®å¤§ããªä¹–é›¢",
                "impact": "äº¤æ¸‰æ±ºè£‚ã®å¯èƒ½æ€§"
            })
            risks["mitigation_strategies"].append(
                "æ®µéšçš„ãªä¾¡å€¤ææ¡ˆã¨æŸ”è»Ÿãªä¾¡æ ¼ã‚ªãƒ—ã‚·ãƒ§ãƒ³"
            )
        
        # 3. ç«¶åˆãƒªã‚¹ã‚¯
        competitor_mentions = self._detect_competitor_mentions(conversation_history)
        if competitor_mentions > 0:
            risk_scores["competition"] = 0.7
            risks["risk_factors"].append({
                "type": "competition",
                "severity": "medium",
                "description": "ç«¶åˆä»–ç¤¾ã®å­˜åœ¨",
                "impact": "ä¾¡æ ¼ç«¶äº‰ã‚„æ¡ä»¶æ¯”è¼ƒ"
            })
            risks["mitigation_strategies"].append(
                "ç‹¬è‡ªä¾¡å€¤ã®å¼·èª¿ã¨å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆã®æ˜ç¢ºåŒ–"
            )
        
        # 4. ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³åœæ»ãƒªã‚¹ã‚¯
        if current_state.get("rounds_without_progress", 0) > 2:
            risk_scores["stagnation"] = 0.6
            risks["risk_factors"].append({
                "type": "stagnation",
                "severity": "medium",
                "description": "äº¤æ¸‰ã®åœæ»",
                "impact": "ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã®å–ªå¤±"
            })
            risks["mitigation_strategies"].append(
                "æ–°ã—ã„ææ¡ˆã‚„è¦–ç‚¹ã®å°å…¥"
            )
        
        # å…¨ä½“çš„ãªãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        if risk_scores:
            avg_risk = np.mean(list(risk_scores.values()))
            if avg_risk > 0.7:
                risks["overall_risk_level"] = "high"
            elif avg_risk > 0.4:
                risks["overall_risk_level"] = "medium"
            else:
                risks["overall_risk_level"] = "low"
        
        # æ—©æœŸè­¦å‘Šã‚µã‚¤ãƒ³
        risks["early_warning_signs"] = [
            "è¿”ä¿¡é–“éš”ã®æ€¥æ¿€ãªå»¶é•·",
            "è³ªå•ã®æ¸›å°‘ã‚„å…·ä½“æ€§ã®æ¬ å¦‚",
            "ä¾¡æ ¼ã«é–¢ã™ã‚‹ç¹°ã‚Šè¿”ã—ã®æ‡¸å¿µè¡¨æ˜",
            "æ„æ€æ±ºå®šã®å…ˆå»¶ã°ã—"
        ]
        
        return risks
    
    async def _generate_action_recommendations(
        self,
        current_state: Dict
    ) -> List[Dict]:
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ¨å¥¨ã‚’ç”Ÿæˆ"""
        
        recommendations = []
        stage = current_state.get("negotiation_stage", "unknown")
        
        # ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ã®æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        if stage == "initial_contact":
            recommendations.append({
                "action": "build_rapport",
                "description": "ä¿¡é ¼é–¢ä¿‚ã®æ§‹ç¯‰ã«æ³¨åŠ›",
                "specific_steps": [
                    "ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸææ¡ˆã®ä½œæˆ",
                    "éå»ã®æˆåŠŸäº‹ä¾‹ã®å…±æœ‰",
                    "ç›¸æ‰‹ã®ãƒ‹ãƒ¼ã‚ºã®æ·±æ˜ã‚Š"
                ],
                "priority": "high",
                "expected_impact": "é–¢å¿ƒåº¦ã®å‘ä¸Š"
            })
        
        elif stage == "condition_negotiation":
            recommendations.append({
                "action": "value_reinforcement",
                "description": "ä¾¡å€¤ææ¡ˆã®å¼·åŒ–",
                "specific_steps": [
                    "ROIã®å…·ä½“çš„ãªæç¤º",
                    "è¿½åŠ ç‰¹å…¸ã®ææ¡ˆ",
                    "æŸ”è»Ÿãªæ”¯æ‰•ã„æ¡ä»¶ã®æç¤º"
                ],
                "priority": "high",
                "expected_impact": "åˆæ„ç¢ºç‡ã®å‘ä¸Š"
            })
        
        elif stage == "final_agreement":
            recommendations.append({
                "action": "close_deal",
                "description": "ã‚¯ãƒ­ãƒ¼ã‚¸ãƒ³ã‚°ã®å®Ÿè¡Œ",
                "specific_steps": [
                    "æœ€çµ‚æ¡ä»¶ã®æ˜ç¢ºãªæç¤º",
                    "æœŸé™ä»˜ãã‚¤ãƒ³ã‚»ãƒ³ãƒ†ã‚£ãƒ–",
                    "æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å…·ä½“åŒ–"
                ],
                "priority": "critical",
                "expected_impact": "å–å¼•æˆç«‹"
            })
        
        # ãƒªã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®æ¨å¥¨
        if current_state.get("risk_level", "medium") == "high":
            recommendations.append({
                "action": "risk_mitigation",
                "description": "ãƒªã‚¹ã‚¯è»½æ¸›ç­–ã®å®Ÿè¡Œ",
                "specific_steps": [
                    "æ‡¸å¿µäº‹é …ã®ç›´æ¥çš„ãªå¯¾å‡¦",
                    "ä¿è¨¼ã‚„è©¦ç”¨æœŸé–“ã®æä¾›",
                    "æ®µéšçš„ãªå°å…¥ãƒ—ãƒ©ãƒ³ã®ææ¡ˆ"
                ],
                "priority": "high",
                "expected_impact": "ãƒªã‚¹ã‚¯è¦å› ã®è§£æ¶ˆ"
            })
        
        return recommendations
    
    def _extract_prediction_features(
        self,
        current_state: Dict,
        conversation_history: List[Dict]
    ) -> Dict:
        """äºˆæ¸¬ç”¨ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
        
        features = {
            "conversation_length": len(conversation_history),
            "current_stage": current_state.get("negotiation_stage", "unknown"),
            "rounds_count": current_state.get("round_number", 1),
            "avg_response_time_hours": self._calculate_avg_response_time(conversation_history),
            "sentiment_trend": self._calculate_sentiment_trend(conversation_history),
            "budget_alignment_score": self._calculate_budget_alignment(current_state),
            "engagement_score": self._calculate_engagement_score(conversation_history),
            "message_length_trend": self._analyze_message_length_trend(conversation_history),
            "question_ratio": self._calculate_question_ratio(conversation_history),
            "positive_signal_count": self._count_positive_signals(conversation_history)
        }
        
        return features
    
    def _calculate_historical_success_rate(self, patterns: List[Dict]) -> float:
        """å±¥æ­´æˆåŠŸç‡ã‚’è¨ˆç®—"""
        
        if not patterns:
            return 0.5
        
        success_count = sum(
            1 for p in patterns 
            if p.get("pattern_type") in ["success", "partial"]
        )
        
        return success_count / len(patterns)
    
    def _calculate_confidence_interval(
        self,
        probability: float,
        sample_size: int
    ) -> List[float]:
        """ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—"""
        
        # ç°¡æ˜“çš„ãªä¿¡é ¼åŒºé–“è¨ˆç®—
        if sample_size < 5:
            margin = 0.2
        elif sample_size < 20:
            margin = 0.1
        else:
            margin = 0.05
        
        return [
            max(0, probability - margin),
            min(1, probability + margin)
        ]
    
    def _calculate_prediction_confidence(
        self,
        features: Dict,
        similar_patterns: List[Dict]
    ) -> float:
        """äºˆæ¸¬ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—"""
        
        confidence = 0.5
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã«ã‚ˆã‚‹ä¿¡é ¼åº¦
        pattern_count = len(similar_patterns)
        if pattern_count >= 20:
            confidence += 0.3
        elif pattern_count >= 10:
            confidence += 0.2
        elif pattern_count >= 5:
            confidence += 0.1
        
        # ä¼šè©±ã®é•·ã•ã«ã‚ˆã‚‹ä¿¡é ¼åº¦
        conv_length = features.get("conversation_length", 0)
        if conv_length >= 10:
            confidence += 0.15
        elif conv_length >= 5:
            confidence += 0.1
        
        # ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ€§
        if features.get("budget_alignment_score", 0) > 0:
            confidence += 0.05
        
        return min(confidence, 0.95)
    
    def _identify_key_factors(
        self,
        adjustments: List[float],
        features: Dict
    ) -> List[Dict]:
        """ä¸»è¦ãªå½±éŸ¿è¦å› ã‚’ç‰¹å®š"""
        
        factor_names = [
            "å¿œç­”æ™‚é–“",
            "æ„Ÿæƒ…å‚¾å‘",
            "äºˆç®—é©åˆæ€§",
            "ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ",
            "éå»ã®æˆåŠŸç‡"
        ]
        
        factors = []
        for i, (name, adjustment) in enumerate(zip(factor_names, adjustments)):
            if abs(adjustment) > 0.05:
                factors.append({
                    "factor": name,
                    "impact": "positive" if adjustment > 0 else "negative",
                    "magnitude": abs(adjustment)
                })
        
        # å½±éŸ¿åº¦ã§ã‚½ãƒ¼ãƒˆ
        factors.sort(key=lambda x: x["magnitude"], reverse=True)
        
        return factors[:3]  # ä¸Šä½3ã¤
    
    def _calculate_probability_trend(
        self,
        current_state: Dict,
        conversation_history: List[Dict]
    ) -> str:
        """ç¢ºç‡ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—"""
        
        if len(conversation_history) < 3:
            return "stable"
        
        # æœ€è¿‘ã®ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚·ã‚°ãƒŠãƒ«
        recent_positive = self._count_positive_signals(conversation_history[-3:])
        overall_positive = self._count_positive_signals(conversation_history)
        
        recent_rate = recent_positive / 3
        overall_rate = overall_positive / len(conversation_history)
        
        if recent_rate > overall_rate * 1.2:
            return "improving"
        elif recent_rate < overall_rate * 0.8:
            return "declining"
        else:
            return "stable"
    
    def _analyze_conversation_momentum(
        self,
        conversation_history: List[Dict]
    ) -> float:
        """ä¼šè©±ã®å‹¢ã„ã‚’åˆ†æ"""
        
        if len(conversation_history) < 2:
            return 0.5
        
        # å¿œç­”é–“éš”ã®çŸ­ç¸®
        response_times = []
        for i in range(1, len(conversation_history)):
            # ç°¡æ˜“çš„ãªæ™‚é–“å·®è¨ˆç®—
            response_times.append(1)  # å®Ÿéš›ã¯æ™‚åˆ»å·®ã‚’è¨ˆç®—
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é•·ã®å¢—åŠ 
        recent_length = np.mean([
            len(msg.get("content", "")) 
            for msg in conversation_history[-3:]
        ])
        
        # ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚·ã‚°ãƒŠãƒ«
        positive_signals = self._count_positive_signals(conversation_history[-3:])
        
        # ç·åˆçš„ãªå‹¢ã„ã‚¹ã‚³ã‚¢
        momentum = 0.3 + (positive_signals / 3) * 0.4 + min(recent_length / 500, 0.3)
        
        return min(momentum, 1.0)
    
    def _analyze_response_pattern(
        self,
        conversation_history: List[Dict]
    ) -> Dict:
        """å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        
        # ç°¡æ˜“å®Ÿè£…
        return {
            "pattern": "business_hours",
            "avg_response_hours": 12,
            "consistency": 0.7,
            "preferred_time": "10:00-18:00"
        }
    
    def _extract_budget_mentions(
        self,
        conversation_history: List[Dict]
    ) -> List[Dict]:
        """äºˆç®—ã«é–¢ã™ã‚‹è¨€åŠã‚’æŠ½å‡º"""
        
        budget_mentions = []
        budget_keywords = ["äºˆç®—", "ä¾¡æ ¼", "è²»ç”¨", "æ–™é‡‘", "å††", "ä¸‡å††"]
        
        for i, msg in enumerate(conversation_history):
            content = msg.get("content", "").lower()
            if any(keyword in content for keyword in budget_keywords):
                # ç°¡æ˜“çš„ãªé‡‘é¡æŠ½å‡º
                budget_mentions.append({
                    "message_index": i,
                    "content": content[:100],
                    "role": msg.get("role", "user")
                })
        
        return budget_mentions
    
    def _analyze_budget_trajectory(
        self,
        budget_mentions: List[Dict]
    ) -> Dict:
        """äºˆç®—ã®æ¨ç§»ã‚’åˆ†æ"""
        
        # ç°¡æ˜“å®Ÿè£…
        return {
            "trend": "converging",
            "projected_range": {"min": 300000, "max": 500000},
            "current_gap": 200000,
            "average_range": {"min": 350000, "max": 450000}
        }
    
    def _generate_budget_recommendation(
        self,
        trajectory: Dict
    ) -> str:
        """äºˆç®—ã«é–¢ã™ã‚‹æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        
        if trajectory["trend"] == "converging":
            return "ç¾åœ¨ã®èª¿æ•´ãƒšãƒ¼ã‚¹ã‚’ç¶­æŒã—ã€è¿½åŠ ä¾¡å€¤ã®æç¤ºã§æœ€çµ‚åˆæ„ã¸"
        elif trajectory["trend"] == "diverging":
            return "æœŸå¾…å€¤ã®ãƒªã‚»ãƒƒãƒˆã¨æ®µéšçš„ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®æç¤º"
        else:
            return "æ˜ç¢ºãªä¾¡å€¤ææ¡ˆã¨æŸ”è»Ÿãªä¾¡æ ¼æ§‹é€ ã®æç¤º"
    
    def _calculate_engagement_metrics(
        self,
        conversation_history: List[Dict]
    ) -> Dict:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™ã‚’è¨ˆç®—"""
        
        if not conversation_history:
            return {
                "overall_score": 0.5,
                "recent_score": 0.5,
                "risk_indicators": [],
                "opportunity_indicators": [],
                "confidence": 0.3
            }
        
        # å…¨ä½“ã‚¹ã‚³ã‚¢
        overall_score = 0.5
        
        # è³ªå•ã®æ•°
        question_count = sum(
            1 for msg in conversation_history 
            if "?" in msg.get("content", "")
        )
        overall_score += (question_count / len(conversation_history)) * 0.3
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é•·ã•
        avg_length = np.mean([
            len(msg.get("content", "")) 
            for msg in conversation_history
        ])
        overall_score += min(avg_length / 300, 0.2)
        
        # æœ€è¿‘ã®ã‚¹ã‚³ã‚¢ï¼ˆç›´è¿‘3ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
        recent_messages = conversation_history[-3:]
        recent_score = 0.5
        if recent_messages:
            recent_questions = sum(
                1 for msg in recent_messages 
                if "?" in msg.get("content", "")
            )
            recent_score += (recent_questions / len(recent_messages)) * 0.5
        
        return {
            "overall_score": min(overall_score, 1.0),
            "recent_score": min(recent_score, 1.0),
            "risk_indicators": ["è¿”ä¿¡é…å»¶"] if overall_score < 0.4 else [],
            "opportunity_indicators": ["é«˜é–¢å¿ƒ"] if overall_score > 0.7 else [],
            "confidence": 0.5 + (len(conversation_history) / 20)
        }
    
    def _project_future_engagement(
        self,
        metrics: Dict,
        trend: str
    ) -> List[float]:
        """å°†æ¥ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’äºˆæ¸¬"""
        
        current = metrics["overall_score"]
        
        if trend == "increasing":
            return [
                min(current * 1.1, 0.9),
                min(current * 1.15, 0.85),
                min(current * 1.1, 0.8)
            ]
        elif trend == "decreasing":
            return [
                max(current * 0.9, 0.3),
                max(current * 0.85, 0.25),
                max(current * 0.8, 0.2)
            ]
        else:
            return [current, current * 0.95, current * 0.9]
    
    def _check_response_delays(
        self,
        conversation_history: List[Dict]
    ) -> Dict:
        """å¿œç­”é…å»¶ã‚’ãƒã‚§ãƒƒã‚¯"""
        
        # ç°¡æ˜“å®Ÿè£…
        return {
            "max_delay_hours": 24,
            "avg_delay_hours": 12,
            "trend": "stable"
        }
    
    def _detect_competitor_mentions(
        self,
        conversation_history: List[Dict]
    ) -> int:
        """ç«¶åˆä»–ç¤¾ã¸ã®è¨€åŠã‚’æ¤œå‡º"""
        
        competitor_keywords = ["ä»–ç¤¾", "åˆ¥ã®", "æ¯”è¼ƒ", "æ¤œè¨ä¸­", "ã‚ªãƒ•ã‚¡ãƒ¼"]
        count = 0
        
        for msg in conversation_history:
            content = msg.get("content", "").lower()
            if any(keyword in content for keyword in competitor_keywords):
                count += 1
        
        return count
    
    def _calculate_avg_response_time(
        self,
        conversation_history: List[Dict]
    ) -> float:
        """å¹³å‡å¿œç­”æ™‚é–“ã‚’è¨ˆç®—"""
        
        # ç°¡æ˜“å®Ÿè£…
        return 12.0
    
    def _calculate_sentiment_trend(
        self,
        conversation_history: List[Dict]
    ) -> float:
        """æ„Ÿæƒ…ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è¨ˆç®—"""
        
        # ç°¡æ˜“å®Ÿè£…ï¼šãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ãƒ‰ã®ã‚«ã‚¦ãƒ³ãƒˆ
        positive_words = ["ã„ã„ã­", "ç´ æ™´ã‚‰ã—ã„", "èˆˆå‘³", "ãœã²", "æ¥½ã—ã¿"]
        negative_words = ["é›£ã—ã„", "å³ã—ã„", "å¿ƒé…", "ä¸å®‰", "é«˜ã„"]
        
        positive_count = 0
        negative_count = 0
        
        for msg in conversation_history:
            content = msg.get("content", "").lower()
            positive_count += sum(1 for word in positive_words if word in content)
            negative_count += sum(1 for word in negative_words if word in content)
        
        if positive_count + negative_count == 0:
            return 0.0
        
        return (positive_count - negative_count) / (positive_count + negative_count)
    
    def _calculate_budget_alignment(
        self,
        current_state: Dict
    ) -> float:
        """äºˆç®—é©åˆåº¦ã‚’è¨ˆç®—"""
        
        gap = current_state.get("budget_gap_percentage", 50)
        return max(0, 1 - (gap / 100))
    
    def _calculate_engagement_score(
        self,
        conversation_history: List[Dict]
    ) -> float:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
        
        metrics = self._calculate_engagement_metrics(conversation_history)
        return metrics["overall_score"]
    
    def _analyze_message_length_trend(
        self,
        conversation_history: List[Dict]
    ) -> str:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é•·ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æ"""
        
        if len(conversation_history) < 3:
            return "stable"
        
        lengths = [len(msg.get("content", "")) for msg in conversation_history]
        recent_avg = np.mean(lengths[-3:])
        overall_avg = np.mean(lengths)
        
        if recent_avg > overall_avg * 1.2:
            return "increasing"
        elif recent_avg < overall_avg * 0.8:
            return "decreasing"
        else:
            return "stable"
    
    def _calculate_question_ratio(
        self,
        conversation_history: List[Dict]
    ) -> float:
        """è³ªå•ã®å‰²åˆã‚’è¨ˆç®—"""
        
        if not conversation_history:
            return 0.0
        
        question_count = sum(
            1 for msg in conversation_history 
            if "?" in msg.get("content", "")
        )
        
        return question_count / len(conversation_history)
    
    def _count_positive_signals(
        self,
        messages: List[Dict]
    ) -> int:
        """ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚·ã‚°ãƒŠãƒ«ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        
        positive_phrases = [
            "ã„ã„ã§ã™ã­", "èˆˆå‘³ãŒã‚ã‚Šã¾ã™", "å‰å‘ãã«", "æ¤œè¨ã—ã¾ã™",
            "ãœã²", "æ¥½ã—ã¿", "ç´ æ™´ã‚‰ã—ã„", "ã‚ã‚ŠãŒã¨ã†"
        ]
        
        count = 0
        for msg in messages:
            content = msg.get("content", "").lower()
            count += sum(1 for phrase in positive_phrases if phrase in content)
        
        return count