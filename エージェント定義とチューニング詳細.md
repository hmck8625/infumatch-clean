# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®šç¾©ã¨ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°è©³ç´°è¨­è¨ˆ

## ğŸ¯ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–‹ç™ºã®å…¨ä½“åƒ

### Google Agentspace ã‚’æ´»ç”¨ã—ãŸ3ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

```mermaid
graph TD
    A[Google Agentspace<br>åŸºç›¤] --> B[ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†<br>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ]
    A --> C[ææ¡ˆ<br>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ]
    A --> D[äº¤æ¸‰<br>ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ]
    
    B --> E[Vertex AI<br>è£œåŠ©]
    C --> F[BigQuery<br>ãƒ‡ãƒ¼ã‚¿åˆ†æ]
    D --> G[ä¼šè©±å±¥æ­´<br>ç®¡ç†]
```

## 1ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

### åŸºæœ¬å®šç¾©

```yaml
agent_name: "DataPreprocessingAgent"
description: "YouTube APIã‹ã‚‰å–å¾—ã—ãŸç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’é«˜åº¦ã«åˆ†æãƒ»åŠ å·¥"
model: "gemini-1.5-pro"
temperature: 0.3  # ç²¾åº¦é‡è¦–ã§ä½ã‚ã«è¨­å®š
max_tokens: 4096
```

### ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ

```python
SYSTEM_PROMPT = """
ã‚ãªãŸã¯YouTubeãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ã®åˆ†æå°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®å½¹å‰²ã‚’æŒã¡ã¾ã™ï¼š

1. ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹æŠ½å‡º
   - ãƒãƒ£ãƒ³ãƒãƒ«èª¬æ˜æ–‡ã‹ã‚‰æ­£ç¢ºã«ãƒ“ã‚¸ãƒã‚¹ç”¨ãƒ¡ãƒ¼ãƒ«ã‚’ç‰¹å®š
   - ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ1-10ï¼‰ã‚’ä»˜ä¸
   - ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”¨é€”ã‚’æ¨æ¸¬

2. ã‚«ãƒ†ã‚´ãƒªåˆ†æ
   - å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ã€èª¬æ˜æ–‡ã€ã‚¿ã‚°ã‹ã‚‰ç·åˆçš„ã«åˆ¤æ–­
   - è¤‡æ•°ã‚«ãƒ†ã‚´ãƒªã®å¯èƒ½æ€§ã‚’è€ƒæ…®
   - ä¿¡é ¼åº¦ä»˜ãã§åˆ†é¡

3. ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆåˆ†æ
   - ç™»éŒ²è€…æ•°ã«å¯¾ã™ã‚‹å¹³å‡è¦–è´å›æ•°ã®æ¯”ç‡
   - ã‚³ãƒ¡ãƒ³ãƒˆç‡ã€ã„ã„ã­ç‡ã®ç®—å‡º
   - æˆé•·ãƒˆãƒ¬ãƒ³ãƒ‰ã®åˆ†æ

4. ãƒ“ã‚¸ãƒã‚¹é©æ€§è©•ä¾¡
   - PRæ¡ˆä»¶ã®å—ã‘å…¥ã‚Œå¯èƒ½æ€§
   - éå»ã®ã‚¿ã‚¤ã‚¢ãƒƒãƒ—å®Ÿç¸¾ã®æ¨æ¸¬
   - æ¨å¥¨ã•ã‚Œã‚‹å•†æã‚«ãƒ†ã‚´ãƒª

å‡ºåŠ›ã¯å¿…ãšæ§‹é€ åŒ–ã•ã‚ŒãŸJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¿”ã—ã¦ãã ã•ã„ã€‚
"""
```

### ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•

#### A. Few-shot Learning ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š

```python
class DataPreprocessingAgentTuner:
    def __init__(self):
        self.training_examples = []
        
    def add_training_example(self, input_data, expected_output, actual_output):
        """å­¦ç¿’ç”¨ã‚µãƒ³ãƒ—ãƒ«ã®è¿½åŠ """
        self.training_examples.append({
            'input': input_data,
            'expected': expected_output,
            'actual': actual_output,
            'accuracy': self.calculate_accuracy(expected_output, actual_output)
        })
    
    def generate_improved_prompt(self):
        """æˆåŠŸä¾‹ã‚’åŸºã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ”¹å–„"""
        high_accuracy_examples = [
            ex for ex in self.training_examples 
            if ex['accuracy'] > 0.9
        ]
        
        few_shot_prompt = "ä»¥ä¸‹ã¯å„ªã‚ŒãŸåˆ†æä¾‹ã§ã™ï¼š\n\n"
        for ex in high_accuracy_examples[:3]:  # ä¸Šä½3ä¾‹
            few_shot_prompt += f"å…¥åŠ›: {ex['input']}\n"
            few_shot_prompt += f"å‡ºåŠ›: {ex['expected']}\n\n"
            
        return SYSTEM_PROMPT + "\n\n" + few_shot_prompt
```

#### B. A/Bãƒ†ã‚¹ãƒˆã«ã‚ˆã‚‹ç¶™ç¶šçš„æ”¹å–„

```python
class ABTestFramework:
    def __init__(self):
        self.variants = {
            'A': {'prompt': SYSTEM_PROMPT, 'success_rate': 0},
            'B': {'prompt': IMPROVED_PROMPT, 'success_rate': 0}
        }
        
    async def process_with_ab_test(self, channel_data):
        variant = random.choice(['A', 'B'])
        result = await self.process_with_variant(channel_data, variant)
        
        # æˆåŠŸåˆ¤å®šï¼ˆãƒ¡ãƒ¼ãƒ«æŠ½å‡ºæˆåŠŸã€ã‚«ãƒ†ã‚´ãƒªé©åˆãªã©ï¼‰
        if self.evaluate_success(result):
            self.variants[variant]['success_rate'] += 1
            
        return result, variant
```

## 2ï¸âƒ£ ææ¡ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

### åŸºæœ¬å®šç¾©

```yaml
agent_name: "RecommendationAgent"
description: "ä¼æ¥­ãƒ‹ãƒ¼ã‚ºã«æœ€é©ãªã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã‚’AIãŒææ¡ˆ"
model: "gemini-1.5-flash"  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹é€Ÿåº¦é‡è¦–
temperature: 0.7  # å‰µé€ æ€§ã¨ã®ãƒãƒ©ãƒ³ã‚¹
max_tokens: 2048
```

### ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç®¡ç†

```python
class RecommendationContext:
    def __init__(self):
        self.company_profile = {}
        self.past_campaigns = []
        self.success_metrics = {}
        
    def build_context_prompt(self, campaign_request):
        return f"""
        ## ä¼æ¥­ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«
        æ¥­ç•Œ: {self.company_profile.get('industry')}
        éå»ã®æˆåŠŸã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³: {self.summarize_successes()}
        
        ## ä»Šå›ã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³è¦ä»¶
        å•†æ: {campaign_request['product']}
        äºˆç®—: {campaign_request['budget']}
        ç›®æ¨™: {campaign_request['objective']}
        
        ## åˆ†ææŒ‡ç¤º
        1. ã“ã®ä¼æ¥­ã«æœ€é©ãªã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®ç‰¹å¾´ã‚’åˆ†æ
        2. éå»ã®æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è€ƒæ…®
        3. äºˆç®—å†…ã§æœ€å¤§åŠ¹æœã‚’å¾—ã‚‰ã‚Œã‚‹çµ„ã¿åˆã‚ã›ã‚’ææ¡ˆ
        """
```

### å‹•çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´

```python
class DynamicTuning:
    def __init__(self):
        self.performance_history = []
        
    def adjust_parameters(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«åŸºã¥ã„ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª¿æ•´"""
        recent_performance = self.performance_history[-10:]
        avg_satisfaction = np.mean([p['satisfaction'] for p in recent_performance])
        
        if avg_satisfaction < 0.7:
            # æº€è¶³åº¦ãŒä½ã„å ´åˆã¯ã€ã‚ˆã‚Šä¿å®ˆçš„ã«
            return {
                'temperature': 0.5,
                'top_p': 0.9,
                'frequency_penalty': 0.2
            }
        else:
            # æº€è¶³åº¦ãŒé«˜ã„å ´åˆã¯ã€ã‚ˆã‚Šå‰µé€ çš„ã«
            return {
                'temperature': 0.8,
                'top_p': 0.95,
                'frequency_penalty': 0.0
            }
```

## 3ï¸âƒ£ äº¤æ¸‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆæœ€é‡è¦ï¼‰

### åŸºæœ¬å®šç¾©

```yaml
agent_name: "NegotiationAgent_Misaki"
description: "äººé–“ã‚‰ã—ã„è‡ªç„¶ãªäº¤æ¸‰ã‚’å®Ÿç¾ã™ã‚‹å–¶æ¥­æ‹…å½“è€…AI"
model: "gemini-1.5-pro"  # æœ€é«˜å“è³ªãƒ¢ãƒ‡ãƒ«
temperature: 0.85  # äººé–“ã‚‰ã—ã•ã®ãŸã‚ã«é«˜ã‚
max_tokens: 1024
response_delay: "10-120 minutes"  # äººé–“çš„ãªè¿”ä¿¡é–“éš”
```

### è©³ç´°ãªäººæ ¼è¨­å®š

```python
PERSONA_DEFINITION = {
    "basic_info": {
        "name": "ç”°ä¸­ç¾å’²",
        "age": 28,
        "role": "ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ‹…å½“",
        "company": "æ ªå¼ä¼šç¤¾InfuMatch",
        "experience": "å‰è·ã¯å¤§æ‰‹PRä¼šç¤¾ã§3å¹´é–“å‹¤å‹™"
    },
    "personality": {
        "traits": [
            "æ˜ã‚‹ãè¦ªã—ã¿ã‚„ã™ã„",
            "ç›¸æ‰‹ã®ç«‹å ´ã‚’ç†è§£ã™ã‚‹å…±æ„ŸåŠ›",
            "æ™‚ã€…å¤©ç„¶ãªä¸€é¢ã‚‚",
            "ã‚³ãƒ¼ãƒ’ãƒ¼ãŒå¤§å¥½ã"
        ],
        "communication_style": {
            "formality": "casual_polite",  # ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«æ•¬èª
            "emoji_frequency": 0.15,       # 15%ã®ç¢ºç‡ã§çµµæ–‡å­—
            "personal_anecdote": 0.1,      # 10%ã§å€‹äººçš„ãªè©±é¡Œ
            "typo_rate": 0.02             # 2%ã§ã‚¿ã‚¤ãƒ
        }
    },
    "knowledge": {
        "expertise": ["SNSãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°", "è‹¥è€…ãƒˆãƒ¬ãƒ³ãƒ‰", "ã‚³ã‚¹ãƒ¡ãƒ»ç¾å®¹"],
        "weak_points": ["å°‚é–€çš„ã™ãã‚‹æŠ€è¡“ç”¨èª", "å¤ã„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ‰‹æ³•"]
    },
    "schedule": {
        "work_hours": "9:00-18:00",
        "lunch_break": "12:00-13:00",
        "response_patterns": {
            "morning": {"delay": "10-30min", "energy": "high"},
            "afternoon": {"delay": "20-60min", "energy": "medium"},
            "evening": {"delay": "30-120min", "energy": "low"}
        }
    }
}
```

### ä¼šè©±ã®æ–‡è„ˆç®¡ç†

```python
class ConversationMemory:
    def __init__(self):
        self.conversation_history = []
        self.influencer_profile = {}
        self.mentioned_topics = set()
        self.relationship_stage = "initial"  # initial -> warming -> negotiating -> closing
        
    def update_context(self, message, response):
        """ä¼šè©±ã®é€²è¡Œã«å¿œã˜ã¦æ–‡è„ˆã‚’æ›´æ–°"""
        self.conversation_history.append({
            'timestamp': datetime.now(),
            'message': message,
            'response': response
        })
        
        # é–¢ä¿‚æ€§ã®æ®µéšã‚’æ›´æ–°
        if len(self.conversation_history) > 3:
            self.relationship_stage = "warming"
        if "äºˆç®—" in message or "æ–™é‡‘" in message:
            self.relationship_stage = "negotiating"
            
    def generate_contextual_prompt(self, new_message):
        """æ–‡è„ˆã‚’è€ƒæ…®ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        return f"""
        ã‚ãªãŸã¯{PERSONA_DEFINITION['basic_info']['name']}ã§ã™ã€‚
        
        ## ç¾åœ¨ã®é–¢ä¿‚æ€§æ®µéš: {self.relationship_stage}
        
        ## ã“ã‚Œã¾ã§ã®ä¼šè©±ã§è§¦ã‚ŒãŸè©±é¡Œ:
        {', '.join(self.mentioned_topics)}
        
        ## ä¼šè©±å±¥æ­´ï¼ˆæœ€æ–°3ä»¶ï¼‰:
        {self.format_recent_history()}
        
        ## æ–°ç€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:
        {new_message}
        
        ## è¿”ä¿¡ä½œæˆã®æŒ‡ç¤º:
        - é–¢ä¿‚æ€§æ®µéšã«å¿œã˜ãŸé©åˆ‡ãªãƒˆãƒ¼ãƒ³ã§
        - éå»ã®è©±é¡Œã‚’è‡ªç„¶ã«ç¹”ã‚Šäº¤ãœã‚‹
        - {self.get_stage_specific_instructions()}
        """
```

### äººé–“ã‚‰ã—ã•ã®æ¼”å‡ºãƒ†ã‚¯ãƒ‹ãƒƒã‚¯

```python
class HumanLikeGenerator:
    def __init__(self):
        self.typo_patterns = [
            ("ã§ã™", "ã§s", 0.01),
            ("ã‚ã‚ŠãŒã¨ã†", "ã‚ã‚ŠãŒã¨ã†ï¼", 0.1),
            ("ã‚ˆã‚ã—ã", "ã‚ˆã‚ã—ããƒ¼", 0.05)
        ]
        self.filler_words = ["ãˆãƒ¼ã£ã¨", "ãã†ã§ã™ã­", "ãªã‚‹ã»ã©"]
        
    def add_human_touches(self, text, context):
        """äººé–“ã‚‰ã—ã„è¦ç´ ã‚’è¿½åŠ """
        # 1. æ™‚é–“å¸¯ã«å¿œã˜ãŸæŒ¨æ‹¶
        text = self.add_time_based_greeting(text)
        
        # 2. ãŸã¾ã«é¡”æ–‡å­—ã‚„çµµæ–‡å­—
        if random.random() < PERSONA_DEFINITION['personality']['communication_style']['emoji_frequency']:
            text = self.add_emoji(text)
            
        # 3. å€‹äººçš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æŒ¿å…¥
        if random.random() < PERSONA_DEFINITION['personality']['communication_style']['personal_anecdote']:
            text = self.insert_personal_story(text, context)
            
        # 4. è‡ªç„¶ãªã‚¿ã‚¤ãƒ
        text = self.introduce_natural_typos(text)
        
        # 5. æ€è€ƒã®æºã‚Œã‚’è¡¨ç¾
        text = self.add_thinking_process(text)
        
        return text
    
    def add_thinking_process(self, text):
        """æ€è€ƒéç¨‹ã‚’ç¤ºã™è¡¨ç¾ã‚’è¿½åŠ """
        thinking_patterns = [
            "å®Ÿã¯æœ€åˆã¯ã€‡ã€‡ã‹ãªã¨æ€ã£ãŸã‚“ã§ã™ãŒã€",
            "ã¡ã‚‡ã£ã¨æ‚©ã‚“ã ã‚“ã§ã™ã‘ã©ã€",
            "ã“ã‚Œã¯ç§ã®å€‹äººçš„ãªæ„è¦‹ãªã‚“ã§ã™ãŒã€"
        ]
        
        if "ææ¡ˆ" in text and random.random() < 0.3:
            position = text.find("ææ¡ˆ")
            pattern = random.choice(thinking_patterns)
            text = text[:position] + pattern + text[position:]
            
        return text
```

### ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãŸã‚ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—

```python
class AgentPerformanceTracker:
    def __init__(self):
        self.metrics = {
            'response_rate': [],      # è¿”ä¿¡ç‡
            'positive_sentiment': [],  # ãƒã‚¸ãƒ†ã‚£ãƒ–ãªåå¿œç‡
            'conversion_rate': [],    # æˆç´„ç‡
            'human_score': []         # äººé–“ã‚‰ã—ã•ã‚¹ã‚³ã‚¢
        }
        
    def collect_feedback(self, conversation_id):
        """ä¼šè©±çµ‚äº†å¾Œã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†"""
        feedback = {
            'did_respond': bool,
            'sentiment': float,  # -1 to 1
            'converted': bool,
            'suspected_ai': bool  # AIã ã¨ç–‘ã‚ã‚ŒãŸã‹
        }
        
        self.update_metrics(feedback)
        return self.generate_improvement_suggestions()
    
    def generate_improvement_suggestions(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«åŸºã¥ãæ”¹å–„ææ¡ˆ"""
        suggestions = []
        
        if np.mean(self.metrics['human_score']) < 0.7:
            suggestions.append({
                'area': 'humanization',
                'action': 'increase_personal_anecdotes',
                'parameter_change': {
                    'personal_anecdote': 0.15,  # 10% -> 15%
                    'typo_rate': 0.03          # 2% -> 3%
                }
            })
            
        if np.mean(self.metrics['response_rate']) < 0.5:
            suggestions.append({
                'area': 'initial_contact',
                'action': 'more_personalized_opening',
                'prompt_addition': 'å¿…ãšç›¸æ‰‹ã®æœ€æ–°å‹•ç”»ã«ã¤ã„ã¦å…·ä½“çš„ã«è¨€åŠã™ã‚‹'
            })
            
        return suggestions
```

### ç¶™ç¶šçš„ãªå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 

```python
class ContinuousLearning:
    def __init__(self):
        self.successful_patterns = []
        self.failed_patterns = []
        
    def learn_from_conversation(self, conversation, outcome):
        """ä¼šè©±ã‹ã‚‰å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
        patterns = self.extract_patterns(conversation)
        
        if outcome['success']:
            self.successful_patterns.extend(patterns)
        else:
            self.failed_patterns.extend(patterns)
            
        # å®šæœŸçš„ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ›´æ–°
        if len(self.successful_patterns) > 100:
            self.update_agent_prompts()
            
    def update_agent_prompts(self):
        """æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åŸºã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•æ›´æ–°"""
        success_insights = self.analyze_patterns(self.successful_patterns)
        failure_insights = self.analyze_patterns(self.failed_patterns)
        
        updated_prompt = f"""
        ## æˆåŠŸã™ã‚‹ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³:
        {success_insights}
        
        ## é¿ã‘ã‚‹ã¹ããƒ‘ã‚¿ãƒ¼ãƒ³:
        {failure_insights}
        
        {SYSTEM_PROMPT}
        """
        
        return updated_prompt
```

## ğŸš€ å®Ÿè£…ã¨ãƒ‡ãƒ—ãƒ­ã‚¤æˆ¦ç•¥

### é–‹ç™ºç’°å¢ƒã§ã®ãƒ†ã‚¹ãƒˆ

```python
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®A/Bãƒ†ã‚¹ãƒˆç’°å¢ƒ
class AgentTestingFramework:
    def __init__(self):
        self.test_scenarios = [
            "åˆå›ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ",
            "æ–™é‡‘äº¤æ¸‰",
            "æ—¥ç¨‹èª¿æ•´",
            "å¥‘ç´„ç· çµ"
        ]
        
    async def run_comprehensive_test(self, agent):
        results = {}
        
        for scenario in self.test_scenarios:
            # 10ãƒ‘ã‚¿ãƒ¼ãƒ³ãšã¤ãƒ†ã‚¹ãƒˆ
            scenario_results = []
            for i in range(10):
                result = await self.test_scenario(agent, scenario)
                scenario_results.append(result)
                
            results[scenario] = {
                'success_rate': self.calculate_success_rate(scenario_results),
                'human_score': self.calculate_human_score(scenario_results),
                'average_time': self.calculate_avg_time(scenario_results)
            }
            
        return results
```

### æœ¬ç•ªç’°å¢ƒã¸ã®æ®µéšçš„å°å…¥

```yaml
deployment_stages:
  stage1_shadow:
    description: "æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ä¸¦è¡Œç¨¼åƒ"
    duration: "1 week"
    traffic: "0%"
    purpose: "å‹•ä½œç¢ºèªã¨ãƒ­ã‚°åé›†"
    
  stage2_canary:
    description: "ä¸€éƒ¨ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã§æ¤œè¨¼"
    duration: "1 week"
    traffic: "10%"
    purpose: "å®Ÿéš›ã®åå¿œã‚’ç¢ºèª"
    
  stage3_progressive:
    description: "æ®µéšçš„å±•é–‹"
    duration: "2 weeks"
    traffic: "10% -> 50% -> 100%"
    purpose: "å•é¡ŒãŒãªã„ã“ã¨ã‚’ç¢ºèªã—ãªãŒã‚‰å±•é–‹"
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

```python
class AgentMonitoring:
    def __init__(self):
        self.metrics = {
            'latency': CloudMonitoring('response_time'),
            'accuracy': CloudMonitoring('extraction_accuracy'),
            'satisfaction': CloudMonitoring('user_satisfaction'),
            'cost': CloudMonitoring('api_cost')
        }
        
    def create_dashboard(self):
        """ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š"""
        return {
            'widgets': [
                {
                    'title': 'ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¿œç­”æ™‚é–“',
                    'metric': 'response_time_p95',
                    'threshold': 3000  # 3ç§’
                },
                {
                    'title': 'ãƒ¡ãƒ¼ãƒ«æŠ½å‡ºç²¾åº¦',
                    'metric': 'email_extraction_accuracy',
                    'threshold': 0.95  # 95%
                },
                {
                    'title': 'äº¤æ¸‰æˆåŠŸç‡',
                    'metric': 'negotiation_success_rate',
                    'threshold': 0.3  # 30%
                }
            ]
        }
```

---

**æ–‡æ›¸ä½œæˆæ—¥**: 2025-06-14  
**ä½œæˆè€…**: ãƒãƒƒã‚«ã‚½ãƒ³ãƒãƒ¼ãƒ   
**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—å®Ÿè£…ã¨ãƒ†ã‚¹ãƒˆç’°å¢ƒæ§‹ç¯‰